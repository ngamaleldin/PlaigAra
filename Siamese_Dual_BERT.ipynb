{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 16:03:33.557332: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-14 16:03:33.584873: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-14 16:03:33.585695: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-14 16:03:34.155253: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.13.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 15:23:11.693567: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-14 15:23:11.858929: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-14 15:23:11.858981: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 6.891944,
     "end_time": "2021-04-14T22:58:53.819082",
     "exception": false,
     "start_time": "2021-04-14T22:58:46.927138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/longnew/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling1D, Concatenate, Dropout, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from transformers import AutoTokenizer, TFLongformerModel, LongformerConfig, AutoModel, BertConfig, TFAutoModel, TFBertModel, LongformerTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "papermill": {
     "duration": 0.027398,
     "end_time": "2021-04-14T22:58:53.861468",
     "exception": false,
     "start_time": "2021-04-14T22:58:53.834070",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, fontsize=25)\n",
    "    #plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90, fontsize=15)\n",
    "    plt.yticks(tick_marks, classes, fontsize=15)\n",
    "\n",
    "    fmt = '.2f'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\", fontsize = 14)\n",
    "\n",
    "    plt.ylabel('True label', fontsize=20)\n",
    "    plt.xlabel('Predicted label', fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('FinalDatasetBalanced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_content</th>\n",
       "      <th>suspicious_content</th>\n",
       "      <th>plagiarism_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>بين عالم يعمل على أن يجعل الحياة أكثر رفاهية، ...</td>\n",
       "      <td>إن الاختلاج هو الحالة التي يحدث فيها تفريغ فجا...</td>\n",
       "      <td>No Plagiarism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>لماذا نحتاج لطرح صيغة جديدة من صيغ الإجابة على...</td>\n",
       "      <td>اً كانوا يؤدونه للنبي صلى الله عليه وسلم لقاتل...</td>\n",
       "      <td>No Plagiarism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>* اختارتني الأمم المتحدة سفيرا لانحيازي للبسطا...</td>\n",
       "      <td>المخرجة الفلسطينية \"مي المصري\" في مجمل أعمالها...</td>\n",
       "      <td>No Plagiarism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>الحياة محطات.\\nوحياتي تزخر بمحطات كثيرة, في ال...</td>\n",
       "      <td>وة إلى \"أمة الإسلام\"، وكان في دعوته يميل إلى ا...</td>\n",
       "      <td>No Plagiarism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>لمحات من سيرة عذبة لواحد من عشاق التراث العربي...</td>\n",
       "      <td>ن الإسلام.. يقدمه - عن فهم وعقيدة - على أنه نظ...</td>\n",
       "      <td>No Plagiarism</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      source_content  \\\n",
       "0  بين عالم يعمل على أن يجعل الحياة أكثر رفاهية، ...   \n",
       "1  لماذا نحتاج لطرح صيغة جديدة من صيغ الإجابة على...   \n",
       "2  * اختارتني الأمم المتحدة سفيرا لانحيازي للبسطا...   \n",
       "3  الحياة محطات.\\nوحياتي تزخر بمحطات كثيرة, في ال...   \n",
       "4  لمحات من سيرة عذبة لواحد من عشاق التراث العربي...   \n",
       "\n",
       "                                  suspicious_content plagiarism_type  \n",
       "0  إن الاختلاج هو الحالة التي يحدث فيها تفريغ فجا...   No Plagiarism  \n",
       "1  اً كانوا يؤدونه للنبي صلى الله عليه وسلم لقاتل...   No Plagiarism  \n",
       "2  المخرجة الفلسطينية \"مي المصري\" في مجمل أعمالها...   No Plagiarism  \n",
       "3  وة إلى \"أمة الإسلام\"، وكان في دعوته يميل إلى ا...   No Plagiarism  \n",
       "4  ن الإسلام.. يقدمه - عن فهم وعقيدة - على أنه نظ...   No Plagiarism  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No Plagiarism', 'Artificial Obfuscation', 'No Obfuscation',\n",
       "       'Simulated Obfuscation'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['plagiarism_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['plagiarism_type'] = df['plagiarism_type'].factorize()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_label = dict(enumerate(df['plagiarism_type'].factorize()[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0, 1: 1, 2: 2, 3: 3}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['plagiarism_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    \n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    \n",
    "def convert_to_transformer_inputs(str1, str2, tokenizer, max_sequence_length, double=True):\n",
    "    def return_id(str1, str2, length):\n",
    "        inputs = tokenizer.encode_plus(\n",
    "            str1, str2,\n",
    "            add_special_tokens=True,\n",
    "            max_length=length,\n",
    "            truncation=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        input_ids = inputs[\"input_ids\"]\n",
    "        input_masks = inputs[\"attention_mask\"]\n",
    "        input_segments = inputs[\"token_type_ids\"]\n",
    "        \n",
    "        padding_length = length - len(input_ids)\n",
    "        padding_id = tokenizer.pad_token_id\n",
    "        \n",
    "        input_ids = input_ids + ([padding_id] * padding_length)\n",
    "        input_masks = input_masks + ([0] * padding_length)\n",
    "        input_segments = input_segments + ([0] * padding_length)\n",
    "        \n",
    "        return [input_ids, input_masks, input_segments]\n",
    "\n",
    "    if double:\n",
    "        input_ids_1, input_masks_1, input_segments_1 = return_id(str1, None, max_sequence_length)\n",
    "        input_ids_2, input_masks_2, input_segments_2 = return_id(str2, None, max_sequence_length)\n",
    "\n",
    "        return [input_ids_1, input_masks_1, input_segments_1,\n",
    "                input_ids_2, input_masks_2, input_segments_2]\n",
    "    else:\n",
    "        input_ids, input_masks, input_segments = return_id(str1, str2, max_sequence_length)\n",
    "\n",
    "        return [input_ids, input_masks, input_segments, None, None, None]\n",
    "\n",
    "def compute_input_arrays(df, columns, tokenizer, max_sequence_length, double=True):\n",
    "    input_ids_1, input_masks_1, input_segments_1 = [], [], []\n",
    "    input_ids_2, input_masks_2, input_segments_2 = [], [], []\n",
    "    \n",
    "    for _, instance in df[columns].iterrows():\n",
    "        str1, str2 = instance[columns[0]], instance[columns[1]]\n",
    "        ids_1, masks_1, segments_1, ids_2, masks_2, segments_2 = \\\n",
    "            convert_to_transformer_inputs(str1, str2, tokenizer, max_sequence_length, double=double)\n",
    "        \n",
    "        input_ids_1.append(ids_1)\n",
    "        input_masks_1.append(masks_1)\n",
    "        input_segments_1.append(segments_1)\n",
    "        input_ids_2.append(ids_2)\n",
    "        input_masks_2.append(masks_2)\n",
    "        input_segments_2.append(segments_2)\n",
    "\n",
    "    if double:\n",
    "        return [np.asarray(input_ids_1, dtype=np.int32), \n",
    "                np.asarray(input_masks_1, dtype=np.int32), \n",
    "                np.asarray(input_segments_1, dtype=np.int32),\n",
    "                np.asarray(input_ids_2, dtype=np.int32), \n",
    "                np.asarray(input_masks_2, dtype=np.int32), \n",
    "                np.asarray(input_segments_2, dtype=np.int32)]\n",
    "    else:\n",
    "        return [np.asarray(input_ids_1, dtype=np.int32), \n",
    "                np.asarray(input_masks_1, dtype=np.int32), \n",
    "                np.asarray(input_segments_1, dtype=np.int32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "papermill": {
     "duration": 0.029122,
     "end_time": "2021-04-14T22:58:58.574409",
     "exception": false,
     "start_time": "2021-04-14T22:58:58.545287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1702, 2) (730, 2)\n",
      "(1702,) (730,)\n"
     ]
    }
   ],
   "source": [
    "### TRAIN TEST SPLIT ###\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['source_content','suspicious_content']], df['plagiarism_type'].values, \n",
    "                                                    random_state=33, test_size = 0.3)\n",
    "\n",
    "# del df\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "papermill": {
     "duration": 1.789212,
     "end_time": "2021-04-14T22:59:00.379957",
     "exception": false,
     "start_time": "2021-04-14T22:58:58.590745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### IMPORT TOKENIZER ###\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 16000\n",
    "MODEL_NAME = \"longformer-encdec-base-16384\"\n",
    "# MODEL_NAME = \"google-bert/bert-base-uncased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.978528,
     "end_time": "2021-04-14T23:15:37.165887",
     "exception": false,
     "start_time": "2021-04-14T23:15:36.187359",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **DUAL BERT (TWO INPUT)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "papermill": {
     "duration": 18.533315,
     "end_time": "2021-04-14T23:15:56.675934",
     "exception": false,
     "start_time": "2021-04-14T23:15:38.142619",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### CREATE SEQUENCES (id, mask, segments) FOR TRAIN AND TEST ###\n",
    "\n",
    "input_train = compute_input_arrays(X_train,['source_content','suspicious_content'], tokenizer, MAX_SEQUENCE_LENGTH)\n",
    "input_test = compute_input_arrays(X_test, ['source_content','suspicious_content'], tokenizer, MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dual_longformer():\n",
    "    \n",
    "    set_seed(33)\n",
    "    opt = Adam(learning_rate=2e-5)\n",
    "    \n",
    "    id1 = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n",
    "    id2 = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n",
    "    mask1 = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n",
    "    mask2 = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n",
    "    atn1 = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n",
    "    atn2 = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n",
    "    \n",
    "    config = LongformerConfig.from_pretrained(MODEL_NAME)\n",
    "    config.max_position_embeddings = 16000\n",
    "    config.attention_window = [256] * config.num_hidden_layers\n",
    "\n",
    "    # tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "\n",
    "    # with tf.device('/GPU:0'):\n",
    "    longformer_model1 = TFAutoModel.from_pretrained(MODEL_NAME, config=config, from_pt=True)\n",
    "    longformer_model2 = TFAutoModel.from_pretrained(MODEL_NAME, config=config, from_pt=True)\n",
    "    \n",
    "    embedding1 = longformer_model1(id1, attention_mask=mask1, token_type_ids=atn1)[0]\n",
    "    embedding2 = longformer_model2(id2, attention_mask=mask2, token_type_ids=atn2)[0]\n",
    "    \n",
    "    x1 = GlobalAveragePooling1D()(embedding1)\n",
    "    x2 = GlobalAveragePooling1D()(embedding2)\n",
    "    \n",
    "    x = Concatenate()([x1, x2])\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    out = Dense(len(map_label), activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=[id1, mask1, atn1, id2, mask2, atn2], outputs=out)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=opt)\n",
    "    \n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "class SavePretrainedCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, save_path='longformer_checkpoints'):\n",
    "        super().__init__()\n",
    "        self.save_path = save_path\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        epoch_path = f'{self.save_path}/epoch_{epoch+1}'\n",
    "        os.makedirs(epoch_path, exist_ok=True)\n",
    "        \n",
    "        # Save the model\n",
    "        self.model.save_pretrained(epoch_path)\n",
    "        print(f'\\nSaved model to {epoch_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 1722.981337,
     "end_time": "2021-04-14T23:44:43.098655",
     "exception": false,
     "start_time": "2021-04-14T23:16:00.117318",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 15:24:03.692447: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-14 15:24:03.692540: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-14 15:24:03.692572: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-14 15:24:03.952846: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-14 15:24:03.952919: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-14 15:24:03.952929: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-11-14 15:24:03.952963: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-14 15:24:03.953024: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5535 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "You are using a model of type bart to instantiate a model of type longformer. This is not supported for all configurations of models and can yield errors.\n",
      "2024-11-14 15:24:05.108756: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFLongformerModel: ['model.encoder.layers.5.self_attn.output.weight', 'model.decoder.layers.2.self_attn_layer_norm.weight', 'model.encoder.layers.5.self_attn.longformer_self_attn.key.bias', 'model.encoder.embed_tokens.weight', 'model.decoder.layers.0.self_attn_layer_norm.bias', 'model.decoder.layers.0.self_attn.out_proj.bias', 'model.encoder.layers.2.self_attn.longformer_self_attn.query_global.weight', 'model.encoder.layers.3.self_attn.longformer_self_attn.value_global.bias', 'model.decoder.layers.3.final_layer_norm.weight', 'model.encoder.layers.3.self_attn.longformer_self_attn.query.weight', 'model.decoder.layers.1.encoder_attn.k_proj.bias', 'model.decoder.layers.4.self_attn.out_proj.weight', 'model.decoder.layers.1.self_attn.k_proj.bias', 'model.decoder.layers.3.self_attn.k_proj.bias', 'model.decoder.layers.5.fc1.weight', 'model.decoder.layers.5.encoder_attn_layer_norm.weight', 'model.encoder.layers.5.fc2.weight', 'model.encoder.layers.3.self_attn.output.bias', 'model.encoder.layers.2.self_attn.longformer_self_attn.value.bias', 'model.decoder.layers.1.self_attn_layer_norm.weight', 'model.encoder.layers.0.final_layer_norm.bias', 'model.encoder.layers.0.self_attn.longformer_self_attn.query.bias', 'model.encoder.layers.5.self_attn.longformer_self_attn.value_global.bias', 'model.encoder.layers.4.self_attn_layer_norm.bias', 'model.encoder.layers.3.final_layer_norm.weight', 'model.decoder.layers.5.final_layer_norm.bias', 'model.decoder.layers.3.encoder_attn.v_proj.bias', 'model.decoder.layers.0.encoder_attn_layer_norm.weight', 'model.encoder.layers.0.self_attn.longformer_self_attn.query_global.weight', 'model.encoder.layers.2.self_attn.longformer_self_attn.query.weight', 'model.decoder.layers.1.final_layer_norm.weight', 'model.decoder.layers.4.fc2.bias', 'model.encoder.layers.2.self_attn_layer_norm.bias', 'model.encoder.layers.1.self_attn.output.bias', 'model.decoder.layers.2.fc2.bias', 'model.decoder.layers.5.encoder_attn_layer_norm.bias', 'model.decoder.layers.1.encoder_attn.v_proj.bias', 'model.decoder.layers.4.encoder_attn_layer_norm.bias', 'model.decoder.layers.1.fc1.bias', 'model.decoder.layers.2.encoder_attn.out_proj.weight', 'model.decoder.layers.3.self_attn.q_proj.weight', 'model.encoder.layers.3.final_layer_norm.bias', 'model.decoder.layers.2.fc2.weight', 'model.encoder.layers.1.fc1.weight', 'model.decoder.layers.3.encoder_attn.v_proj.weight', 'model.decoder.layers.5.encoder_attn.v_proj.bias', 'model.encoder.layers.1.self_attn_layer_norm.weight', 'model.decoder.layers.1.encoder_attn.out_proj.bias', 'model.encoder.layers.5.fc1.weight', 'model.encoder.layers.4.fc2.bias', 'model.decoder.layers.4.self_attn.out_proj.bias', 'model.decoder.layers.5.self_attn.v_proj.weight', 'model.decoder.layers.3.self_attn.out_proj.weight', 'model.decoder.layers.4.fc1.bias', 'model.decoder.layers.3.self_attn_layer_norm.bias', 'model.decoder.embed_positions.weight', 'model.decoder.layers.0.self_attn.k_proj.weight', 'model.encoder.layers.5.self_attn.output.bias', 'model.encoder.layers.1.final_layer_norm.weight', 'model.encoder.layers.0.self_attn_layer_norm.bias', 'model.decoder.layers.1.self_attn.v_proj.bias', 'model.encoder.layers.3.fc2.bias', 'model.decoder.layers.4.fc1.weight', 'model.encoder.layers.5.self_attn.longformer_self_attn.key_global.weight', 'model.decoder.layers.1.encoder_attn.out_proj.weight', 'model.decoder.layers.2.self_attn.out_proj.bias', 'model.decoder.layers.5.self_attn_layer_norm.bias', 'model.decoder.layers.1.encoder_attn_layer_norm.bias', 'model.decoder.layers.1.encoder_attn.k_proj.weight', 'model.encoder.layers.5.fc2.bias', 'model.encoder.layers.3.self_attn.longformer_self_attn.key.bias', 'model.encoder.layers.1.self_attn.longformer_self_attn.query_global.bias', 'model.decoder.layers.2.self_attn.v_proj.weight', 'model.decoder.layers.5.self_attn.q_proj.bias', 'model.shared.weight', 'model.decoder.layers.3.encoder_attn_layer_norm.weight', 'model.encoder.layers.1.self_attn_layer_norm.bias', 'model.encoder.layers.3.self_attn.longformer_self_attn.value_global.weight', 'model.decoder.layers.4.encoder_attn.k_proj.bias', 'model.encoder.layers.4.self_attn.longformer_self_attn.value.weight', 'model.encoder.layers.5.fc1.bias', 'model.decoder.layers.3.fc1.bias', 'model.decoder.layernorm_embedding.weight', 'model.encoder.layers.5.self_attn.longformer_self_attn.query.bias', 'model.encoder.layers.4.self_attn.longformer_self_attn.query.bias', 'model.decoder.layers.5.encoder_attn.q_proj.weight', 'model.decoder.layers.5.self_attn.out_proj.weight', 'model.encoder.layers.0.fc1.bias', 'model.encoder.layers.1.self_attn.longformer_self_attn.query_global.weight', 'model.decoder.layers.1.self_attn.out_proj.bias', 'model.encoder.layers.0.final_layer_norm.weight', 'model.encoder.layers.4.self_attn.longformer_self_attn.value.bias', 'model.encoder.layers.3.fc2.weight', 'model.encoder.layers.4.self_attn.longformer_self_attn.key.bias', 'model.encoder.layers.5.self_attn.longformer_self_attn.query_global.bias', 'model.decoder.layers.2.self_attn.k_proj.weight', 'model.encoder.layers.4.self_attn.longformer_self_attn.value_global.bias', 'model.decoder.layers.2.final_layer_norm.weight', 'model.decoder.layers.3.self_attn.v_proj.weight', 'model.encoder.layers.5.final_layer_norm.weight', 'model.decoder.layers.0.encoder_attn.q_proj.bias', 'model.decoder.layers.1.self_attn.out_proj.weight', 'model.decoder.layers.2.self_attn.q_proj.bias', 'model.decoder.layers.2.encoder_attn.out_proj.bias', 'model.encoder.layers.0.fc1.weight', 'model.encoder.layers.4.self_attn.longformer_self_attn.query_global.weight', 'model.encoder.layers.4.final_layer_norm.weight', 'model.encoder.layers.5.self_attn_layer_norm.bias', 'model.decoder.layers.5.encoder_attn.k_proj.weight', 'model.decoder.layers.4.self_attn.v_proj.weight', 'model.decoder.layers.0.fc2.weight', 'model.encoder.layers.1.final_layer_norm.bias', 'model.decoder.layers.3.self_attn.k_proj.weight', 'model.encoder.layers.4.final_layer_norm.bias', 'model.encoder.layers.4.fc2.weight', 'model.decoder.layers.3.encoder_attn.k_proj.bias', 'model.encoder.layers.3.self_attn_layer_norm.bias', 'model.encoder.layers.4.self_attn.output.bias', 'model.decoder.layers.5.self_attn.q_proj.weight', 'model.decoder.layers.3.final_layer_norm.bias', 'model.decoder.layers.3.encoder_attn.q_proj.weight', 'model.decoder.layers.2.encoder_attn.v_proj.weight', 'model.decoder.layers.4.encoder_attn.q_proj.weight', 'model.decoder.layers.3.encoder_attn.k_proj.weight', 'model.encoder.layers.1.self_attn.longformer_self_attn.value_global.weight', 'model.encoder.layers.0.self_attn.longformer_self_attn.value_global.weight', 'model.encoder.layers.4.self_attn.output.weight', 'model.encoder.layers.4.fc1.bias', 'model.encoder.layers.3.self_attn.longformer_self_attn.query.bias', 'model.encoder.layers.2.self_attn.longformer_self_attn.value_global.bias', 'model.decoder.layers.0.encoder_attn.k_proj.bias', 'model.decoder.layers.2.encoder_attn_layer_norm.bias', 'model.decoder.layers.4.final_layer_norm.weight', 'model.decoder.layers.4.final_layer_norm.bias', 'model.decoder.layers.0.encoder_attn.q_proj.weight', 'model.decoder.layers.5.fc1.bias', 'model.decoder.layers.3.encoder_attn_layer_norm.bias', 'model.encoder.layers.3.self_attn.longformer_self_attn.value.weight', 'model.encoder.layers.4.self_attn.longformer_self_attn.key_global.weight', 'model.encoder.layers.0.self_attn.longformer_self_attn.query.weight', 'model.encoder.layers.0.self_attn.longformer_self_attn.key.weight', 'model.encoder.layers.2.self_attn.output.bias', 'model.encoder.layers.0.self_attn.longformer_self_attn.key_global.bias', 'model.decoder.layers.1.encoder_attn_layer_norm.weight', 'model.encoder.layers.2.self_attn.output.weight', 'model.decoder.layers.3.encoder_attn.q_proj.bias', 'model.decoder.layers.3.fc1.weight', 'model.decoder.layers.5.self_attn_layer_norm.weight', 'model.decoder.layers.0.self_attn.out_proj.weight', 'model.encoder.layers.5.self_attn_layer_norm.weight', 'model.decoder.layers.0.self_attn.v_proj.weight', 'model.encoder.layers.5.self_attn.longformer_self_attn.key_global.bias', 'model.decoder.layers.2.encoder_attn_layer_norm.weight', 'model.encoder.layers.5.self_attn.longformer_self_attn.value_global.weight', 'model.decoder.layers.2.fc1.weight', 'model.decoder.layers.2.encoder_attn.k_proj.weight', 'model.encoder.layers.2.self_attn.longformer_self_attn.key_global.weight', 'model.decoder.layers.4.self_attn_layer_norm.bias', 'model.decoder.layers.4.self_attn.q_proj.weight', 'model.decoder.layernorm_embedding.bias', 'model.encoder.layers.3.fc1.weight', 'model.encoder.layers.4.self_attn.longformer_self_attn.key_global.bias', 'model.decoder.layers.2.encoder_attn.v_proj.bias', 'model.encoder.layers.0.self_attn.longformer_self_attn.query_global.bias', 'model.encoder.layers.0.self_attn.longformer_self_attn.value_global.bias', 'model.decoder.layers.2.encoder_attn.q_proj.bias', 'model.decoder.layers.2.fc1.bias', 'final_logits_bias', 'model.decoder.layers.1.self_attn.q_proj.bias', 'model.decoder.layers.5.encoder_attn.v_proj.weight', 'model.encoder.layers.5.self_attn.longformer_self_attn.key.weight', 'model.encoder.layers.1.fc1.bias', 'model.decoder.layers.1.self_attn.k_proj.weight', 'model.encoder.layers.4.self_attn.longformer_self_attn.query.weight', 'model.decoder.layers.5.self_attn.out_proj.bias', 'model.decoder.layers.0.fc1.bias', 'model.decoder.layers.0.self_attn.q_proj.weight', 'model.decoder.layers.4.encoder_attn.k_proj.weight', 'model.decoder.layers.0.fc1.weight', 'model.decoder.layers.4.encoder_attn_layer_norm.weight', 'model.encoder.layers.2.fc1.weight', 'model.encoder.layers.3.self_attn.longformer_self_attn.key_global.weight', 'model.decoder.layers.3.encoder_attn.out_proj.weight', 'model.encoder.layers.0.self_attn_layer_norm.weight', 'model.decoder.layers.5.encoder_attn.q_proj.bias', 'model.decoder.layers.4.encoder_attn.v_proj.bias', 'model.decoder.layers.1.fc2.weight', 'model.encoder.layers.4.fc1.weight', 'model.decoder.layers.2.self_attn.v_proj.bias', 'model.encoder.layers.3.self_attn.longformer_self_attn.value.bias', 'model.encoder.layers.5.final_layer_norm.bias', 'model.encoder.layers.3.self_attn.longformer_self_attn.query_global.weight', 'model.decoder.layers.1.final_layer_norm.bias', 'model.encoder.layers.2.final_layer_norm.bias', 'model.decoder.layers.5.self_attn.v_proj.bias', 'model.encoder.layers.1.self_attn.longformer_self_attn.value.bias', 'model.decoder.layers.2.self_attn.out_proj.weight', 'model.encoder.layers.2.self_attn.longformer_self_attn.query.bias', 'model.encoder.layers.1.self_attn.longformer_self_attn.value.weight', 'model.decoder.layers.0.final_layer_norm.bias', 'model.decoder.layers.1.encoder_attn.q_proj.bias', 'model.decoder.layers.3.encoder_attn.out_proj.bias', 'model.decoder.layers.4.fc2.weight', 'model.encoder.layers.1.self_attn.longformer_self_attn.key_global.weight', 'model.encoder.layers.0.self_attn.longformer_self_attn.value.weight', 'model.encoder.layers.2.fc1.bias', 'model.decoder.layers.0.self_attn.v_proj.bias', 'model.decoder.layers.0.final_layer_norm.weight', 'model.decoder.layers.2.final_layer_norm.bias', 'model.decoder.layers.4.self_attn.k_proj.bias', 'model.encoder.layers.5.self_attn.longformer_self_attn.query_global.weight', 'model.encoder.layers.1.self_attn.longformer_self_attn.value_global.bias', 'model.encoder.layers.3.self_attn.longformer_self_attn.key_global.bias', 'model.encoder.layers.3.self_attn_layer_norm.weight', 'model.encoder.layers.2.self_attn.longformer_self_attn.key.bias', 'model.encoder.layers.4.self_attn.longformer_self_attn.key.weight', 'model.decoder.layers.4.self_attn.k_proj.weight', 'model.decoder.layers.2.self_attn.k_proj.bias', 'model.decoder.layers.0.self_attn_layer_norm.weight', 'model.decoder.layers.0.encoder_attn_layer_norm.bias', 'model.encoder.layers.2.self_attn.longformer_self_attn.query_global.bias', 'model.decoder.layers.5.encoder_attn.out_proj.weight', 'model.decoder.layers.3.self_attn.out_proj.bias', 'model.encoder.embed_positions.weight', 'model.decoder.layers.0.encoder_attn.out_proj.bias', 'model.decoder.layers.5.fc2.weight', 'model.decoder.layers.3.fc2.bias', 'model.decoder.layers.5.encoder_attn.k_proj.bias', 'model.decoder.layers.1.encoder_attn.v_proj.weight', 'model.encoder.layers.0.fc2.weight', 'model.decoder.layers.2.encoder_attn.q_proj.weight', 'model.decoder.layers.3.self_attn_layer_norm.weight', 'model.decoder.layers.3.fc2.weight', 'model.decoder.layers.5.self_attn.k_proj.weight', 'model.decoder.layers.0.fc2.bias', 'model.encoder.layers.1.self_attn.output.weight', 'model.encoder.layers.1.fc2.bias', 'model.encoder.layers.5.self_attn.longformer_self_attn.value.weight', 'model.encoder.layers.5.self_attn.longformer_self_attn.value.bias', 'model.decoder.layers.0.encoder_attn.v_proj.bias', 'model.decoder.layers.1.fc2.bias', 'model.decoder.layers.4.self_attn.v_proj.bias', 'model.decoder.layers.4.self_attn_layer_norm.weight', 'model.decoder.layers.5.final_layer_norm.weight', 'model.decoder.layers.2.self_attn_layer_norm.bias', 'model.encoder.layers.2.fc2.weight', 'model.encoder.layers.2.self_attn.longformer_self_attn.value.weight', 'model.decoder.layers.1.fc1.weight', 'model.decoder.layers.4.encoder_attn.out_proj.weight', 'model.encoder.layers.3.self_attn.longformer_self_attn.key.weight', 'model.decoder.layers.0.encoder_attn.v_proj.weight', 'model.encoder.layers.1.self_attn.longformer_self_attn.key.weight', 'model.encoder.layers.1.self_attn.longformer_self_attn.key.bias', 'model.encoder.layers.1.self_attn.longformer_self_attn.key_global.bias', 'model.encoder.layers.2.self_attn.longformer_self_attn.key.weight', 'model.encoder.layernorm_embedding.weight', 'model.encoder.layers.0.self_attn.longformer_self_attn.key_global.weight', 'model.encoder.layernorm_embedding.bias', 'model.encoder.layers.3.fc1.bias', 'model.decoder.layers.0.encoder_attn.out_proj.weight', 'model.decoder.layers.1.self_attn.v_proj.weight', 'model.encoder.layers.1.fc2.weight', 'model.encoder.layers.4.self_attn_layer_norm.weight', 'model.decoder.layers.0.encoder_attn.k_proj.weight', 'model.decoder.layers.1.self_attn.q_proj.weight', 'model.decoder.layers.1.self_attn_layer_norm.bias', 'model.decoder.embed_tokens.weight', 'model.decoder.layers.5.encoder_attn.out_proj.bias', 'model.encoder.layers.0.self_attn.output.bias', 'model.decoder.layers.4.encoder_attn.v_proj.weight', 'model.decoder.layers.3.self_attn.v_proj.bias', 'model.encoder.layers.4.self_attn.longformer_self_attn.value_global.weight', 'model.decoder.layers.1.encoder_attn.q_proj.weight', 'model.encoder.layers.1.self_attn.longformer_self_attn.query.weight', 'model.encoder.layers.2.self_attn.longformer_self_attn.key_global.bias', 'model.encoder.layers.3.self_attn.output.weight', 'model.encoder.layers.2.fc2.bias', 'model.encoder.layers.4.self_attn.longformer_self_attn.query_global.bias', 'model.decoder.layers.4.self_attn.q_proj.bias', 'model.decoder.layers.4.encoder_attn.q_proj.bias', 'model.decoder.layers.2.self_attn.q_proj.weight', 'model.decoder.layers.0.self_attn.q_proj.bias', 'model.decoder.layers.4.encoder_attn.out_proj.bias', 'model.encoder.layers.0.self_attn.longformer_self_attn.key.bias', 'model.encoder.layers.1.self_attn.longformer_self_attn.query.bias', 'model.decoder.layers.3.self_attn.q_proj.bias', 'model.decoder.layers.5.self_attn.k_proj.bias', 'model.encoder.layers.0.fc2.bias', 'model.encoder.layers.0.self_attn.output.weight', 'model.encoder.layers.2.final_layer_norm.weight', 'model.encoder.layers.0.self_attn.longformer_self_attn.value.bias', 'model.encoder.layers.5.self_attn.longformer_self_attn.query.weight', 'model.decoder.layers.0.self_attn.k_proj.bias', 'model.encoder.layers.3.self_attn.longformer_self_attn.query_global.bias', 'model.decoder.layers.2.encoder_attn.k_proj.bias', 'model.decoder.layers.5.fc2.bias', 'model.encoder.layers.2.self_attn.longformer_self_attn.value_global.weight', 'model.encoder.layers.2.self_attn_layer_norm.weight']\n",
      "- This IS expected if you are initializing TFLongformerModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFLongformerModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFLongformerModel were not initialized from the PyTorch model and are newly initialized: ['embeddings.word_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.position_embeddings.weight', 'embeddings.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.query_global.weight', 'encoder.layer.0.attention.self.query_global.bias', 'encoder.layer.0.attention.self.key_global.weight', 'encoder.layer.0.attention.self.key_global.bias', 'encoder.layer.0.attention.self.value_global.weight', 'encoder.layer.0.attention.self.value_global.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.query_global.weight', 'encoder.layer.1.attention.self.query_global.bias', 'encoder.layer.1.attention.self.key_global.weight', 'encoder.layer.1.attention.self.key_global.bias', 'encoder.layer.1.attention.self.value_global.weight', 'encoder.layer.1.attention.self.value_global.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.query_global.weight', 'encoder.layer.2.attention.self.query_global.bias', 'encoder.layer.2.attention.self.key_global.weight', 'encoder.layer.2.attention.self.key_global.bias', 'encoder.layer.2.attention.self.value_global.weight', 'encoder.layer.2.attention.self.value_global.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.query_global.weight', 'encoder.layer.3.attention.self.query_global.bias', 'encoder.layer.3.attention.self.key_global.weight', 'encoder.layer.3.attention.self.key_global.bias', 'encoder.layer.3.attention.self.value_global.weight', 'encoder.layer.3.attention.self.value_global.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.query_global.weight', 'encoder.layer.4.attention.self.query_global.bias', 'encoder.layer.4.attention.self.key_global.weight', 'encoder.layer.4.attention.self.key_global.bias', 'encoder.layer.4.attention.self.value_global.weight', 'encoder.layer.4.attention.self.value_global.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.query_global.weight', 'encoder.layer.5.attention.self.query_global.bias', 'encoder.layer.5.attention.self.key_global.weight', 'encoder.layer.5.attention.self.key_global.bias', 'encoder.layer.5.attention.self.value_global.weight', 'encoder.layer.5.attention.self.value_global.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'pooler.dense.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFLongformerModel: ['model.encoder.layers.5.self_attn.output.weight', 'model.decoder.layers.2.self_attn_layer_norm.weight', 'model.encoder.layers.5.self_attn.longformer_self_attn.key.bias', 'model.encoder.embed_tokens.weight', 'model.decoder.layers.0.self_attn_layer_norm.bias', 'model.decoder.layers.0.self_attn.out_proj.bias', 'model.encoder.layers.2.self_attn.longformer_self_attn.query_global.weight', 'model.encoder.layers.3.self_attn.longformer_self_attn.value_global.bias', 'model.decoder.layers.3.final_layer_norm.weight', 'model.encoder.layers.3.self_attn.longformer_self_attn.query.weight', 'model.decoder.layers.1.encoder_attn.k_proj.bias', 'model.decoder.layers.4.self_attn.out_proj.weight', 'model.decoder.layers.1.self_attn.k_proj.bias', 'model.decoder.layers.3.self_attn.k_proj.bias', 'model.decoder.layers.5.fc1.weight', 'model.decoder.layers.5.encoder_attn_layer_norm.weight', 'model.encoder.layers.5.fc2.weight', 'model.encoder.layers.3.self_attn.output.bias', 'model.encoder.layers.2.self_attn.longformer_self_attn.value.bias', 'model.decoder.layers.1.self_attn_layer_norm.weight', 'model.encoder.layers.0.final_layer_norm.bias', 'model.encoder.layers.0.self_attn.longformer_self_attn.query.bias', 'model.encoder.layers.5.self_attn.longformer_self_attn.value_global.bias', 'model.encoder.layers.4.self_attn_layer_norm.bias', 'model.encoder.layers.3.final_layer_norm.weight', 'model.decoder.layers.5.final_layer_norm.bias', 'model.decoder.layers.3.encoder_attn.v_proj.bias', 'model.decoder.layers.0.encoder_attn_layer_norm.weight', 'model.encoder.layers.0.self_attn.longformer_self_attn.query_global.weight', 'model.encoder.layers.2.self_attn.longformer_self_attn.query.weight', 'model.decoder.layers.1.final_layer_norm.weight', 'model.decoder.layers.4.fc2.bias', 'model.encoder.layers.2.self_attn_layer_norm.bias', 'model.encoder.layers.1.self_attn.output.bias', 'model.decoder.layers.2.fc2.bias', 'model.decoder.layers.5.encoder_attn_layer_norm.bias', 'model.decoder.layers.1.encoder_attn.v_proj.bias', 'model.decoder.layers.4.encoder_attn_layer_norm.bias', 'model.decoder.layers.1.fc1.bias', 'model.decoder.layers.2.encoder_attn.out_proj.weight', 'model.decoder.layers.3.self_attn.q_proj.weight', 'model.encoder.layers.3.final_layer_norm.bias', 'model.decoder.layers.2.fc2.weight', 'model.encoder.layers.1.fc1.weight', 'model.decoder.layers.3.encoder_attn.v_proj.weight', 'model.decoder.layers.5.encoder_attn.v_proj.bias', 'model.encoder.layers.1.self_attn_layer_norm.weight', 'model.decoder.layers.1.encoder_attn.out_proj.bias', 'model.encoder.layers.5.fc1.weight', 'model.encoder.layers.4.fc2.bias', 'model.decoder.layers.4.self_attn.out_proj.bias', 'model.decoder.layers.5.self_attn.v_proj.weight', 'model.decoder.layers.3.self_attn.out_proj.weight', 'model.decoder.layers.4.fc1.bias', 'model.decoder.layers.3.self_attn_layer_norm.bias', 'model.decoder.embed_positions.weight', 'model.decoder.layers.0.self_attn.k_proj.weight', 'model.encoder.layers.5.self_attn.output.bias', 'model.encoder.layers.1.final_layer_norm.weight', 'model.encoder.layers.0.self_attn_layer_norm.bias', 'model.decoder.layers.1.self_attn.v_proj.bias', 'model.encoder.layers.3.fc2.bias', 'model.decoder.layers.4.fc1.weight', 'model.encoder.layers.5.self_attn.longformer_self_attn.key_global.weight', 'model.decoder.layers.1.encoder_attn.out_proj.weight', 'model.decoder.layers.2.self_attn.out_proj.bias', 'model.decoder.layers.5.self_attn_layer_norm.bias', 'model.decoder.layers.1.encoder_attn_layer_norm.bias', 'model.decoder.layers.1.encoder_attn.k_proj.weight', 'model.encoder.layers.5.fc2.bias', 'model.encoder.layers.3.self_attn.longformer_self_attn.key.bias', 'model.encoder.layers.1.self_attn.longformer_self_attn.query_global.bias', 'model.decoder.layers.2.self_attn.v_proj.weight', 'model.decoder.layers.5.self_attn.q_proj.bias', 'model.shared.weight', 'model.decoder.layers.3.encoder_attn_layer_norm.weight', 'model.encoder.layers.1.self_attn_layer_norm.bias', 'model.encoder.layers.3.self_attn.longformer_self_attn.value_global.weight', 'model.decoder.layers.4.encoder_attn.k_proj.bias', 'model.encoder.layers.4.self_attn.longformer_self_attn.value.weight', 'model.encoder.layers.5.fc1.bias', 'model.decoder.layers.3.fc1.bias', 'model.decoder.layernorm_embedding.weight', 'model.encoder.layers.5.self_attn.longformer_self_attn.query.bias', 'model.encoder.layers.4.self_attn.longformer_self_attn.query.bias', 'model.decoder.layers.5.encoder_attn.q_proj.weight', 'model.decoder.layers.5.self_attn.out_proj.weight', 'model.encoder.layers.0.fc1.bias', 'model.encoder.layers.1.self_attn.longformer_self_attn.query_global.weight', 'model.decoder.layers.1.self_attn.out_proj.bias', 'model.encoder.layers.0.final_layer_norm.weight', 'model.encoder.layers.4.self_attn.longformer_self_attn.value.bias', 'model.encoder.layers.3.fc2.weight', 'model.encoder.layers.4.self_attn.longformer_self_attn.key.bias', 'model.encoder.layers.5.self_attn.longformer_self_attn.query_global.bias', 'model.decoder.layers.2.self_attn.k_proj.weight', 'model.encoder.layers.4.self_attn.longformer_self_attn.value_global.bias', 'model.decoder.layers.2.final_layer_norm.weight', 'model.decoder.layers.3.self_attn.v_proj.weight', 'model.encoder.layers.5.final_layer_norm.weight', 'model.decoder.layers.0.encoder_attn.q_proj.bias', 'model.decoder.layers.1.self_attn.out_proj.weight', 'model.decoder.layers.2.self_attn.q_proj.bias', 'model.decoder.layers.2.encoder_attn.out_proj.bias', 'model.encoder.layers.0.fc1.weight', 'model.encoder.layers.4.self_attn.longformer_self_attn.query_global.weight', 'model.encoder.layers.4.final_layer_norm.weight', 'model.encoder.layers.5.self_attn_layer_norm.bias', 'model.decoder.layers.5.encoder_attn.k_proj.weight', 'model.decoder.layers.4.self_attn.v_proj.weight', 'model.decoder.layers.0.fc2.weight', 'model.encoder.layers.1.final_layer_norm.bias', 'model.decoder.layers.3.self_attn.k_proj.weight', 'model.encoder.layers.4.final_layer_norm.bias', 'model.encoder.layers.4.fc2.weight', 'model.decoder.layers.3.encoder_attn.k_proj.bias', 'model.encoder.layers.3.self_attn_layer_norm.bias', 'model.encoder.layers.4.self_attn.output.bias', 'model.decoder.layers.5.self_attn.q_proj.weight', 'model.decoder.layers.3.final_layer_norm.bias', 'model.decoder.layers.3.encoder_attn.q_proj.weight', 'model.decoder.layers.2.encoder_attn.v_proj.weight', 'model.decoder.layers.4.encoder_attn.q_proj.weight', 'model.decoder.layers.3.encoder_attn.k_proj.weight', 'model.encoder.layers.1.self_attn.longformer_self_attn.value_global.weight', 'model.encoder.layers.0.self_attn.longformer_self_attn.value_global.weight', 'model.encoder.layers.4.self_attn.output.weight', 'model.encoder.layers.4.fc1.bias', 'model.encoder.layers.3.self_attn.longformer_self_attn.query.bias', 'model.encoder.layers.2.self_attn.longformer_self_attn.value_global.bias', 'model.decoder.layers.0.encoder_attn.k_proj.bias', 'model.decoder.layers.2.encoder_attn_layer_norm.bias', 'model.decoder.layers.4.final_layer_norm.weight', 'model.decoder.layers.4.final_layer_norm.bias', 'model.decoder.layers.0.encoder_attn.q_proj.weight', 'model.decoder.layers.5.fc1.bias', 'model.decoder.layers.3.encoder_attn_layer_norm.bias', 'model.encoder.layers.3.self_attn.longformer_self_attn.value.weight', 'model.encoder.layers.4.self_attn.longformer_self_attn.key_global.weight', 'model.encoder.layers.0.self_attn.longformer_self_attn.query.weight', 'model.encoder.layers.0.self_attn.longformer_self_attn.key.weight', 'model.encoder.layers.2.self_attn.output.bias', 'model.encoder.layers.0.self_attn.longformer_self_attn.key_global.bias', 'model.decoder.layers.1.encoder_attn_layer_norm.weight', 'model.encoder.layers.2.self_attn.output.weight', 'model.decoder.layers.3.encoder_attn.q_proj.bias', 'model.decoder.layers.3.fc1.weight', 'model.decoder.layers.5.self_attn_layer_norm.weight', 'model.decoder.layers.0.self_attn.out_proj.weight', 'model.encoder.layers.5.self_attn_layer_norm.weight', 'model.decoder.layers.0.self_attn.v_proj.weight', 'model.encoder.layers.5.self_attn.longformer_self_attn.key_global.bias', 'model.decoder.layers.2.encoder_attn_layer_norm.weight', 'model.encoder.layers.5.self_attn.longformer_self_attn.value_global.weight', 'model.decoder.layers.2.fc1.weight', 'model.decoder.layers.2.encoder_attn.k_proj.weight', 'model.encoder.layers.2.self_attn.longformer_self_attn.key_global.weight', 'model.decoder.layers.4.self_attn_layer_norm.bias', 'model.decoder.layers.4.self_attn.q_proj.weight', 'model.decoder.layernorm_embedding.bias', 'model.encoder.layers.3.fc1.weight', 'model.encoder.layers.4.self_attn.longformer_self_attn.key_global.bias', 'model.decoder.layers.2.encoder_attn.v_proj.bias', 'model.encoder.layers.0.self_attn.longformer_self_attn.query_global.bias', 'model.encoder.layers.0.self_attn.longformer_self_attn.value_global.bias', 'model.decoder.layers.2.encoder_attn.q_proj.bias', 'model.decoder.layers.2.fc1.bias', 'final_logits_bias', 'model.decoder.layers.1.self_attn.q_proj.bias', 'model.decoder.layers.5.encoder_attn.v_proj.weight', 'model.encoder.layers.5.self_attn.longformer_self_attn.key.weight', 'model.encoder.layers.1.fc1.bias', 'model.decoder.layers.1.self_attn.k_proj.weight', 'model.encoder.layers.4.self_attn.longformer_self_attn.query.weight', 'model.decoder.layers.5.self_attn.out_proj.bias', 'model.decoder.layers.0.fc1.bias', 'model.decoder.layers.0.self_attn.q_proj.weight', 'model.decoder.layers.4.encoder_attn.k_proj.weight', 'model.decoder.layers.0.fc1.weight', 'model.decoder.layers.4.encoder_attn_layer_norm.weight', 'model.encoder.layers.2.fc1.weight', 'model.encoder.layers.3.self_attn.longformer_self_attn.key_global.weight', 'model.decoder.layers.3.encoder_attn.out_proj.weight', 'model.encoder.layers.0.self_attn_layer_norm.weight', 'model.decoder.layers.5.encoder_attn.q_proj.bias', 'model.decoder.layers.4.encoder_attn.v_proj.bias', 'model.decoder.layers.1.fc2.weight', 'model.encoder.layers.4.fc1.weight', 'model.decoder.layers.2.self_attn.v_proj.bias', 'model.encoder.layers.3.self_attn.longformer_self_attn.value.bias', 'model.encoder.layers.5.final_layer_norm.bias', 'model.encoder.layers.3.self_attn.longformer_self_attn.query_global.weight', 'model.decoder.layers.1.final_layer_norm.bias', 'model.encoder.layers.2.final_layer_norm.bias', 'model.decoder.layers.5.self_attn.v_proj.bias', 'model.encoder.layers.1.self_attn.longformer_self_attn.value.bias', 'model.decoder.layers.2.self_attn.out_proj.weight', 'model.encoder.layers.2.self_attn.longformer_self_attn.query.bias', 'model.encoder.layers.1.self_attn.longformer_self_attn.value.weight', 'model.decoder.layers.0.final_layer_norm.bias', 'model.decoder.layers.1.encoder_attn.q_proj.bias', 'model.decoder.layers.3.encoder_attn.out_proj.bias', 'model.decoder.layers.4.fc2.weight', 'model.encoder.layers.1.self_attn.longformer_self_attn.key_global.weight', 'model.encoder.layers.0.self_attn.longformer_self_attn.value.weight', 'model.encoder.layers.2.fc1.bias', 'model.decoder.layers.0.self_attn.v_proj.bias', 'model.decoder.layers.0.final_layer_norm.weight', 'model.decoder.layers.2.final_layer_norm.bias', 'model.decoder.layers.4.self_attn.k_proj.bias', 'model.encoder.layers.5.self_attn.longformer_self_attn.query_global.weight', 'model.encoder.layers.1.self_attn.longformer_self_attn.value_global.bias', 'model.encoder.layers.3.self_attn.longformer_self_attn.key_global.bias', 'model.encoder.layers.3.self_attn_layer_norm.weight', 'model.encoder.layers.2.self_attn.longformer_self_attn.key.bias', 'model.encoder.layers.4.self_attn.longformer_self_attn.key.weight', 'model.decoder.layers.4.self_attn.k_proj.weight', 'model.decoder.layers.2.self_attn.k_proj.bias', 'model.decoder.layers.0.self_attn_layer_norm.weight', 'model.decoder.layers.0.encoder_attn_layer_norm.bias', 'model.encoder.layers.2.self_attn.longformer_self_attn.query_global.bias', 'model.decoder.layers.5.encoder_attn.out_proj.weight', 'model.decoder.layers.3.self_attn.out_proj.bias', 'model.encoder.embed_positions.weight', 'model.decoder.layers.0.encoder_attn.out_proj.bias', 'model.decoder.layers.5.fc2.weight', 'model.decoder.layers.3.fc2.bias', 'model.decoder.layers.5.encoder_attn.k_proj.bias', 'model.decoder.layers.1.encoder_attn.v_proj.weight', 'model.encoder.layers.0.fc2.weight', 'model.decoder.layers.2.encoder_attn.q_proj.weight', 'model.decoder.layers.3.self_attn_layer_norm.weight', 'model.decoder.layers.3.fc2.weight', 'model.decoder.layers.5.self_attn.k_proj.weight', 'model.decoder.layers.0.fc2.bias', 'model.encoder.layers.1.self_attn.output.weight', 'model.encoder.layers.1.fc2.bias', 'model.encoder.layers.5.self_attn.longformer_self_attn.value.weight', 'model.encoder.layers.5.self_attn.longformer_self_attn.value.bias', 'model.decoder.layers.0.encoder_attn.v_proj.bias', 'model.decoder.layers.1.fc2.bias', 'model.decoder.layers.4.self_attn.v_proj.bias', 'model.decoder.layers.4.self_attn_layer_norm.weight', 'model.decoder.layers.5.final_layer_norm.weight', 'model.decoder.layers.2.self_attn_layer_norm.bias', 'model.encoder.layers.2.fc2.weight', 'model.encoder.layers.2.self_attn.longformer_self_attn.value.weight', 'model.decoder.layers.1.fc1.weight', 'model.decoder.layers.4.encoder_attn.out_proj.weight', 'model.encoder.layers.3.self_attn.longformer_self_attn.key.weight', 'model.decoder.layers.0.encoder_attn.v_proj.weight', 'model.encoder.layers.1.self_attn.longformer_self_attn.key.weight', 'model.encoder.layers.1.self_attn.longformer_self_attn.key.bias', 'model.encoder.layers.1.self_attn.longformer_self_attn.key_global.bias', 'model.encoder.layers.2.self_attn.longformer_self_attn.key.weight', 'model.encoder.layernorm_embedding.weight', 'model.encoder.layers.0.self_attn.longformer_self_attn.key_global.weight', 'model.encoder.layernorm_embedding.bias', 'model.encoder.layers.3.fc1.bias', 'model.decoder.layers.0.encoder_attn.out_proj.weight', 'model.decoder.layers.1.self_attn.v_proj.weight', 'model.encoder.layers.1.fc2.weight', 'model.encoder.layers.4.self_attn_layer_norm.weight', 'model.decoder.layers.0.encoder_attn.k_proj.weight', 'model.decoder.layers.1.self_attn.q_proj.weight', 'model.decoder.layers.1.self_attn_layer_norm.bias', 'model.decoder.embed_tokens.weight', 'model.decoder.layers.5.encoder_attn.out_proj.bias', 'model.encoder.layers.0.self_attn.output.bias', 'model.decoder.layers.4.encoder_attn.v_proj.weight', 'model.decoder.layers.3.self_attn.v_proj.bias', 'model.encoder.layers.4.self_attn.longformer_self_attn.value_global.weight', 'model.decoder.layers.1.encoder_attn.q_proj.weight', 'model.encoder.layers.1.self_attn.longformer_self_attn.query.weight', 'model.encoder.layers.2.self_attn.longformer_self_attn.key_global.bias', 'model.encoder.layers.3.self_attn.output.weight', 'model.encoder.layers.2.fc2.bias', 'model.encoder.layers.4.self_attn.longformer_self_attn.query_global.bias', 'model.decoder.layers.4.self_attn.q_proj.bias', 'model.decoder.layers.4.encoder_attn.q_proj.bias', 'model.decoder.layers.2.self_attn.q_proj.weight', 'model.decoder.layers.0.self_attn.q_proj.bias', 'model.decoder.layers.4.encoder_attn.out_proj.bias', 'model.encoder.layers.0.self_attn.longformer_self_attn.key.bias', 'model.encoder.layers.1.self_attn.longformer_self_attn.query.bias', 'model.decoder.layers.3.self_attn.q_proj.bias', 'model.decoder.layers.5.self_attn.k_proj.bias', 'model.encoder.layers.0.fc2.bias', 'model.encoder.layers.0.self_attn.output.weight', 'model.encoder.layers.2.final_layer_norm.weight', 'model.encoder.layers.0.self_attn.longformer_self_attn.value.bias', 'model.encoder.layers.5.self_attn.longformer_self_attn.query.weight', 'model.decoder.layers.0.self_attn.k_proj.bias', 'model.encoder.layers.3.self_attn.longformer_self_attn.query_global.bias', 'model.decoder.layers.2.encoder_attn.k_proj.bias', 'model.decoder.layers.5.fc2.bias', 'model.encoder.layers.2.self_attn.longformer_self_attn.value_global.weight', 'model.encoder.layers.2.self_attn_layer_norm.weight']\n",
      "- This IS expected if you are initializing TFLongformerModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFLongformerModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFLongformerModel were not initialized from the PyTorch model and are newly initialized: ['embeddings.word_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.position_embeddings.weight', 'embeddings.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.query_global.weight', 'encoder.layer.0.attention.self.query_global.bias', 'encoder.layer.0.attention.self.key_global.weight', 'encoder.layer.0.attention.self.key_global.bias', 'encoder.layer.0.attention.self.value_global.weight', 'encoder.layer.0.attention.self.value_global.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.query_global.weight', 'encoder.layer.1.attention.self.query_global.bias', 'encoder.layer.1.attention.self.key_global.weight', 'encoder.layer.1.attention.self.key_global.bias', 'encoder.layer.1.attention.self.value_global.weight', 'encoder.layer.1.attention.self.value_global.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.query_global.weight', 'encoder.layer.2.attention.self.query_global.bias', 'encoder.layer.2.attention.self.key_global.weight', 'encoder.layer.2.attention.self.key_global.bias', 'encoder.layer.2.attention.self.value_global.weight', 'encoder.layer.2.attention.self.value_global.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.query_global.weight', 'encoder.layer.3.attention.self.query_global.bias', 'encoder.layer.3.attention.self.key_global.weight', 'encoder.layer.3.attention.self.key_global.bias', 'encoder.layer.3.attention.self.value_global.weight', 'encoder.layer.3.attention.self.value_global.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.query_global.weight', 'encoder.layer.4.attention.self.query_global.bias', 'encoder.layer.4.attention.self.key_global.weight', 'encoder.layer.4.attention.self.key_global.bias', 'encoder.layer.4.attention.self.value_global.weight', 'encoder.layer.4.attention.self.value_global.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.query_global.weight', 'encoder.layer.5.attention.self.query_global.bias', 'encoder.layer.5.attention.self.key_global.weight', 'encoder.layer.5.attention.self.key_global.bias', 'encoder.layer.5.attention.self.value_global.weight', 'encoder.layer.5.attention.self.value_global.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'pooler.dense.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_longformer_model/longformer/pooler/dense/kernel:0', 'tf_longformer_model/longformer/pooler/dense/bias:0', 'tf_longformer_model_1/longformer/pooler/dense/kernel:0', 'tf_longformer_model_1/longformer/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_longformer_model/longformer/pooler/dense/kernel:0', 'tf_longformer_model/longformer/pooler/dense/bias:0', 'tf_longformer_model_1/longformer/pooler/dense/kernel:0', 'tf_longformer_model_1/longformer/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_longformer_model/longformer/pooler/dense/kernel:0', 'tf_longformer_model/longformer/pooler/dense/bias:0', 'tf_longformer_model_1/longformer/pooler/dense/kernel:0', 'tf_longformer_model_1/longformer/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_longformer_model/longformer/pooler/dense/kernel:0', 'tf_longformer_model/longformer/pooler/dense/bias:0', 'tf_longformer_model_1/longformer/pooler/dense/kernel:0', 'tf_longformer_model_1/longformer/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    }
   ],
   "source": [
    "model = dual_longformer()\n",
    "history = model.fit(input_train, y_train, epochs=4, batch_size=2, validation_data=(input_test, y_test),\n",
    "    verbose=1,callbacks=[SavePretrainedCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "if 'val_loss' in history.history:\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 76.528347,
     "end_time": "2021-04-14T23:46:01.604933",
     "exception": false,
     "start_time": "2021-04-14T23:44:45.076586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### PREDICT TEST ###\n",
    "\n",
    "pred_test = np.argmax(model.predict(input_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 1.982288,
     "end_time": "2021-04-14T23:46:05.990713",
     "exception": false,
     "start_time": "2021-04-14T23:46:04.008425",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(classification_report([map_label[i] for i in y_test], [map_label[i] for i in pred_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 2.28804,
     "end_time": "2021-04-14T23:46:10.239381",
     "exception": false,
     "start_time": "2021-04-14T23:46:07.951341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix([map_label[i] for i in y_test], \n",
    "                              [map_label[i] for i in pred_test])\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "plot_confusion_matrix(cnf_matrix, classes=list(map_label.values()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 1.968644,
     "end_time": "2021-04-14T23:46:14.458594",
     "exception": false,
     "start_time": "2021-04-14T23:46:12.489950",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **SIAMESE BERT (TWO INPUT)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 1.950003,
     "end_time": "2021-04-14T23:46:18.395610",
     "exception": false,
     "start_time": "2021-04-14T23:46:16.445607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def siamese_longformer():\n",
    "    \n",
    "    set_seed(33)\n",
    "    \n",
    "    opt = Adam(learning_rate=2e-5)\n",
    "    \n",
    "    id1 = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n",
    "    id2 = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n",
    "    \n",
    "    mask1 = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n",
    "    mask2 = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n",
    "    \n",
    "    atn1 = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n",
    "    atn2 = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n",
    "    \n",
    "    config = LongformerConfig()\n",
    "    config.output_hidden_states = False # Set to True to obtain hidden states\n",
    "    \n",
    "    tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "\n",
    "    with tf.device('/GPU:0'):\n",
    "        longformer_model = TFLongformerModel.from_pretrained(MODEL_NAME,from_pt=True, config=config)\n",
    "\n",
    "    embedding1 = longformer_model(id1, attention_mask=mask1, token_type_ids=atn1)[0]\n",
    "    embedding2 = longformer_model(id2, attention_mask=mask2, token_type_ids=atn2)[0]\n",
    "    \n",
    "    x1 = GlobalAveragePooling1D()(embedding1)\n",
    "    x2 = GlobalAveragePooling1D()(embedding2)\n",
    "    \n",
    "    x = Concatenate()([x1, x2])\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    out = Dense(len(map_label), activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=[id1, mask1, atn1, id2, mask2, atn2], outputs=out)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=opt)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 15:20:12.567041: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-14 15:20:12.567304: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-14 15:20:12.567339: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-14 15:20:12.964738: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-14 15:20:12.964898: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-14 15:20:12.964935: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-11-14 15:20:12.964990: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-14 15:20:12.965237: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5535 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2024-11-14 15:20:14.347112: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFLongformerModel: ['model.encoder.layers.5.self_attn.longformer_self_attn.key.weight', 'model.encoder.layers.3.self_attn.longformer_self_attn.value_global.weight', 'model.encoder.layers.3.self_attn.longformer_self_attn.value.bias', 'model.decoder.layers.5.fc1.bias', 'model.encoder.layers.3.self_attn.longformer_self_attn.query_global.bias', 'model.decoder.layers.4.self_attn_layer_norm.weight', 'final_logits_bias', 'model.decoder.layers.2.self_attn.v_proj.bias', 'model.decoder.layers.5.encoder_attn.k_proj.bias', 'model.decoder.layers.2.fc1.weight', 'model.decoder.layers.1.encoder_attn.q_proj.bias', 'model.encoder.layers.2.fc1.weight', 'model.decoder.layers.2.encoder_attn.out_proj.weight', 'model.decoder.layers.0.self_attn.out_proj.weight', 'model.encoder.layers.2.self_attn.longformer_self_attn.value.weight', 'model.encoder.layers.0.self_attn.longformer_self_attn.key.weight', 'model.decoder.layers.0.self_attn_layer_norm.bias', 'model.decoder.layers.2.final_layer_norm.bias', 'model.decoder.layers.3.self_attn.k_proj.weight', 'model.decoder.layers.5.final_layer_norm.bias', 'model.encoder.layers.1.final_layer_norm.bias', 'model.decoder.layers.3.self_attn.v_proj.bias', 'model.decoder.layers.0.encoder_attn_layer_norm.bias', 'model.decoder.layers.2.fc2.weight', 'model.decoder.layers.2.self_attn_layer_norm.bias', 'model.encoder.layers.3.self_attn.longformer_self_attn.value_global.bias', 'model.encoder.layers.5.self_attn.longformer_self_attn.value.weight', 'model.decoder.layers.1.fc1.weight', 'model.decoder.layers.5.encoder_attn.q_proj.bias', 'model.decoder.layers.0.fc1.weight', 'model.decoder.layers.2.encoder_attn.v_proj.weight', 'model.decoder.layers.0.self_attn.q_proj.bias', 'model.decoder.layers.0.encoder_attn.v_proj.weight', 'model.decoder.layers.4.self_attn.k_proj.bias', 'model.encoder.layers.1.fc1.bias', 'model.decoder.layers.2.encoder_attn.q_proj.weight', 'model.encoder.layers.4.final_layer_norm.weight', 'model.encoder.layers.5.fc2.weight', 'model.decoder.layers.5.fc1.weight', 'model.encoder.layers.0.self_attn.longformer_self_attn.query.weight', 'model.decoder.layers.4.encoder_attn_layer_norm.bias', 'model.encoder.layernorm_embedding.bias', 'model.shared.weight', 'model.encoder.embed_tokens.weight', 'model.encoder.layers.0.self_attn_layer_norm.bias', 'model.encoder.layers.3.self_attn.longformer_self_attn.key.weight', 'model.decoder.layers.2.encoder_attn_layer_norm.bias', 'model.decoder.layers.4.self_attn.v_proj.weight', 'model.decoder.layernorm_embedding.weight', 'model.decoder.layers.0.encoder_attn_layer_norm.weight', 'model.decoder.layers.2.self_attn.k_proj.weight', 'model.decoder.layers.3.self_attn.k_proj.bias', 'model.encoder.layers.0.self_attn.longformer_self_attn.key_global.weight', 'model.encoder.layers.0.self_attn.output.bias', 'model.encoder.layers.5.self_attn.longformer_self_attn.value_global.weight', 'model.encoder.layers.5.self_attn_layer_norm.bias', 'model.decoder.layers.5.fc2.bias', 'model.decoder.layers.0.fc2.weight', 'model.decoder.layers.3.self_attn.q_proj.bias', 'model.decoder.layers.3.encoder_attn.q_proj.weight', 'model.encoder.layers.5.self_attn.longformer_self_attn.query.weight', 'model.encoder.layers.2.self_attn.longformer_self_attn.query_global.weight', 'model.encoder.layers.4.self_attn.longformer_self_attn.query.bias', 'model.decoder.layers.0.final_layer_norm.weight', 'model.decoder.layers.4.fc2.weight', 'model.decoder.layers.2.encoder_attn.k_proj.weight', 'model.encoder.layers.2.self_attn.output.bias', 'model.encoder.layers.0.self_attn_layer_norm.weight', 'model.decoder.layers.4.encoder_attn.out_proj.bias', 'model.encoder.layers.0.self_attn.longformer_self_attn.key_global.bias', 'model.encoder.layers.0.fc1.weight', 'model.decoder.layers.1.self_attn.q_proj.bias', 'model.decoder.layers.0.self_attn.k_proj.bias', 'model.decoder.layers.5.self_attn.out_proj.bias', 'model.encoder.layers.0.fc2.bias', 'model.encoder.layers.5.self_attn.longformer_self_attn.key_global.weight', 'model.encoder.layers.2.self_attn.longformer_self_attn.key.weight', 'model.decoder.layers.4.final_layer_norm.weight', 'model.decoder.layers.5.self_attn.v_proj.weight', 'model.encoder.layers.2.final_layer_norm.weight', 'model.decoder.layers.3.fc2.weight', 'model.encoder.layers.3.fc2.weight', 'model.decoder.layers.2.self_attn.out_proj.bias', 'model.encoder.layers.4.fc2.weight', 'model.encoder.layers.3.self_attn.output.bias', 'model.decoder.layers.2.self_attn.q_proj.weight', 'model.decoder.layers.5.self_attn.q_proj.weight', 'model.encoder.layers.2.self_attn_layer_norm.bias', 'model.encoder.layers.2.self_attn.longformer_self_attn.query_global.bias', 'model.decoder.layers.5.self_attn.v_proj.bias', 'model.encoder.layers.5.fc1.weight', 'model.encoder.layers.1.self_attn.longformer_self_attn.key.bias', 'model.decoder.layers.2.self_attn.out_proj.weight', 'model.encoder.layers.5.fc2.bias', 'model.encoder.layers.0.self_attn.longformer_self_attn.value.weight', 'model.encoder.layers.0.fc2.weight', 'model.decoder.layers.0.encoder_attn.q_proj.weight', 'model.encoder.layers.5.self_attn.longformer_self_attn.value.bias', 'model.decoder.layernorm_embedding.bias', 'model.decoder.layers.1.final_layer_norm.bias', 'model.decoder.embed_tokens.weight', 'model.encoder.layernorm_embedding.weight', 'model.decoder.layers.2.fc2.bias', 'model.encoder.layers.2.self_attn_layer_norm.weight', 'model.decoder.layers.3.self_attn_layer_norm.weight', 'model.encoder.layers.2.self_attn.longformer_self_attn.value_global.bias', 'model.decoder.layers.3.encoder_attn.k_proj.weight', 'model.decoder.layers.0.encoder_attn.v_proj.bias', 'model.decoder.layers.4.self_attn.q_proj.weight', 'model.decoder.layers.4.fc1.weight', 'model.decoder.layers.5.self_attn.k_proj.weight', 'model.encoder.layers.1.self_attn.longformer_self_attn.key_global.bias', 'model.encoder.layers.3.final_layer_norm.bias', 'model.encoder.layers.2.fc2.weight', 'model.decoder.layers.0.encoder_attn.out_proj.bias', 'model.encoder.layers.3.self_attn.longformer_self_attn.key_global.bias', 'model.decoder.layers.5.encoder_attn.v_proj.bias', 'model.encoder.layers.1.self_attn.longformer_self_attn.value_global.bias', 'model.decoder.layers.0.encoder_attn.out_proj.weight', 'model.decoder.layers.0.final_layer_norm.bias', 'model.decoder.layers.2.self_attn.q_proj.bias', 'model.decoder.layers.5.encoder_attn.v_proj.weight', 'model.decoder.layers.2.encoder_attn.v_proj.bias', 'model.decoder.layers.2.self_attn.k_proj.bias', 'model.decoder.layers.5.encoder_attn_layer_norm.weight', 'model.encoder.layers.4.self_attn.longformer_self_attn.value.weight', 'model.encoder.layers.2.self_attn.longformer_self_attn.query.bias', 'model.encoder.layers.3.self_attn_layer_norm.bias', 'model.encoder.layers.0.self_attn.longformer_self_attn.value_global.bias', 'model.decoder.layers.5.self_attn_layer_norm.bias', 'model.decoder.layers.1.self_attn_layer_norm.weight', 'model.encoder.layers.4.self_attn.longformer_self_attn.key.weight', 'model.encoder.layers.3.self_attn_layer_norm.weight', 'model.decoder.layers.1.self_attn.q_proj.weight', 'model.decoder.layers.3.self_attn.out_proj.bias', 'model.encoder.layers.3.self_attn.longformer_self_attn.query_global.weight', 'model.decoder.layers.5.final_layer_norm.weight', 'model.decoder.layers.5.encoder_attn.k_proj.weight', 'model.decoder.layers.1.self_attn.out_proj.weight', 'model.decoder.layers.4.self_attn.v_proj.bias', 'model.encoder.layers.1.self_attn.longformer_self_attn.query_global.weight', 'model.encoder.layers.3.self_attn.longformer_self_attn.query.bias', 'model.decoder.layers.1.encoder_attn.out_proj.weight', 'model.decoder.layers.1.encoder_attn.out_proj.bias', 'model.encoder.layers.1.fc2.weight', 'model.encoder.layers.1.self_attn_layer_norm.bias', 'model.encoder.layers.2.self_attn.longformer_self_attn.value_global.weight', 'model.decoder.layers.2.encoder_attn.out_proj.bias', 'model.decoder.layers.3.self_attn.out_proj.weight', 'model.decoder.layers.1.self_attn.v_proj.bias', 'model.encoder.layers.5.self_attn.output.weight', 'model.decoder.layers.0.self_attn_layer_norm.weight', 'model.decoder.layers.3.final_layer_norm.weight', 'model.encoder.layers.2.self_attn.longformer_self_attn.value.bias', 'model.encoder.layers.3.self_attn.longformer_self_attn.query.weight', 'model.decoder.layers.3.encoder_attn_layer_norm.weight', 'model.decoder.layers.1.fc1.bias', 'model.decoder.layers.2.self_attn.v_proj.weight', 'model.encoder.layers.4.self_attn.longformer_self_attn.key_global.bias', 'model.encoder.layers.5.self_attn.longformer_self_attn.value_global.bias', 'model.decoder.layers.0.self_attn.v_proj.weight', 'model.encoder.layers.4.self_attn.longformer_self_attn.key_global.weight', 'model.decoder.layers.1.encoder_attn_layer_norm.bias', 'model.encoder.layers.1.self_attn.output.bias', 'model.encoder.layers.4.self_attn.longformer_self_attn.value_global.weight', 'model.decoder.layers.2.fc1.bias', 'model.encoder.layers.1.self_attn_layer_norm.weight', 'model.decoder.layers.4.fc2.bias', 'model.decoder.layers.5.self_attn.q_proj.bias', 'model.decoder.layers.0.self_attn.q_proj.weight', 'model.encoder.layers.5.self_attn.longformer_self_attn.query_global.bias', 'model.decoder.layers.4.encoder_attn.v_proj.weight', 'model.decoder.layers.5.encoder_attn.out_proj.bias', 'model.decoder.layers.4.encoder_attn.k_proj.weight', 'model.encoder.layers.0.self_attn.longformer_self_attn.query_global.weight', 'model.decoder.layers.0.encoder_attn.k_proj.weight', 'model.encoder.layers.4.self_attn_layer_norm.weight', 'model.encoder.layers.1.self_attn.longformer_self_attn.key.weight', 'model.decoder.layers.3.encoder_attn.v_proj.weight', 'model.decoder.layers.5.encoder_attn.q_proj.weight', 'model.decoder.layers.1.encoder_attn.q_proj.weight', 'model.decoder.layers.4.self_attn.q_proj.bias', 'model.encoder.layers.2.fc2.bias', 'model.encoder.layers.4.fc2.bias', 'model.decoder.layers.0.fc2.bias', 'model.decoder.layers.0.self_attn.out_proj.bias', 'model.decoder.layers.1.final_layer_norm.weight', 'model.decoder.layers.3.fc2.bias', 'model.encoder.layers.5.self_attn_layer_norm.weight', 'model.encoder.layers.1.self_attn.longformer_self_attn.key_global.weight', 'model.decoder.layers.4.final_layer_norm.bias', 'model.encoder.layers.4.final_layer_norm.bias', 'model.encoder.layers.2.final_layer_norm.bias', 'model.decoder.layers.4.self_attn.k_proj.weight', 'model.decoder.layers.2.final_layer_norm.weight', 'model.decoder.layers.3.self_attn_layer_norm.bias', 'model.decoder.embed_positions.weight', 'model.decoder.layers.5.self_attn.k_proj.bias', 'model.encoder.layers.3.final_layer_norm.weight', 'model.encoder.layers.3.self_attn.longformer_self_attn.value.weight', 'model.encoder.layers.4.self_attn.longformer_self_attn.value.bias', 'model.encoder.layers.0.fc1.bias', 'model.encoder.layers.5.self_attn.longformer_self_attn.query_global.weight', 'model.encoder.layers.5.fc1.bias', 'model.decoder.layers.4.self_attn.out_proj.weight', 'model.decoder.layers.4.encoder_attn.q_proj.bias', 'model.encoder.layers.3.self_attn.longformer_self_attn.key.bias', 'model.encoder.layers.5.self_attn.longformer_self_attn.query.bias', 'model.decoder.layers.2.encoder_attn.k_proj.bias', 'model.encoder.layers.0.self_attn.output.weight', 'model.decoder.layers.4.self_attn_layer_norm.bias', 'model.decoder.layers.2.encoder_attn_layer_norm.weight', 'model.encoder.layers.3.self_attn.longformer_self_attn.key_global.weight', 'model.decoder.layers.3.self_attn.q_proj.weight', 'model.encoder.layers.1.self_attn.longformer_self_attn.query_global.bias', 'model.encoder.layers.1.self_attn.longformer_self_attn.value.bias', 'model.encoder.layers.4.self_attn_layer_norm.bias', 'model.encoder.layers.4.fc1.bias', 'model.decoder.layers.0.fc1.bias', 'model.encoder.layers.1.final_layer_norm.weight', 'model.decoder.layers.1.self_attn.out_proj.bias', 'model.encoder.layers.1.fc2.bias', 'model.encoder.layers.1.self_attn.longformer_self_attn.value.weight', 'model.encoder.layers.4.self_attn.longformer_self_attn.value_global.bias', 'model.decoder.layers.0.self_attn.v_proj.bias', 'model.encoder.layers.2.fc1.bias', 'model.decoder.layers.1.encoder_attn.v_proj.weight', 'model.decoder.layers.2.self_attn_layer_norm.weight', 'model.decoder.layers.3.self_attn.v_proj.weight', 'model.decoder.layers.4.fc1.bias', 'model.decoder.layers.5.encoder_attn_layer_norm.bias', 'model.encoder.layers.2.self_attn.longformer_self_attn.key.bias', 'model.decoder.layers.4.self_attn.out_proj.bias', 'model.decoder.layers.1.self_attn_layer_norm.bias', 'model.encoder.layers.1.self_attn.longformer_self_attn.value_global.weight', 'model.decoder.layers.3.fc1.weight', 'model.encoder.layers.0.final_layer_norm.weight', 'model.decoder.layers.5.self_attn.out_proj.weight', 'model.encoder.layers.0.self_attn.longformer_self_attn.key.bias', 'model.decoder.layers.5.encoder_attn.out_proj.weight', 'model.decoder.layers.3.encoder_attn.out_proj.weight', 'model.encoder.layers.1.self_attn.longformer_self_attn.query.bias', 'model.decoder.layers.4.encoder_attn.q_proj.weight', 'model.encoder.layers.0.self_attn.longformer_self_attn.query_global.bias', 'model.decoder.layers.3.encoder_attn_layer_norm.bias', 'model.encoder.layers.1.fc1.weight', 'model.encoder.layers.0.self_attn.longformer_self_attn.value.bias', 'model.encoder.layers.1.self_attn.output.weight', 'model.encoder.layers.4.self_attn.output.weight', 'model.encoder.embed_positions.weight', 'model.encoder.layers.0.self_attn.longformer_self_attn.value_global.weight', 'model.decoder.layers.0.self_attn.k_proj.weight', 'model.decoder.layers.1.encoder_attn.v_proj.bias', 'model.decoder.layers.1.fc2.bias', 'model.decoder.layers.0.encoder_attn.k_proj.bias', 'model.encoder.layers.3.fc1.bias', 'model.decoder.layers.1.encoder_attn_layer_norm.weight', 'model.decoder.layers.1.fc2.weight', 'model.decoder.layers.2.encoder_attn.q_proj.bias', 'model.encoder.layers.5.self_attn.longformer_self_attn.key_global.bias', 'model.decoder.layers.3.encoder_attn.q_proj.bias', 'model.decoder.layers.4.encoder_attn.k_proj.bias', 'model.encoder.layers.2.self_attn.longformer_self_attn.query.weight', 'model.decoder.layers.0.encoder_attn.q_proj.bias', 'model.decoder.layers.3.final_layer_norm.bias', 'model.decoder.layers.4.encoder_attn.out_proj.weight', 'model.encoder.layers.5.final_layer_norm.weight', 'model.decoder.layers.1.self_attn.v_proj.weight', 'model.encoder.layers.3.self_attn.output.weight', 'model.encoder.layers.0.final_layer_norm.bias', 'model.decoder.layers.3.encoder_attn.k_proj.bias', 'model.decoder.layers.4.encoder_attn.v_proj.bias', 'model.encoder.layers.5.self_attn.output.bias', 'model.encoder.layers.0.self_attn.longformer_self_attn.query.bias', 'model.encoder.layers.4.fc1.weight', 'model.encoder.layers.1.self_attn.longformer_self_attn.query.weight', 'model.encoder.layers.4.self_attn.longformer_self_attn.key.bias', 'model.encoder.layers.4.self_attn.longformer_self_attn.query_global.bias', 'model.decoder.layers.4.encoder_attn_layer_norm.weight', 'model.encoder.layers.5.final_layer_norm.bias', 'model.decoder.layers.1.self_attn.k_proj.weight', 'model.encoder.layers.5.self_attn.longformer_self_attn.key.bias', 'model.encoder.layers.3.fc1.weight', 'model.decoder.layers.3.encoder_attn.out_proj.bias', 'model.encoder.layers.4.self_attn.output.bias', 'model.decoder.layers.3.fc1.bias', 'model.decoder.layers.5.self_attn_layer_norm.weight', 'model.decoder.layers.1.encoder_attn.k_proj.bias', 'model.encoder.layers.2.self_attn.output.weight', 'model.encoder.layers.2.self_attn.longformer_self_attn.key_global.weight', 'model.encoder.layers.3.fc2.bias', 'model.decoder.layers.1.encoder_attn.k_proj.weight', 'model.decoder.layers.5.fc2.weight', 'model.encoder.layers.4.self_attn.longformer_self_attn.query_global.weight', 'model.encoder.layers.2.self_attn.longformer_self_attn.key_global.bias', 'model.decoder.layers.1.self_attn.k_proj.bias', 'model.decoder.layers.3.encoder_attn.v_proj.bias', 'model.encoder.layers.4.self_attn.longformer_self_attn.query.weight']\n",
      "- This IS expected if you are initializing TFLongformerModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFLongformerModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFLongformerModel were not initialized from the PyTorch model and are newly initialized: ['embeddings.word_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.position_embeddings.weight', 'embeddings.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.query_global.weight', 'encoder.layer.0.attention.self.query_global.bias', 'encoder.layer.0.attention.self.key_global.weight', 'encoder.layer.0.attention.self.key_global.bias', 'encoder.layer.0.attention.self.value_global.weight', 'encoder.layer.0.attention.self.value_global.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.query_global.weight', 'encoder.layer.1.attention.self.query_global.bias', 'encoder.layer.1.attention.self.key_global.weight', 'encoder.layer.1.attention.self.key_global.bias', 'encoder.layer.1.attention.self.value_global.weight', 'encoder.layer.1.attention.self.value_global.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.query_global.weight', 'encoder.layer.2.attention.self.query_global.bias', 'encoder.layer.2.attention.self.key_global.weight', 'encoder.layer.2.attention.self.key_global.bias', 'encoder.layer.2.attention.self.value_global.weight', 'encoder.layer.2.attention.self.value_global.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.query_global.weight', 'encoder.layer.3.attention.self.query_global.bias', 'encoder.layer.3.attention.self.key_global.weight', 'encoder.layer.3.attention.self.key_global.bias', 'encoder.layer.3.attention.self.value_global.weight', 'encoder.layer.3.attention.self.value_global.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.query_global.weight', 'encoder.layer.4.attention.self.query_global.bias', 'encoder.layer.4.attention.self.key_global.weight', 'encoder.layer.4.attention.self.key_global.bias', 'encoder.layer.4.attention.self.value_global.weight', 'encoder.layer.4.attention.self.value_global.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.query_global.weight', 'encoder.layer.5.attention.self.query_global.bias', 'encoder.layer.5.attention.self.key_global.weight', 'encoder.layer.5.attention.self.key_global.bias', 'encoder.layer.5.attention.self.value_global.weight', 'encoder.layer.5.attention.self.value_global.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.query_global.weight', 'encoder.layer.6.attention.self.query_global.bias', 'encoder.layer.6.attention.self.key_global.weight', 'encoder.layer.6.attention.self.key_global.bias', 'encoder.layer.6.attention.self.value_global.weight', 'encoder.layer.6.attention.self.value_global.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.query_global.weight', 'encoder.layer.7.attention.self.query_global.bias', 'encoder.layer.7.attention.self.key_global.weight', 'encoder.layer.7.attention.self.key_global.bias', 'encoder.layer.7.attention.self.value_global.weight', 'encoder.layer.7.attention.self.value_global.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.query_global.weight', 'encoder.layer.8.attention.self.query_global.bias', 'encoder.layer.8.attention.self.key_global.weight', 'encoder.layer.8.attention.self.key_global.bias', 'encoder.layer.8.attention.self.value_global.weight', 'encoder.layer.8.attention.self.value_global.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.query_global.weight', 'encoder.layer.9.attention.self.query_global.bias', 'encoder.layer.9.attention.self.key_global.weight', 'encoder.layer.9.attention.self.key_global.bias', 'encoder.layer.9.attention.self.value_global.weight', 'encoder.layer.9.attention.self.value_global.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.query_global.weight', 'encoder.layer.10.attention.self.query_global.bias', 'encoder.layer.10.attention.self.key_global.weight', 'encoder.layer.10.attention.self.key_global.bias', 'encoder.layer.10.attention.self.value_global.weight', 'encoder.layer.10.attention.self.value_global.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.query_global.weight', 'encoder.layer.11.attention.self.query_global.bias', 'encoder.layer.11.attention.self.key_global.weight', 'encoder.layer.11.attention.self.key_global.bias', 'encoder.layer.11.attention.self.value_global.weight', 'encoder.layer.11.attention.self.value_global.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'pooler.dense.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_longformer_model/longformer/pooler/dense/kernel:0', 'tf_longformer_model/longformer/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_longformer_model/longformer/pooler/dense/kernel:0', 'tf_longformer_model/longformer/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_longformer_model/longformer/pooler/dense/kernel:0', 'tf_longformer_model/longformer/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_longformer_model/longformer/pooler/dense/kernel:0', 'tf_longformer_model/longformer/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    }
   ],
   "source": [
    "model = siamese_longformer()\n",
    "history = model.fit(input_train, y_train, epochs=3, batch_size=1, validation_data=(input_test, y_test),\n",
    "    verbose=1,callbacks=[SavePretrainedCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 1682.114267,
     "end_time": "2021-04-15T00:14:22.473371",
     "exception": false,
     "start_time": "2021-04-14T23:46:20.359104",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "if 'val_loss' in history.history:\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 77.120746,
     "end_time": "2021-04-15T00:15:42.721322",
     "exception": false,
     "start_time": "2021-04-15T00:14:25.600576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### PREDICT TEST ###\n",
    "\n",
    "pred_test = np.argmax(model.predict(input_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 2.964217,
     "end_time": "2021-04-15T00:15:49.014465",
     "exception": false,
     "start_time": "2021-04-15T00:15:46.050248",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(classification_report([map_label[i] for i in y_test], [map_label[i] for i in pred_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 3.518968,
     "end_time": "2021-04-15T00:15:55.431429",
     "exception": false,
     "start_time": "2021-04-15T00:15:51.912461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix([map_label[i] for i in y_test], \n",
    "                              [map_label[i] for i in pred_test])\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "plot_confusion_matrix(cnf_matrix, classes=list(map_label.values()))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "triallong",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "papermill": {
   "duration": 4641.04413,
   "end_time": "2021-04-15T00:16:04.340475",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-04-14T22:58:43.296345",
   "version": "1.2.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "056ad0ee594147d0b0ebdb6aa3dde3b5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "05b01938f0ab410da34276515cdc116d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "067dc092ea57468897b355394c7c33a9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "08c0e072e6d64593aedba0c997ee74b1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "095d4d51c0a54de9a0a5b9d19b671735": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "15bab65ebff54da2821a430c6992dde5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "176622b01d914ac9af79faec3801be41": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_22afd3e5087542bea94d45004b2f72b1",
       "max": 6837,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_05b01938f0ab410da34276515cdc116d",
       "value": 6837
      }
     },
     "1d1c06fc03014bed887ebb5557e8809b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "1d49332b25b34e99981263078eef8416": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "22afd3e5087542bea94d45004b2f72b1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "25a6f617f6b54bec8766480a5c54d5e2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_095d4d51c0a54de9a0a5b9d19b671735",
       "placeholder": "​",
       "style": "IPY_MODEL_f58108d330b241a3adf7a9d2b5e7f3c0",
       "value": " 536M/536M [00:17&lt;00:00, 30.3MB/s]"
      }
     },
     "3072815d3f2a4a3499e84b56a741fd06": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_780850e5dbb9489089970171cc1d3c07",
        "IPY_MODEL_47312edfdd61485ba5ead0e60e7afd04"
       ],
       "layout": "IPY_MODEL_056ad0ee594147d0b0ebdb6aa3dde3b5"
      }
     },
     "326f710596ff4055b1fa47ef79ce0dfb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "364aecf09ad24e4b9bf2b866354810ff": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3c46c2fdb9ed4d34b4678a83a7148ff6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "3cb8bcf356054f349e294a2924307d0e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ebf174fce9a7460aa9db876bbd056d5f",
       "placeholder": "​",
       "style": "IPY_MODEL_9ca2d6dff5294ac5b1009cfe026a1195",
       "value": " 2931/2931 [00:15&lt;00:00, 187.88it/s]"
      }
     },
     "3f4fa016552449b2bd5969403f81662d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1d49332b25b34e99981263078eef8416",
       "max": 231508,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_1d1c06fc03014bed887ebb5557e8809b",
       "value": 231508
      }
     },
     "4285bb4cfcae42f99141e71ea309c24b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_364aecf09ad24e4b9bf2b866354810ff",
       "max": 2931,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_68c0e5876e5b465293e716e0964f758e",
       "value": 2931
      }
     },
     "45df27b4c46d4e84b7e3073eaf08472d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "46e54182dfe44ad18e11588883ffd72a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_176622b01d914ac9af79faec3801be41",
        "IPY_MODEL_61a458e35b32456b995ef57400302d39"
       ],
       "layout": "IPY_MODEL_326f710596ff4055b1fa47ef79ce0dfb"
      }
     },
     "47312edfdd61485ba5ead0e60e7afd04": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_577d84fb72e74a61bdabdec9f8b85671",
       "placeholder": "​",
       "style": "IPY_MODEL_f36094021ee94ddea4bccd17495c2ec6",
       "value": " 6837/6837 [00:43&lt;00:00, 158.92it/s]"
      }
     },
     "479318114c084bceb1d14b271d615de4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cc69802e355c4aafac414097bbcbf8ea",
       "max": 433,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c254dc907b1c4b3b968d3fc4f6e21c21",
       "value": 433
      }
     },
     "4a43e24d93cd48f8880d7f8ca6a806d6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "54bd6ff33d0046b1b09bc2948e9248e6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_45df27b4c46d4e84b7e3073eaf08472d",
       "placeholder": "​",
       "style": "IPY_MODEL_dd0f58e83d154186af34c8f638684469",
       "value": " 433/433 [00:00&lt;00:00, 435B/s]"
      }
     },
     "577d84fb72e74a61bdabdec9f8b85671": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5c4d68d25d0c48a58562b5f578e6874f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_7df734eacdbc418a9811b6ac46fe901e",
        "IPY_MODEL_25a6f617f6b54bec8766480a5c54d5e2"
       ],
       "layout": "IPY_MODEL_a55c2acd59ba4e1089759baf2092d149"
      }
     },
     "61a458e35b32456b995ef57400302d39": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8a53baa054bc419e9d7f29a8ec1060dd",
       "placeholder": "​",
       "style": "IPY_MODEL_c7ad63d417544e899d4903cf7a764f2c",
       "value": " 6837/6837 [00:27&lt;00:00, 245.51it/s]"
      }
     },
     "68c0e5876e5b465293e716e0964f758e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "740b6b3850444a04bcaaf3d2b0c26e33": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "780850e5dbb9489089970171cc1d3c07": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_eb0c66b854404ee98b07a7a8a673517e",
       "max": 6837,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4a43e24d93cd48f8880d7f8ca6a806d6",
       "value": 6837
      }
     },
     "7df734eacdbc418a9811b6ac46fe901e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_740b6b3850444a04bcaaf3d2b0c26e33",
       "max": 536063208,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c469cec6ebde42d1808a121e7580f89d",
       "value": 536063208
      }
     },
     "7f08d62205ab43da82e7667c2db29587": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8a53baa054bc419e9d7f29a8ec1060dd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8cc7d9552de0406a9be26c59501ef476": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "93433b56e51d46d0a1826c1a2fa3a893": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_067dc092ea57468897b355394c7c33a9",
       "placeholder": "​",
       "style": "IPY_MODEL_3c46c2fdb9ed4d34b4678a83a7148ff6",
       "value": " 2931/2931 [00:32&lt;00:00, 91.29it/s]"
      }
     },
     "9547d80b3bf34424826b92ff76f7c40b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_479318114c084bceb1d14b271d615de4",
        "IPY_MODEL_54bd6ff33d0046b1b09bc2948e9248e6"
       ],
       "layout": "IPY_MODEL_c308f17636ba48e59a72212f93de1601"
      }
     },
     "9751b1ab0c1541ba92815fc8d0a6e6b2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9ca2d6dff5294ac5b1009cfe026a1195": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a26b43784468412882912b8b7d90532f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_3f4fa016552449b2bd5969403f81662d",
        "IPY_MODEL_a6f676f165b94b4babf6fc099acbba62"
       ],
       "layout": "IPY_MODEL_15bab65ebff54da2821a430c6992dde5"
      }
     },
     "a55c2acd59ba4e1089759baf2092d149": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a6f676f165b94b4babf6fc099acbba62": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b16d86daebd141d49275c8f5e77ecb07",
       "placeholder": "​",
       "style": "IPY_MODEL_8cc7d9552de0406a9be26c59501ef476",
       "value": " 232k/232k [00:00&lt;00:00, 861kB/s]"
      }
     },
     "b16d86daebd141d49275c8f5e77ecb07": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c254dc907b1c4b3b968d3fc4f6e21c21": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "c308f17636ba48e59a72212f93de1601": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c3f439923dfb4ee2a56e1d35e64ca8dd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_4285bb4cfcae42f99141e71ea309c24b",
        "IPY_MODEL_3cb8bcf356054f349e294a2924307d0e"
       ],
       "layout": "IPY_MODEL_c869acf7a05f47fbb46bd15c298b05fa"
      }
     },
     "c469cec6ebde42d1808a121e7580f89d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "c7ad63d417544e899d4903cf7a764f2c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c869acf7a05f47fbb46bd15c298b05fa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cc69802e355c4aafac414097bbcbf8ea": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d94316b0ded94fd0a81935fbed5094a5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9751b1ab0c1541ba92815fc8d0a6e6b2",
       "max": 2931,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_08c0e072e6d64593aedba0c997ee74b1",
       "value": 2931
      }
     },
     "dd0f58e83d154186af34c8f638684469": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e769e04d2d554a66890476616b086e36": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d94316b0ded94fd0a81935fbed5094a5",
        "IPY_MODEL_93433b56e51d46d0a1826c1a2fa3a893"
       ],
       "layout": "IPY_MODEL_7f08d62205ab43da82e7667c2db29587"
      }
     },
     "eb0c66b854404ee98b07a7a8a673517e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ebf174fce9a7460aa9db876bbd056d5f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f36094021ee94ddea4bccd17495c2ec6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f58108d330b241a3adf7a9d2b5e7f3c0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
