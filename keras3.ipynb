{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 13:49:55.652686: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1731584995.664850  463442 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1731584995.668197  463442 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-14 13:49:55.680435: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "hahah\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"hahah\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msi/miniconda3/envs/longformer/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import keras\n",
    "from keras.layers import Input, GlobalAveragePooling1D, Concatenate, Dropout, Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import Callback\n",
    "import keras.backend as K  \n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    TFLongformerModel,\n",
    "    LongformerConfig,\n",
    "    AutoModel,\n",
    "    BertConfig,\n",
    "    TFAutoModel,\n",
    "    TFBertModel,\n",
    "    LongformerTokenizer,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, fontsize=25)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90, fontsize=15)\n",
    "    plt.yticks(tick_marks, classes, fontsize=15)\n",
    "\n",
    "    fmt = '.2f'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(\n",
    "            j, i, format(cm[i, j], fmt),\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\", fontsize=14\n",
    "        )\n",
    "\n",
    "    plt.ylabel('True label', fontsize=20)\n",
    "    plt.xlabel('Predicted label', fontsize=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load and preprocess data\n",
    "df = pd.read_csv('FinalDatasetBalanced.csv')\n",
    "df['plagiarism_type'] = df['plagiarism_type'].factorize()[0]\n",
    "map_label = dict(enumerate(df['plagiarism_type'].factorize()[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def set_seed(seed):\n",
    "    # Replace tf.random.set_seed with keras.utils.set_random_seed\n",
    "    keras.utils.set_random_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    \n",
    "def convert_to_transformer_inputs(str1, str2, tokenizer, max_sequence_length, double=True):\n",
    "    def return_id(str1, str2, length):\n",
    "        inputs = tokenizer.encode_plus(\n",
    "            str1, str2,\n",
    "            add_special_tokens=True,\n",
    "            max_length=length,\n",
    "            truncation=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        input_ids = inputs[\"input_ids\"]\n",
    "        input_masks = inputs[\"attention_mask\"]\n",
    "        input_segments = inputs[\"token_type_ids\"]\n",
    "        \n",
    "        padding_length = length - len(input_ids)\n",
    "        padding_id = tokenizer.pad_token_id\n",
    "        \n",
    "        input_ids = input_ids + ([padding_id] * padding_length)\n",
    "        input_masks = input_masks + ([0] * padding_length)\n",
    "        input_segments = input_segments + ([0] * padding_length)\n",
    "        \n",
    "        return [input_ids, input_masks, input_segments]\n",
    "\n",
    "    if double:\n",
    "        input_ids_1, input_masks_1, input_segments_1 = return_id(str1, None, max_sequence_length)\n",
    "        input_ids_2, input_masks_2, input_segments_2 = return_id(str2, None, max_sequence_length)\n",
    "\n",
    "        return [\n",
    "            input_ids_1, input_masks_1, input_segments_1,\n",
    "            input_ids_2, input_masks_2, input_segments_2\n",
    "        ]\n",
    "    else:\n",
    "        input_ids, input_masks, input_segments = return_id(str1, str2, max_sequence_length)\n",
    "        return [input_ids, input_masks, input_segments, None, None, None]\n",
    "\n",
    "def compute_input_arrays(df, columns, tokenizer, max_sequence_length, double=True):\n",
    "    input_ids_1, input_masks_1, input_segments_1 = [], [], []\n",
    "    input_ids_2, input_masks_2, input_segments_2 = [], [], []\n",
    "    \n",
    "    for _, instance in df[columns].iterrows():\n",
    "        str1, str2 = instance[columns[0]], instance[columns[1]]\n",
    "        ids_1, masks_1, segments_1, ids_2, masks_2, segments_2 = \\\n",
    "            convert_to_transformer_inputs(str1, str2, tokenizer, max_sequence_length, double=double)\n",
    "        \n",
    "        input_ids_1.append(ids_1)\n",
    "        input_masks_1.append(masks_1)\n",
    "        input_segments_1.append(segments_1)\n",
    "        input_ids_2.append(ids_2)\n",
    "        input_masks_2.append(masks_2)\n",
    "        input_segments_2.append(segments_2)\n",
    "\n",
    "    if double:\n",
    "        return [\n",
    "            np.asarray(input_ids_1, dtype=np.int32), \n",
    "            np.asarray(input_masks_1, dtype=np.int32), \n",
    "            np.asarray(input_segments_1, dtype=np.int32),\n",
    "            np.asarray(input_ids_2, dtype=np.int32), \n",
    "            np.asarray(input_masks_2, dtype=np.int32), \n",
    "            np.asarray(input_segments_2, dtype=np.int32)\n",
    "        ]\n",
    "    else:\n",
    "        return [\n",
    "            np.asarray(input_ids_1, dtype=np.int32), \n",
    "            np.asarray(input_masks_1, dtype=np.int32), \n",
    "            np.asarray(input_segments_1, dtype=np.int32)\n",
    "        ]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1702, 2) (730, 2)\n",
      "(1702,) (730,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[['source_content', 'suspicious_content']], df['plagiarism_type'].values, \n",
    "    random_state=33, test_size=0.3\n",
    ")\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)\n",
    "\n",
    "# Import tokenizer\n",
    "MAX_SEQUENCE_LENGTH = 16000\n",
    "MODEL_NAME = \"longformer-encdec-large-16384\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create sequences for train and test\n",
    "input_train = compute_input_arrays(\n",
    "    X_train, ['source_content', 'suspicious_content'], tokenizer, MAX_SEQUENCE_LENGTH\n",
    ")\n",
    "input_test = compute_input_arrays(\n",
    "    X_test, ['source_content', 'suspicious_content'], tokenizer, MAX_SEQUENCE_LENGTH\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dual_longformer():\n",
    "    set_seed(33)\n",
    "    opt = Adam(learning_rate=2e-5)\n",
    "    \n",
    "    # Replace dtype=tf.int32 with dtype='int32'\n",
    "    id1 = Input((MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    id2 = Input((MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    mask1 = Input((MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    mask2 = Input((MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    atn1 = Input((MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    atn2 = Input((MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    \n",
    "    config = LongformerConfig.from_pretrained(MODEL_NAME)\n",
    "    config.max_position_embeddings = 16000\n",
    "    config.attention_window = [256] * config.num_hidden_layers\n",
    "    longformer_model1 = TFLongformerModel.from_pretrained(MODEL_NAME, config=config, from_pt=True,ignore_mismatched_sizes=True)\n",
    "    longformer_model2 = TFLongformerModel.from_pretrained(MODEL_NAME, config=config, from_pt=True, ignore_mismatched_sizes=True)\n",
    "    \n",
    "    embedding1 = longformer_model1(id1, attention_mask=mask1, token_type_ids=atn1)[0]\n",
    "    embedding2 = longformer_model2(id2, attention_mask=mask2, token_type_ids=atn2)[0]\n",
    "    \n",
    "    x1 = GlobalAveragePooling1D()(embedding1)\n",
    "    x2 = GlobalAveragePooling1D()(embedding2)\n",
    "    \n",
    "    x = Concatenate()([x1, x2])\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    out = Dense(len(map_label), activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=[id1, mask1, atn1, id2, mask2, atn2], outputs=out)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=opt)\n",
    "    \n",
    "    return model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Adjusted the callback to save the model in .keras format\n",
    "class SaveModelCallback(Callback): \n",
    "    def __init__(self, save_path='longformer_checkpoints'):\n",
    "        super().__init__()\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        epoch_path = f'{self.save_path}/epoch_{epoch+1}'\n",
    "        os.makedirs(epoch_path, exist_ok=True)\n",
    "\n",
    "        # Save the model in the new .keras format\n",
    "        self.model.save(f'{epoch_path}/model_{epoch+1}.keras') \n",
    "        print(f'\\nSaved model to {epoch_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1731585070.805744  463442 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21862 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:2d:00.0, compute capability: 8.6\n",
      "You are using a model of type bart to instantiate a model of type longformer. This is not supported for all configurations of models and can yield errors.\n",
      "/home/msi/miniconda3/envs/longformer/lib/python3.11/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "/home/msi/miniconda3/envs/longformer/lib/python3.11/site-packages/tf_keras/src/initializers/initializers.py:121: UserWarning: The initializer TruncatedNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "  warnings.warn(\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFLongformerModel: ['model.decoder.layers.3.final_layer_norm.weight', 'model.encoder.layers.2.self_attn.longformer_self_attn.query_global.weight', 'model.encoder.layers.6.self_attn.longformer_self_attn.value_global.bias', 'model.encoder.layers.9.self_attn_layer_norm.bias', 'model.decoder.layers.11.encoder_attn.k_proj.bias', 'model.encoder.layernorm_embedding.weight', 'model.decoder.layers.11.self_attn.v_proj.weight', 'model.encoder.layers.2.self_attn.longformer_self_attn.value_global.weight', 'model.encoder.layers.0.self_attn.longformer_self_attn.value.weight', 'model.encoder.layers.1.fc2.weight', 'model.decoder.layers.9.self_attn.v_proj.bias', 'model.decoder.layers.9.encoder_attn.v_proj.weight', 'model.decoder.layers.1.encoder_attn.q_proj.weight', 'model.decoder.layers.0.encoder_attn.v_proj.weight', 'model.decoder.layers.11.fc2.bias', 'model.decoder.layers.8.self_attn.q_proj.bias', 'model.decoder.layers.3.encoder_attn.q_proj.weight', 'model.decoder.layers.11.self_attn.v_proj.bias', 'model.encoder.layers.7.self_attn.longformer_self_attn.value_global.weight', 'model.decoder.layers.7.self_attn.v_proj.bias', 'model.decoder.layernorm_embedding.bias', 'model.decoder.layers.0.encoder_attn.out_proj.bias', 'model.decoder.layers.2.encoder_attn.k_proj.weight', 'model.encoder.layers.1.self_attn.output.weight', 'model.encoder.layers.3.self_attn.longformer_self_attn.value.bias', 'model.encoder.layers.3.self_attn.longformer_self_attn.query.bias', 'model.decoder.layers.4.fc2.weight', 'model.encoder.layers.3.self_attn.longformer_self_attn.value.weight', 'model.encoder.layers.5.self_attn_layer_norm.bias', 'model.decoder.layers.8.encoder_attn.out_proj.weight', 'model.encoder.layers.10.self_attn.longformer_self_attn.key_global.bias', 'model.encoder.layers.2.final_layer_norm.bias', 'model.decoder.layers.7.self_attn.k_proj.bias', 'model.decoder.layers.11.final_layer_norm.weight', 'model.decoder.layers.10.self_attn.k_proj.weight', 'model.encoder.layers.3.self_attn.output.bias', 'model.decoder.layers.8.self_attn.out_proj.weight', 'model.decoder.layers.0.encoder_attn.out_proj.weight', 'model.encoder.layers.0.fc1.bias', 'model.encoder.layers.7.fc2.bias', 'model.encoder.layers.8.self_attn.longformer_self_attn.value.weight', 'model.encoder.layers.5.self_attn.longformer_self_attn.query.weight', 'model.decoder.layers.2.self_attn_layer_norm.weight', 'model.decoder.layers.7.self_attn.out_proj.weight', 'model.encoder.layers.11.self_attn.longformer_self_attn.key.bias', 'model.encoder.layers.2.self_attn.longformer_self_attn.key.bias', 'model.encoder.layers.3.self_attn.longformer_self_attn.query_global.weight', 'model.encoder.layers.10.self_attn.longformer_self_attn.value_global.bias', 'model.decoder.layers.3.encoder_attn.v_proj.weight', 'model.encoder.layers.10.final_layer_norm.weight', 'model.decoder.layers.1.self_attn.out_proj.weight', 'model.decoder.layers.6.encoder_attn.out_proj.bias', 'model.decoder.layers.7.encoder_attn.v_proj.bias', 'model.encoder.layers.7.final_layer_norm.bias', 'model.encoder.layers.8.self_attn.longformer_self_attn.query.weight', 'model.encoder.layers.5.self_attn.longformer_self_attn.query_global.weight', 'model.decoder.layers.2.self_attn.out_proj.bias', 'model.encoder.layers.6.self_attn_layer_norm.weight', 'model.decoder.layers.4.self_attn_layer_norm.bias', 'model.encoder.layers.4.self_attn.longformer_self_attn.key.bias', 'model.decoder.layers.6.self_attn.v_proj.weight', 'model.encoder.layers.4.fc1.weight', 'model.decoder.layers.6.self_attn.out_proj.weight', 'model.decoder.layers.2.fc1.bias', 'model.decoder.layers.7.final_layer_norm.weight', 'model.decoder.layers.9.encoder_attn.q_proj.weight', 'model.decoder.layers.10.self_attn.out_proj.weight', 'model.encoder.layers.2.self_attn.longformer_self_attn.query_global.bias', 'model.encoder.layers.11.fc2.weight', 'model.encoder.layers.4.final_layer_norm.bias', 'model.decoder.layers.2.self_attn.out_proj.weight', 'model.decoder.layers.7.self_attn_layer_norm.weight', 'model.decoder.layers.4.encoder_attn.q_proj.weight', 'model.decoder.layers.11.encoder_attn_layer_norm.bias', 'model.encoder.layers.9.fc1.bias', 'model.decoder.layers.11.self_attn.k_proj.weight', 'model.encoder.layers.3.self_attn.longformer_self_attn.value_global.bias', 'model.decoder.layers.9.encoder_attn_layer_norm.bias', 'model.encoder.layers.7.self_attn.output.bias', 'model.encoder.layers.4.self_attn.longformer_self_attn.query.bias', 'model.decoder.layers.1.final_layer_norm.bias', 'model.encoder.layers.9.self_attn.longformer_self_attn.value.bias', 'final_logits_bias', 'model.encoder.layers.9.self_attn.output.weight', 'model.decoder.layers.1.self_attn.out_proj.bias', 'model.encoder.layers.11.self_attn.longformer_self_attn.query_global.weight', 'model.decoder.layers.4.self_attn_layer_norm.weight', 'model.encoder.layers.1.self_attn.longformer_self_attn.key.bias', 'model.encoder.layers.0.self_attn.longformer_self_attn.query.bias', 'model.decoder.layers.4.fc2.bias', 'model.decoder.layers.11.encoder_attn_layer_norm.weight', 'model.decoder.layers.2.encoder_attn.q_proj.weight', 'model.encoder.layers.0.self_attn.output.weight', 'model.encoder.layers.11.self_attn.longformer_self_attn.value_global.bias', 'model.encoder.layers.0.self_attn.longformer_self_attn.value.bias', 'model.decoder.layers.4.encoder_attn.k_proj.bias', 'model.encoder.layers.2.self_attn.output.weight', 'model.encoder.layers.5.self_attn.longformer_self_attn.value.bias', 'model.encoder.layers.1.self_attn.longformer_self_attn.query.weight', 'model.encoder.layers.10.self_attn.longformer_self_attn.query_global.bias', 'model.encoder.layers.11.fc1.bias', 'model.decoder.layers.6.self_attn_layer_norm.bias', 'model.decoder.layers.3.self_attn_layer_norm.bias', 'model.encoder.layers.0.fc2.bias', 'model.encoder.layers.3.self_attn.longformer_self_attn.key.weight', 'model.decoder.layers.3.fc2.bias', 'model.decoder.layers.0.final_layer_norm.weight', 'model.encoder.layers.9.final_layer_norm.weight', 'model.decoder.layers.7.encoder_attn.out_proj.bias', 'model.encoder.layers.9.self_attn.longformer_self_attn.query_global.weight', 'model.decoder.layers.9.encoder_attn.out_proj.bias', 'model.decoder.layers.2.fc1.weight', 'model.decoder.layers.6.encoder_attn.k_proj.weight', 'model.encoder.layers.7.self_attn.output.weight', 'model.encoder.layers.7.self_attn.longformer_self_attn.query.weight', 'model.decoder.layers.7.self_attn.q_proj.weight', 'model.encoder.layers.5.fc1.weight', 'model.decoder.layers.9.self_attn.q_proj.bias', 'model.decoder.layers.10.self_attn.out_proj.bias', 'model.encoder.layers.5.self_attn.longformer_self_attn.key_global.bias', 'model.encoder.layers.8.self_attn.output.weight', 'model.decoder.layers.2.encoder_attn_layer_norm.weight', 'model.encoder.layers.8.self_attn.longformer_self_attn.query_global.weight', 'model.encoder.layers.10.self_attn.output.weight', 'model.encoder.layers.1.self_attn.longformer_self_attn.key_global.bias', 'model.decoder.layers.0.encoder_attn.k_proj.bias', 'model.decoder.layers.4.encoder_attn.v_proj.weight', 'model.encoder.layers.2.final_layer_norm.weight', 'model.encoder.layers.11.self_attn.longformer_self_attn.key.weight', 'model.decoder.layers.6.fc1.bias', 'model.encoder.layers.7.self_attn.longformer_self_attn.value.weight', 'model.decoder.layers.0.self_attn.q_proj.weight', 'model.decoder.layers.6.encoder_attn.out_proj.weight', 'model.decoder.layers.5.final_layer_norm.bias', 'model.encoder.layers.6.self_attn.longformer_self_attn.query.weight', 'model.encoder.layers.1.final_layer_norm.weight', 'model.encoder.layers.9.self_attn.longformer_self_attn.query.weight', 'model.decoder.layers.1.encoder_attn_layer_norm.bias', 'model.decoder.layers.0.self_attn.out_proj.bias', 'model.decoder.layers.3.final_layer_norm.bias', 'model.decoder.layers.1.encoder_attn.k_proj.weight', 'model.encoder.layers.1.self_attn.longformer_self_attn.value_global.weight', 'model.encoder.layers.3.self_attn.longformer_self_attn.value_global.weight', 'model.encoder.layers.7.fc1.bias', 'model.encoder.layers.6.self_attn.longformer_self_attn.query.bias', 'model.decoder.layers.8.encoder_attn.k_proj.bias', 'model.decoder.layers.10.encoder_attn_layer_norm.bias', 'model.encoder.layers.8.self_attn.longformer_self_attn.key_global.bias', 'model.encoder.layers.5.self_attn.longformer_self_attn.key.weight', 'model.encoder.layers.8.fc1.weight', 'model.decoder.layers.8.encoder_attn.q_proj.bias', 'model.encoder.layers.7.self_attn_layer_norm.bias', 'model.decoder.layers.8.fc1.weight', 'model.decoder.layers.10.fc2.weight', 'model.encoder.layers.5.self_attn.longformer_self_attn.query.bias', 'model.decoder.layers.0.encoder_attn_layer_norm.weight', 'model.encoder.layers.7.self_attn.longformer_self_attn.query_global.bias', 'model.encoder.layers.1.fc1.weight', 'model.encoder.layers.5.self_attn.longformer_self_attn.key.bias', 'model.encoder.layers.6.final_layer_norm.bias', 'model.decoder.layers.2.final_layer_norm.bias', 'model.decoder.layers.9.fc2.weight', 'model.decoder.layers.5.self_attn.out_proj.bias', 'model.decoder.layers.5.encoder_attn.k_proj.weight', 'model.decoder.layers.2.self_attn.k_proj.weight', 'model.decoder.layers.7.self_attn.q_proj.bias', 'model.encoder.layers.2.self_attn_layer_norm.weight', 'model.decoder.layers.9.encoder_attn_layer_norm.weight', 'model.encoder.layers.9.self_attn.longformer_self_attn.value.weight', 'model.decoder.layers.6.encoder_attn.q_proj.bias', 'model.decoder.layers.3.fc1.bias', 'model.decoder.layers.3.self_attn.out_proj.weight', 'model.encoder.layers.2.self_attn.longformer_self_attn.key_global.bias', 'model.encoder.layers.5.fc1.bias', 'model.decoder.layers.7.encoder_attn_layer_norm.weight', 'model.decoder.layers.9.self_attn.out_proj.weight', 'model.encoder.layers.3.self_attn_layer_norm.weight', 'model.decoder.layers.7.fc2.bias', 'model.encoder.layers.9.self_attn.longformer_self_attn.key_global.weight', 'model.decoder.layers.2.fc2.weight', 'model.decoder.layers.0.encoder_attn.q_proj.bias', 'model.encoder.layers.7.self_attn.longformer_self_attn.key_global.weight', 'model.decoder.layers.3.self_attn.k_proj.bias', 'model.decoder.layers.7.self_attn.out_proj.bias', 'model.encoder.layers.8.fc2.bias', 'model.decoder.layers.4.encoder_attn_layer_norm.weight', 'model.decoder.layers.8.encoder_attn.v_proj.weight', 'model.encoder.layers.6.self_attn.longformer_self_attn.value.bias', 'model.decoder.layers.2.self_attn.v_proj.bias', 'model.decoder.layers.2.encoder_attn.v_proj.bias', 'model.decoder.layers.9.encoder_attn.v_proj.bias', 'model.encoder.layers.3.final_layer_norm.weight', 'model.encoder.layers.11.self_attn.longformer_self_attn.value.weight', 'model.decoder.layers.11.encoder_attn.q_proj.weight', 'model.decoder.layers.7.encoder_attn.k_proj.weight', 'model.encoder.layers.9.final_layer_norm.bias', 'model.encoder.layers.4.fc2.weight', 'model.decoder.layers.9.self_attn.out_proj.bias', 'model.encoder.layers.2.self_attn.longformer_self_attn.key_global.weight', 'model.encoder.layers.9.fc2.weight', 'model.decoder.layers.0.encoder_attn_layer_norm.bias', 'model.decoder.layers.4.self_attn.q_proj.weight', 'model.encoder.layers.8.self_attn.longformer_self_attn.key.bias', 'model.decoder.layers.0.self_attn_layer_norm.weight', 'model.decoder.layers.1.encoder_attn.out_proj.bias', 'model.decoder.layers.7.self_attn.v_proj.weight', 'model.decoder.layers.9.self_attn.v_proj.weight', 'model.encoder.layers.8.fc2.weight', 'model.encoder.layers.0.self_attn.longformer_self_attn.key_global.bias', 'model.encoder.layers.3.final_layer_norm.bias', 'model.encoder.layers.11.self_attn.longformer_self_attn.key_global.weight', 'model.decoder.layers.10.encoder_attn.k_proj.weight', 'model.decoder.layers.10.encoder_attn.out_proj.weight', 'model.encoder.layers.2.self_attn.longformer_self_attn.value.weight', 'model.decoder.layers.10.self_attn.q_proj.weight', 'model.decoder.layers.7.self_attn_layer_norm.bias', 'model.encoder.layers.6.self_attn.longformer_self_attn.query_global.weight', 'model.encoder.layers.4.self_attn.longformer_self_attn.key_global.weight', 'model.encoder.layers.10.self_attn.longformer_self_attn.query.bias', 'model.encoder.layers.4.self_attn.longformer_self_attn.value.bias', 'model.decoder.layers.1.fc2.bias', 'model.encoder.layers.8.self_attn.longformer_self_attn.query_global.bias', 'model.decoder.layers.3.self_attn.v_proj.weight', 'model.encoder.layers.11.self_attn.longformer_self_attn.value.bias', 'model.decoder.layers.3.encoder_attn.q_proj.bias', 'model.encoder.layers.5.self_attn.longformer_self_attn.key_global.weight', 'model.encoder.layers.1.self_attn.longformer_self_attn.value.bias', 'model.decoder.layers.9.self_attn_layer_norm.weight', 'model.encoder.layers.0.self_attn.longformer_self_attn.value_global.bias', 'model.encoder.layers.7.self_attn.longformer_self_attn.key.weight', 'model.decoder.layers.0.fc1.weight', 'model.encoder.layers.6.self_attn_layer_norm.bias', 'model.encoder.layers.6.fc1.weight', 'model.encoder.layers.10.self_attn_layer_norm.weight', 'model.decoder.layers.0.self_attn_layer_norm.bias', 'model.decoder.layers.1.self_attn.q_proj.weight', 'model.encoder.embed_tokens.weight', 'model.encoder.layers.8.self_attn.longformer_self_attn.value_global.weight', 'model.decoder.layers.2.encoder_attn_layer_norm.bias', 'model.decoder.layers.5.self_attn.v_proj.weight', 'model.encoder.layers.11.fc2.bias', 'model.decoder.layers.6.encoder_attn.k_proj.bias', 'model.decoder.layers.4.final_layer_norm.bias', 'model.decoder.layers.3.self_attn.k_proj.weight', 'model.decoder.layers.3.encoder_attn.v_proj.bias', 'model.encoder.layers.1.self_attn.longformer_self_attn.query_global.bias', 'model.decoder.layers.2.encoder_attn.k_proj.bias', 'model.decoder.layers.3.encoder_attn.out_proj.bias', 'model.decoder.layers.7.fc1.bias', 'model.encoder.layers.9.self_attn_layer_norm.weight', 'model.decoder.layers.9.final_layer_norm.bias', 'model.encoder.layers.6.self_attn.longformer_self_attn.key.bias', 'model.encoder.layers.4.self_attn_layer_norm.bias', 'model.encoder.layers.1.self_attn.longformer_self_attn.query_global.weight', 'model.decoder.layers.11.encoder_attn.v_proj.weight', 'model.encoder.layers.9.self_attn.longformer_self_attn.value_global.bias', 'model.decoder.layers.5.self_attn_layer_norm.bias', 'model.encoder.layers.10.self_attn.longformer_self_attn.query_global.weight', 'model.encoder.layers.7.self_attn.longformer_self_attn.key_global.bias', 'model.encoder.layers.10.final_layer_norm.bias', 'model.encoder.layers.8.fc1.bias', 'model.decoder.layers.3.self_attn.out_proj.bias', 'model.decoder.layers.1.self_attn.k_proj.bias', 'model.decoder.layers.1.encoder_attn.q_proj.bias', 'model.decoder.layers.8.encoder_attn.v_proj.bias', 'model.decoder.layernorm_embedding.weight', 'model.decoder.layers.5.encoder_attn.q_proj.bias', 'model.decoder.layers.8.fc1.bias', 'model.decoder.layers.11.encoder_attn.out_proj.bias', 'model.encoder.layers.10.fc1.weight', 'model.decoder.layers.4.encoder_attn.out_proj.weight', 'model.encoder.embed_positions.weight', 'model.encoder.layers.0.self_attn.longformer_self_attn.query.weight', 'model.decoder.layers.5.self_attn.q_proj.weight', 'model.encoder.layers.3.fc2.weight', 'model.decoder.layers.0.self_attn.k_proj.bias', 'model.decoder.layers.8.self_attn.out_proj.bias', 'model.encoder.layers.5.self_attn.longformer_self_attn.value_global.weight', 'model.decoder.layers.1.encoder_attn.v_proj.bias', 'model.encoder.layers.6.self_attn.output.weight', 'model.encoder.layers.3.fc1.bias', 'model.decoder.layers.5.encoder_attn.out_proj.bias', 'model.encoder.layers.1.self_attn.longformer_self_attn.value_global.bias', 'model.decoder.layers.11.fc1.weight', 'model.encoder.layers.9.fc2.bias', 'model.encoder.layernorm_embedding.bias', 'model.decoder.layers.6.self_attn.v_proj.bias', 'model.encoder.layers.1.self_attn.longformer_self_attn.query.bias', 'model.encoder.layers.10.fc1.bias', 'model.decoder.layers.9.fc2.bias', 'model.decoder.layers.1.self_attn_layer_norm.weight', 'model.decoder.layers.6.self_attn.k_proj.weight', 'model.encoder.layers.0.self_attn.longformer_self_attn.value_global.weight', 'model.decoder.layers.4.self_attn.out_proj.bias', 'model.decoder.layers.5.fc1.weight', 'model.decoder.embed_positions.weight', 'model.encoder.layers.7.self_attn_layer_norm.weight', 'model.encoder.layers.6.self_attn.output.bias', 'model.decoder.layers.7.encoder_attn.q_proj.weight', 'model.decoder.layers.6.self_attn.out_proj.bias', 'model.decoder.layers.10.encoder_attn.out_proj.bias', 'model.decoder.layers.11.self_attn.out_proj.weight', 'model.decoder.layers.1.fc2.weight', 'model.decoder.layers.2.self_attn.q_proj.bias', 'model.decoder.layers.11.self_attn_layer_norm.weight', 'model.encoder.layers.3.fc2.bias', 'model.decoder.layers.1.encoder_attn.v_proj.weight', 'model.decoder.layers.8.self_attn.v_proj.weight', 'model.encoder.layers.1.self_attn_layer_norm.weight', 'model.decoder.layers.0.fc2.bias', 'model.encoder.layers.0.self_attn.longformer_self_attn.query_global.bias', 'model.encoder.layers.2.self_attn.longformer_self_attn.query.weight', 'model.decoder.layers.10.self_attn.v_proj.weight', 'model.decoder.layers.5.self_attn.k_proj.bias', 'model.decoder.layers.8.encoder_attn.q_proj.weight', 'model.encoder.layers.5.self_attn.output.bias', 'model.decoder.layers.11.fc2.weight', 'model.encoder.layers.3.self_attn.longformer_self_attn.key.bias', 'model.encoder.layers.9.self_attn.longformer_self_attn.query_global.bias', 'model.decoder.layers.0.self_attn.k_proj.weight', 'model.encoder.layers.9.self_attn.longformer_self_attn.key.bias', 'model.encoder.layers.4.self_attn.longformer_self_attn.key_global.bias', 'model.encoder.layers.6.fc2.bias', 'model.decoder.layers.0.self_attn.q_proj.bias', 'model.encoder.layers.6.self_attn.longformer_self_attn.value.weight', 'model.encoder.layers.8.self_attn.longformer_self_attn.value_global.bias', 'model.encoder.layers.10.self_attn.output.bias', 'model.decoder.layers.4.self_attn.v_proj.weight', 'model.decoder.layers.1.final_layer_norm.weight', 'model.encoder.layers.1.self_attn.longformer_self_attn.value.weight', 'model.encoder.layers.10.fc2.weight', 'model.encoder.layers.11.self_attn_layer_norm.bias', 'model.decoder.layers.2.self_attn.v_proj.weight', 'model.encoder.layers.8.self_attn_layer_norm.weight', 'model.encoder.layers.4.self_attn.longformer_self_attn.key.weight', 'model.decoder.layers.11.encoder_attn.v_proj.bias', 'model.encoder.layers.2.self_attn.output.bias', 'model.decoder.layers.6.final_layer_norm.weight', 'model.decoder.layers.4.fc1.bias', 'model.encoder.layers.7.self_attn.longformer_self_attn.value_global.bias', 'model.encoder.layers.9.self_attn.longformer_self_attn.key_global.bias', 'model.decoder.layers.10.fc1.bias', 'model.encoder.layers.0.self_attn.longformer_self_attn.query_global.weight', 'model.decoder.layers.1.self_attn.k_proj.weight', 'model.encoder.layers.8.self_attn.longformer_self_attn.key_global.weight', 'model.decoder.layers.9.encoder_attn.k_proj.weight', 'model.encoder.layers.7.self_attn.longformer_self_attn.query_global.weight', 'model.decoder.layers.2.encoder_attn.v_proj.weight', 'model.decoder.layers.6.self_attn.q_proj.bias', 'model.decoder.layers.1.self_attn_layer_norm.bias', 'model.decoder.layers.8.self_attn.v_proj.bias', 'model.encoder.layers.2.self_attn.longformer_self_attn.value.bias', 'model.encoder.layers.7.self_attn.longformer_self_attn.value.bias', 'model.decoder.layers.10.final_layer_norm.bias', 'model.encoder.layers.11.self_attn.longformer_self_attn.query_global.bias', 'model.encoder.layers.4.self_attn.longformer_self_attn.value_global.weight', 'model.decoder.layers.1.encoder_attn.out_proj.weight', 'model.decoder.layers.11.self_attn.out_proj.bias', 'model.decoder.layers.11.encoder_attn.q_proj.bias', 'model.decoder.layers.2.encoder_attn.q_proj.bias', 'model.encoder.layers.4.self_attn.longformer_self_attn.query_global.weight', 'model.decoder.layers.0.fc1.bias', 'model.encoder.layers.4.self_attn.longformer_self_attn.query.weight', 'model.encoder.layers.5.self_attn.longformer_self_attn.value.weight', 'model.encoder.layers.10.self_attn.longformer_self_attn.key_global.weight', 'model.encoder.layers.4.self_attn.output.weight', 'model.decoder.layers.10.self_attn_layer_norm.weight', 'model.decoder.layers.0.final_layer_norm.bias', 'model.encoder.layers.5.self_attn.output.weight', 'model.decoder.layers.5.encoder_attn.q_proj.weight', 'model.encoder.layers.9.self_attn.longformer_self_attn.query.bias', 'model.encoder.layers.2.fc2.bias', 'model.encoder.layers.5.final_layer_norm.weight', 'model.encoder.layers.8.self_attn.longformer_self_attn.value.bias', 'model.encoder.layers.6.fc2.weight', 'model.decoder.layers.8.encoder_attn.out_proj.bias', 'model.decoder.layers.6.encoder_attn_layer_norm.bias', 'model.decoder.layers.3.encoder_attn_layer_norm.weight', 'model.decoder.layers.2.final_layer_norm.weight', 'model.encoder.layers.0.self_attn.output.bias', 'model.encoder.layers.6.fc1.bias', 'model.decoder.layers.4.encoder_attn.k_proj.weight', 'model.decoder.layers.8.encoder_attn_layer_norm.bias', 'model.encoder.layers.10.self_attn.longformer_self_attn.value.weight', 'model.decoder.layers.5.final_layer_norm.weight', 'model.decoder.layers.5.self_attn.q_proj.bias', 'model.decoder.layers.4.encoder_attn_layer_norm.bias', 'model.encoder.layers.3.fc1.weight', 'model.decoder.layers.5.fc2.weight', 'model.encoder.layers.3.self_attn.longformer_self_attn.key_global.bias', 'model.encoder.layers.0.self_attn.longformer_self_attn.key.bias', 'model.encoder.layers.0.final_layer_norm.bias', 'model.decoder.layers.0.encoder_attn.k_proj.weight', 'model.encoder.layers.8.self_attn_layer_norm.bias', 'model.decoder.layers.6.self_attn_layer_norm.weight', 'model.decoder.layers.11.self_attn_layer_norm.bias', 'model.decoder.layers.6.final_layer_norm.bias', 'model.decoder.layers.5.self_attn_layer_norm.weight', 'model.decoder.layers.7.encoder_attn.out_proj.weight', 'model.decoder.layers.5.encoder_attn.k_proj.bias', 'model.encoder.layers.3.self_attn_layer_norm.bias', 'model.encoder.layers.10.self_attn.longformer_self_attn.query.weight', 'model.decoder.layers.6.self_attn.k_proj.bias', 'model.decoder.layers.9.self_attn.k_proj.weight', 'model.decoder.layers.0.self_attn.out_proj.weight', 'model.encoder.layers.0.fc2.weight', 'model.encoder.layers.2.fc1.weight', 'model.decoder.layers.5.encoder_attn.v_proj.bias', 'model.decoder.layers.6.encoder_attn.q_proj.weight', 'model.decoder.layers.6.fc2.bias', 'model.decoder.layers.5.encoder_attn_layer_norm.weight', 'model.encoder.layers.1.self_attn.longformer_self_attn.key.weight', 'model.decoder.layers.6.fc2.weight', 'model.decoder.layers.7.final_layer_norm.bias', 'model.decoder.layers.5.self_attn.out_proj.weight', 'model.encoder.layers.7.self_attn.longformer_self_attn.query.bias', 'model.encoder.layers.7.fc2.weight', 'model.encoder.layers.0.final_layer_norm.weight', 'model.encoder.layers.0.self_attn_layer_norm.bias', 'model.decoder.layers.11.fc1.bias', 'model.decoder.layers.4.final_layer_norm.weight', 'model.decoder.layers.9.fc1.weight', 'model.decoder.layers.3.self_attn_layer_norm.weight', 'model.decoder.layers.3.self_attn.q_proj.bias', 'model.decoder.layers.10.encoder_attn.v_proj.bias', 'model.decoder.layers.2.encoder_attn.out_proj.weight', 'model.decoder.layers.11.final_layer_norm.bias', 'model.decoder.layers.4.encoder_attn.out_proj.bias', 'model.decoder.layers.8.encoder_attn_layer_norm.weight', 'model.encoder.layers.11.final_layer_norm.weight', 'model.decoder.layers.10.self_attn.q_proj.bias', 'model.decoder.layers.0.encoder_attn.v_proj.bias', 'model.encoder.layers.3.self_attn.longformer_self_attn.key_global.weight', 'model.encoder.layers.3.self_attn.longformer_self_attn.query_global.bias', 'model.decoder.layers.4.self_attn.k_proj.weight', 'model.decoder.layers.8.self_attn.k_proj.weight', 'model.encoder.layers.6.self_attn.longformer_self_attn.value_global.weight', 'model.decoder.layers.11.encoder_attn.k_proj.weight', 'model.decoder.layers.3.encoder_attn.k_proj.weight', 'model.encoder.layers.3.self_attn.output.weight', 'model.decoder.layers.2.self_attn.k_proj.bias', 'model.decoder.layers.4.fc1.weight', 'model.decoder.layers.7.fc1.weight', 'model.decoder.layers.8.self_attn_layer_norm.weight', 'model.decoder.layers.10.encoder_attn_layer_norm.weight', 'model.decoder.layers.9.self_attn.k_proj.bias', 'model.decoder.layers.2.encoder_attn.out_proj.bias', 'model.encoder.layers.8.final_layer_norm.weight', 'model.encoder.layers.11.fc1.weight', 'model.encoder.layers.2.self_attn.longformer_self_attn.key.weight', 'model.encoder.layers.10.fc2.bias', 'model.decoder.layers.10.fc1.weight', 'model.decoder.layers.10.final_layer_norm.weight', 'model.encoder.layers.1.self_attn.output.bias', 'model.decoder.layers.4.self_attn.k_proj.bias', 'model.encoder.layers.1.fc2.bias', 'model.encoder.layers.11.self_attn.longformer_self_attn.key_global.bias', 'model.decoder.layers.11.self_attn.q_proj.bias', 'model.encoder.layers.5.fc2.bias', 'model.encoder.layers.11.self_attn.output.weight', 'model.encoder.layers.2.fc2.weight', 'model.encoder.layers.0.self_attn.longformer_self_attn.key.weight', 'model.encoder.layers.2.self_attn.longformer_self_attn.value_global.bias', 'model.encoder.layers.10.self_attn.longformer_self_attn.key.weight', 'model.decoder.layers.6.encoder_attn.v_proj.bias', 'model.decoder.layers.7.self_attn.k_proj.weight', 'model.encoder.layers.0.self_attn.longformer_self_attn.key_global.weight', 'model.decoder.layers.10.self_attn_layer_norm.bias', 'model.decoder.layers.11.self_attn.k_proj.bias', 'model.decoder.layers.10.self_attn.v_proj.bias', 'model.encoder.layers.1.final_layer_norm.bias', 'model.shared.weight', 'model.encoder.layers.4.self_attn_layer_norm.weight', 'model.encoder.layers.8.self_attn.longformer_self_attn.key.weight', 'model.decoder.layers.10.encoder_attn.q_proj.bias', 'model.decoder.layers.11.self_attn.q_proj.weight', 'model.decoder.layers.11.encoder_attn.out_proj.weight', 'model.decoder.layers.3.self_attn.v_proj.bias', 'model.encoder.layers.0.fc1.weight', 'model.decoder.layers.5.encoder_attn.out_proj.weight', 'model.encoder.layers.4.final_layer_norm.weight', 'model.decoder.layers.5.encoder_attn.v_proj.weight', 'model.encoder.layers.8.self_attn.output.bias', 'model.decoder.layers.2.fc2.bias', 'model.decoder.layers.7.encoder_attn.v_proj.weight', 'model.encoder.layers.8.final_layer_norm.bias', 'model.decoder.layers.9.encoder_attn.q_proj.bias', 'model.encoder.layers.5.self_attn_layer_norm.weight', 'model.decoder.layers.7.encoder_attn_layer_norm.bias', 'model.encoder.layers.5.self_attn.longformer_self_attn.query_global.bias', 'model.decoder.layers.4.encoder_attn.v_proj.bias', 'model.decoder.layers.0.self_attn.v_proj.bias', 'model.decoder.layers.3.encoder_attn.k_proj.bias', 'model.decoder.layers.1.fc1.bias', 'model.decoder.layers.5.fc1.bias', 'model.encoder.layers.8.self_attn.longformer_self_attn.query.bias', 'model.decoder.layers.8.self_attn.q_proj.weight', 'model.encoder.layers.1.fc1.bias', 'model.encoder.layers.1.self_attn.longformer_self_attn.key_global.weight', 'model.decoder.layers.1.encoder_attn_layer_norm.weight', 'model.decoder.layers.10.encoder_attn.q_proj.weight', 'model.encoder.layers.7.fc1.weight', 'model.encoder.layers.11.final_layer_norm.bias', 'model.encoder.layers.4.fc1.bias', 'model.decoder.layers.5.encoder_attn_layer_norm.bias', 'model.encoder.layers.7.self_attn.longformer_self_attn.key.bias', 'model.decoder.layers.3.fc2.weight', 'model.encoder.layers.9.self_attn.longformer_self_attn.key.weight', 'model.encoder.layers.9.self_attn.output.bias', 'model.decoder.layers.3.encoder_attn.out_proj.weight', 'model.decoder.layers.4.self_attn.q_proj.bias', 'model.decoder.layers.1.encoder_attn.k_proj.bias', 'model.decoder.layers.2.self_attn_layer_norm.bias', 'model.encoder.layers.6.self_attn.longformer_self_attn.key.weight', 'model.decoder.layers.8.fc2.weight', 'model.encoder.layers.11.self_attn.output.bias', 'model.decoder.layers.9.self_attn.q_proj.weight', 'model.decoder.layers.7.fc2.weight', 'model.encoder.layers.3.self_attn.longformer_self_attn.query.weight', 'model.encoder.layers.6.self_attn.longformer_self_attn.key_global.bias', 'model.decoder.layers.3.encoder_attn_layer_norm.bias', 'model.encoder.layers.4.self_attn.longformer_self_attn.query_global.bias', 'model.decoder.layers.8.final_layer_norm.bias', 'model.decoder.layers.1.fc1.weight', 'model.decoder.layers.9.encoder_attn.out_proj.weight', 'model.decoder.layers.8.self_attn_layer_norm.bias', 'model.decoder.layers.7.encoder_attn.q_proj.bias', 'model.decoder.layers.4.encoder_attn.q_proj.bias', 'model.encoder.layers.5.fc2.weight', 'model.encoder.layers.7.final_layer_norm.weight', 'model.encoder.layers.10.self_attn.longformer_self_attn.key.bias', 'model.decoder.layers.8.encoder_attn.k_proj.weight', 'model.decoder.layers.9.final_layer_norm.weight', 'model.decoder.layers.3.fc1.weight', 'model.decoder.layers.5.self_attn.k_proj.weight', 'model.encoder.layers.11.self_attn.longformer_self_attn.query.bias', 'model.encoder.layers.4.self_attn.longformer_self_attn.value.weight', 'model.encoder.layers.0.self_attn_layer_norm.weight', 'model.encoder.layers.2.fc1.bias', 'model.decoder.layers.3.self_attn.q_proj.weight', 'model.decoder.layers.8.fc2.bias', 'model.encoder.layers.5.final_layer_norm.bias', 'model.encoder.layers.11.self_attn.longformer_self_attn.value_global.weight', 'model.decoder.layers.0.encoder_attn.q_proj.weight', 'model.decoder.layers.8.self_attn.k_proj.bias', 'model.decoder.layers.7.encoder_attn.k_proj.bias', 'model.encoder.layers.2.self_attn_layer_norm.bias', 'model.decoder.layers.4.self_attn.v_proj.bias', 'model.decoder.layers.6.encoder_attn_layer_norm.weight', 'model.encoder.layers.4.self_attn.longformer_self_attn.value_global.bias', 'model.encoder.layers.6.self_attn.longformer_self_attn.query_global.bias', 'model.decoder.layers.4.self_attn.out_proj.weight', 'model.encoder.layers.10.self_attn_layer_norm.bias', 'model.encoder.layers.5.self_attn.longformer_self_attn.value_global.bias', 'model.encoder.layers.6.final_layer_norm.weight', 'model.decoder.layers.9.self_attn_layer_norm.bias', 'model.encoder.layers.10.self_attn.longformer_self_attn.value.bias', 'model.decoder.layers.2.self_attn.q_proj.weight', 'model.decoder.layers.6.self_attn.q_proj.weight', 'model.encoder.layers.11.self_attn_layer_norm.weight', 'model.encoder.layers.4.self_attn.output.bias', 'model.encoder.layers.6.self_attn.longformer_self_attn.key_global.weight', 'model.encoder.layers.9.self_attn.longformer_self_attn.value_global.weight', 'model.encoder.layers.11.self_attn.longformer_self_attn.query.weight', 'model.encoder.layers.4.fc2.bias', 'model.encoder.layers.2.self_attn.longformer_self_attn.query.bias', 'model.decoder.layers.6.fc1.weight', 'model.decoder.layers.0.fc2.weight', 'model.decoder.layers.0.self_attn.v_proj.weight', 'model.decoder.layers.8.final_layer_norm.weight', 'model.decoder.layers.5.fc2.bias', 'model.encoder.layers.9.fc1.weight', 'model.decoder.layers.10.encoder_attn.k_proj.bias', 'model.decoder.embed_tokens.weight', 'model.decoder.layers.9.fc1.bias', 'model.decoder.layers.1.self_attn.v_proj.bias', 'model.decoder.layers.1.self_attn.v_proj.weight', 'model.decoder.layers.6.encoder_attn.v_proj.weight', 'model.decoder.layers.10.encoder_attn.v_proj.weight', 'model.decoder.layers.9.encoder_attn.k_proj.bias', 'model.encoder.layers.1.self_attn_layer_norm.bias', 'model.decoder.layers.10.self_attn.k_proj.bias', 'model.decoder.layers.10.fc2.bias', 'model.encoder.layers.10.self_attn.longformer_self_attn.value_global.weight', 'model.decoder.layers.5.self_attn.v_proj.bias', 'model.decoder.layers.1.self_attn.q_proj.bias']\n",
      "- This IS expected if you are initializing TFLongformerModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFLongformerModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFLongformerModel were not initialized from the PyTorch model and are newly initialized: ['embeddings.word_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.position_embeddings.weight', 'embeddings.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.query_global.weight', 'encoder.layer.0.attention.self.query_global.bias', 'encoder.layer.0.attention.self.key_global.weight', 'encoder.layer.0.attention.self.key_global.bias', 'encoder.layer.0.attention.self.value_global.weight', 'encoder.layer.0.attention.self.value_global.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.query_global.weight', 'encoder.layer.1.attention.self.query_global.bias', 'encoder.layer.1.attention.self.key_global.weight', 'encoder.layer.1.attention.self.key_global.bias', 'encoder.layer.1.attention.self.value_global.weight', 'encoder.layer.1.attention.self.value_global.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.query_global.weight', 'encoder.layer.2.attention.self.query_global.bias', 'encoder.layer.2.attention.self.key_global.weight', 'encoder.layer.2.attention.self.key_global.bias', 'encoder.layer.2.attention.self.value_global.weight', 'encoder.layer.2.attention.self.value_global.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.query_global.weight', 'encoder.layer.3.attention.self.query_global.bias', 'encoder.layer.3.attention.self.key_global.weight', 'encoder.layer.3.attention.self.key_global.bias', 'encoder.layer.3.attention.self.value_global.weight', 'encoder.layer.3.attention.self.value_global.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.query_global.weight', 'encoder.layer.4.attention.self.query_global.bias', 'encoder.layer.4.attention.self.key_global.weight', 'encoder.layer.4.attention.self.key_global.bias', 'encoder.layer.4.attention.self.value_global.weight', 'encoder.layer.4.attention.self.value_global.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.query_global.weight', 'encoder.layer.5.attention.self.query_global.bias', 'encoder.layer.5.attention.self.key_global.weight', 'encoder.layer.5.attention.self.key_global.bias', 'encoder.layer.5.attention.self.value_global.weight', 'encoder.layer.5.attention.self.value_global.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.query_global.weight', 'encoder.layer.6.attention.self.query_global.bias', 'encoder.layer.6.attention.self.key_global.weight', 'encoder.layer.6.attention.self.key_global.bias', 'encoder.layer.6.attention.self.value_global.weight', 'encoder.layer.6.attention.self.value_global.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.query_global.weight', 'encoder.layer.7.attention.self.query_global.bias', 'encoder.layer.7.attention.self.key_global.weight', 'encoder.layer.7.attention.self.key_global.bias', 'encoder.layer.7.attention.self.value_global.weight', 'encoder.layer.7.attention.self.value_global.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.query_global.weight', 'encoder.layer.8.attention.self.query_global.bias', 'encoder.layer.8.attention.self.key_global.weight', 'encoder.layer.8.attention.self.key_global.bias', 'encoder.layer.8.attention.self.value_global.weight', 'encoder.layer.8.attention.self.value_global.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.query_global.weight', 'encoder.layer.9.attention.self.query_global.bias', 'encoder.layer.9.attention.self.key_global.weight', 'encoder.layer.9.attention.self.key_global.bias', 'encoder.layer.9.attention.self.value_global.weight', 'encoder.layer.9.attention.self.value_global.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.query_global.weight', 'encoder.layer.10.attention.self.query_global.bias', 'encoder.layer.10.attention.self.key_global.weight', 'encoder.layer.10.attention.self.key_global.bias', 'encoder.layer.10.attention.self.value_global.weight', 'encoder.layer.10.attention.self.value_global.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.query_global.weight', 'encoder.layer.11.attention.self.query_global.bias', 'encoder.layer.11.attention.self.key_global.weight', 'encoder.layer.11.attention.self.key_global.bias', 'encoder.layer.11.attention.self.value_global.weight', 'encoder.layer.11.attention.self.value_global.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'pooler.dense.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFLongformerModel: ['model.decoder.layers.3.final_layer_norm.weight', 'model.encoder.layers.2.self_attn.longformer_self_attn.query_global.weight', 'model.encoder.layers.6.self_attn.longformer_self_attn.value_global.bias', 'model.encoder.layers.9.self_attn_layer_norm.bias', 'model.decoder.layers.11.encoder_attn.k_proj.bias', 'model.encoder.layernorm_embedding.weight', 'model.decoder.layers.11.self_attn.v_proj.weight', 'model.encoder.layers.2.self_attn.longformer_self_attn.value_global.weight', 'model.encoder.layers.0.self_attn.longformer_self_attn.value.weight', 'model.encoder.layers.1.fc2.weight', 'model.decoder.layers.9.self_attn.v_proj.bias', 'model.decoder.layers.9.encoder_attn.v_proj.weight', 'model.decoder.layers.1.encoder_attn.q_proj.weight', 'model.decoder.layers.0.encoder_attn.v_proj.weight', 'model.decoder.layers.11.fc2.bias', 'model.decoder.layers.8.self_attn.q_proj.bias', 'model.decoder.layers.3.encoder_attn.q_proj.weight', 'model.decoder.layers.11.self_attn.v_proj.bias', 'model.encoder.layers.7.self_attn.longformer_self_attn.value_global.weight', 'model.decoder.layers.7.self_attn.v_proj.bias', 'model.decoder.layernorm_embedding.bias', 'model.decoder.layers.0.encoder_attn.out_proj.bias', 'model.decoder.layers.2.encoder_attn.k_proj.weight', 'model.encoder.layers.1.self_attn.output.weight', 'model.encoder.layers.3.self_attn.longformer_self_attn.value.bias', 'model.encoder.layers.3.self_attn.longformer_self_attn.query.bias', 'model.decoder.layers.4.fc2.weight', 'model.encoder.layers.3.self_attn.longformer_self_attn.value.weight', 'model.encoder.layers.5.self_attn_layer_norm.bias', 'model.decoder.layers.8.encoder_attn.out_proj.weight', 'model.encoder.layers.10.self_attn.longformer_self_attn.key_global.bias', 'model.encoder.layers.2.final_layer_norm.bias', 'model.decoder.layers.7.self_attn.k_proj.bias', 'model.decoder.layers.11.final_layer_norm.weight', 'model.decoder.layers.10.self_attn.k_proj.weight', 'model.encoder.layers.3.self_attn.output.bias', 'model.decoder.layers.8.self_attn.out_proj.weight', 'model.decoder.layers.0.encoder_attn.out_proj.weight', 'model.encoder.layers.0.fc1.bias', 'model.encoder.layers.7.fc2.bias', 'model.encoder.layers.8.self_attn.longformer_self_attn.value.weight', 'model.encoder.layers.5.self_attn.longformer_self_attn.query.weight', 'model.decoder.layers.2.self_attn_layer_norm.weight', 'model.decoder.layers.7.self_attn.out_proj.weight', 'model.encoder.layers.11.self_attn.longformer_self_attn.key.bias', 'model.encoder.layers.2.self_attn.longformer_self_attn.key.bias', 'model.encoder.layers.3.self_attn.longformer_self_attn.query_global.weight', 'model.encoder.layers.10.self_attn.longformer_self_attn.value_global.bias', 'model.decoder.layers.3.encoder_attn.v_proj.weight', 'model.encoder.layers.10.final_layer_norm.weight', 'model.decoder.layers.1.self_attn.out_proj.weight', 'model.decoder.layers.6.encoder_attn.out_proj.bias', 'model.decoder.layers.7.encoder_attn.v_proj.bias', 'model.encoder.layers.7.final_layer_norm.bias', 'model.encoder.layers.8.self_attn.longformer_self_attn.query.weight', 'model.encoder.layers.5.self_attn.longformer_self_attn.query_global.weight', 'model.decoder.layers.2.self_attn.out_proj.bias', 'model.encoder.layers.6.self_attn_layer_norm.weight', 'model.decoder.layers.4.self_attn_layer_norm.bias', 'model.encoder.layers.4.self_attn.longformer_self_attn.key.bias', 'model.decoder.layers.6.self_attn.v_proj.weight', 'model.encoder.layers.4.fc1.weight', 'model.decoder.layers.6.self_attn.out_proj.weight', 'model.decoder.layers.2.fc1.bias', 'model.decoder.layers.7.final_layer_norm.weight', 'model.decoder.layers.9.encoder_attn.q_proj.weight', 'model.decoder.layers.10.self_attn.out_proj.weight', 'model.encoder.layers.2.self_attn.longformer_self_attn.query_global.bias', 'model.encoder.layers.11.fc2.weight', 'model.encoder.layers.4.final_layer_norm.bias', 'model.decoder.layers.2.self_attn.out_proj.weight', 'model.decoder.layers.7.self_attn_layer_norm.weight', 'model.decoder.layers.4.encoder_attn.q_proj.weight', 'model.decoder.layers.11.encoder_attn_layer_norm.bias', 'model.encoder.layers.9.fc1.bias', 'model.decoder.layers.11.self_attn.k_proj.weight', 'model.encoder.layers.3.self_attn.longformer_self_attn.value_global.bias', 'model.decoder.layers.9.encoder_attn_layer_norm.bias', 'model.encoder.layers.7.self_attn.output.bias', 'model.encoder.layers.4.self_attn.longformer_self_attn.query.bias', 'model.decoder.layers.1.final_layer_norm.bias', 'model.encoder.layers.9.self_attn.longformer_self_attn.value.bias', 'final_logits_bias', 'model.encoder.layers.9.self_attn.output.weight', 'model.decoder.layers.1.self_attn.out_proj.bias', 'model.encoder.layers.11.self_attn.longformer_self_attn.query_global.weight', 'model.decoder.layers.4.self_attn_layer_norm.weight', 'model.encoder.layers.1.self_attn.longformer_self_attn.key.bias', 'model.encoder.layers.0.self_attn.longformer_self_attn.query.bias', 'model.decoder.layers.4.fc2.bias', 'model.decoder.layers.11.encoder_attn_layer_norm.weight', 'model.decoder.layers.2.encoder_attn.q_proj.weight', 'model.encoder.layers.0.self_attn.output.weight', 'model.encoder.layers.11.self_attn.longformer_self_attn.value_global.bias', 'model.encoder.layers.0.self_attn.longformer_self_attn.value.bias', 'model.decoder.layers.4.encoder_attn.k_proj.bias', 'model.encoder.layers.2.self_attn.output.weight', 'model.encoder.layers.5.self_attn.longformer_self_attn.value.bias', 'model.encoder.layers.1.self_attn.longformer_self_attn.query.weight', 'model.encoder.layers.10.self_attn.longformer_self_attn.query_global.bias', 'model.encoder.layers.11.fc1.bias', 'model.decoder.layers.6.self_attn_layer_norm.bias', 'model.decoder.layers.3.self_attn_layer_norm.bias', 'model.encoder.layers.0.fc2.bias', 'model.encoder.layers.3.self_attn.longformer_self_attn.key.weight', 'model.decoder.layers.3.fc2.bias', 'model.decoder.layers.0.final_layer_norm.weight', 'model.encoder.layers.9.final_layer_norm.weight', 'model.decoder.layers.7.encoder_attn.out_proj.bias', 'model.encoder.layers.9.self_attn.longformer_self_attn.query_global.weight', 'model.decoder.layers.9.encoder_attn.out_proj.bias', 'model.decoder.layers.2.fc1.weight', 'model.decoder.layers.6.encoder_attn.k_proj.weight', 'model.encoder.layers.7.self_attn.output.weight', 'model.encoder.layers.7.self_attn.longformer_self_attn.query.weight', 'model.decoder.layers.7.self_attn.q_proj.weight', 'model.encoder.layers.5.fc1.weight', 'model.decoder.layers.9.self_attn.q_proj.bias', 'model.decoder.layers.10.self_attn.out_proj.bias', 'model.encoder.layers.5.self_attn.longformer_self_attn.key_global.bias', 'model.encoder.layers.8.self_attn.output.weight', 'model.decoder.layers.2.encoder_attn_layer_norm.weight', 'model.encoder.layers.8.self_attn.longformer_self_attn.query_global.weight', 'model.encoder.layers.10.self_attn.output.weight', 'model.encoder.layers.1.self_attn.longformer_self_attn.key_global.bias', 'model.decoder.layers.0.encoder_attn.k_proj.bias', 'model.decoder.layers.4.encoder_attn.v_proj.weight', 'model.encoder.layers.2.final_layer_norm.weight', 'model.encoder.layers.11.self_attn.longformer_self_attn.key.weight', 'model.decoder.layers.6.fc1.bias', 'model.encoder.layers.7.self_attn.longformer_self_attn.value.weight', 'model.decoder.layers.0.self_attn.q_proj.weight', 'model.decoder.layers.6.encoder_attn.out_proj.weight', 'model.decoder.layers.5.final_layer_norm.bias', 'model.encoder.layers.6.self_attn.longformer_self_attn.query.weight', 'model.encoder.layers.1.final_layer_norm.weight', 'model.encoder.layers.9.self_attn.longformer_self_attn.query.weight', 'model.decoder.layers.1.encoder_attn_layer_norm.bias', 'model.decoder.layers.0.self_attn.out_proj.bias', 'model.decoder.layers.3.final_layer_norm.bias', 'model.decoder.layers.1.encoder_attn.k_proj.weight', 'model.encoder.layers.1.self_attn.longformer_self_attn.value_global.weight', 'model.encoder.layers.3.self_attn.longformer_self_attn.value_global.weight', 'model.encoder.layers.7.fc1.bias', 'model.encoder.layers.6.self_attn.longformer_self_attn.query.bias', 'model.decoder.layers.8.encoder_attn.k_proj.bias', 'model.decoder.layers.10.encoder_attn_layer_norm.bias', 'model.encoder.layers.8.self_attn.longformer_self_attn.key_global.bias', 'model.encoder.layers.5.self_attn.longformer_self_attn.key.weight', 'model.encoder.layers.8.fc1.weight', 'model.decoder.layers.8.encoder_attn.q_proj.bias', 'model.encoder.layers.7.self_attn_layer_norm.bias', 'model.decoder.layers.8.fc1.weight', 'model.decoder.layers.10.fc2.weight', 'model.encoder.layers.5.self_attn.longformer_self_attn.query.bias', 'model.decoder.layers.0.encoder_attn_layer_norm.weight', 'model.encoder.layers.7.self_attn.longformer_self_attn.query_global.bias', 'model.encoder.layers.1.fc1.weight', 'model.encoder.layers.5.self_attn.longformer_self_attn.key.bias', 'model.encoder.layers.6.final_layer_norm.bias', 'model.decoder.layers.2.final_layer_norm.bias', 'model.decoder.layers.9.fc2.weight', 'model.decoder.layers.5.self_attn.out_proj.bias', 'model.decoder.layers.5.encoder_attn.k_proj.weight', 'model.decoder.layers.2.self_attn.k_proj.weight', 'model.decoder.layers.7.self_attn.q_proj.bias', 'model.encoder.layers.2.self_attn_layer_norm.weight', 'model.decoder.layers.9.encoder_attn_layer_norm.weight', 'model.encoder.layers.9.self_attn.longformer_self_attn.value.weight', 'model.decoder.layers.6.encoder_attn.q_proj.bias', 'model.decoder.layers.3.fc1.bias', 'model.decoder.layers.3.self_attn.out_proj.weight', 'model.encoder.layers.2.self_attn.longformer_self_attn.key_global.bias', 'model.encoder.layers.5.fc1.bias', 'model.decoder.layers.7.encoder_attn_layer_norm.weight', 'model.decoder.layers.9.self_attn.out_proj.weight', 'model.encoder.layers.3.self_attn_layer_norm.weight', 'model.decoder.layers.7.fc2.bias', 'model.encoder.layers.9.self_attn.longformer_self_attn.key_global.weight', 'model.decoder.layers.2.fc2.weight', 'model.decoder.layers.0.encoder_attn.q_proj.bias', 'model.encoder.layers.7.self_attn.longformer_self_attn.key_global.weight', 'model.decoder.layers.3.self_attn.k_proj.bias', 'model.decoder.layers.7.self_attn.out_proj.bias', 'model.encoder.layers.8.fc2.bias', 'model.decoder.layers.4.encoder_attn_layer_norm.weight', 'model.decoder.layers.8.encoder_attn.v_proj.weight', 'model.encoder.layers.6.self_attn.longformer_self_attn.value.bias', 'model.decoder.layers.2.self_attn.v_proj.bias', 'model.decoder.layers.2.encoder_attn.v_proj.bias', 'model.decoder.layers.9.encoder_attn.v_proj.bias', 'model.encoder.layers.3.final_layer_norm.weight', 'model.encoder.layers.11.self_attn.longformer_self_attn.value.weight', 'model.decoder.layers.11.encoder_attn.q_proj.weight', 'model.decoder.layers.7.encoder_attn.k_proj.weight', 'model.encoder.layers.9.final_layer_norm.bias', 'model.encoder.layers.4.fc2.weight', 'model.decoder.layers.9.self_attn.out_proj.bias', 'model.encoder.layers.2.self_attn.longformer_self_attn.key_global.weight', 'model.encoder.layers.9.fc2.weight', 'model.decoder.layers.0.encoder_attn_layer_norm.bias', 'model.decoder.layers.4.self_attn.q_proj.weight', 'model.encoder.layers.8.self_attn.longformer_self_attn.key.bias', 'model.decoder.layers.0.self_attn_layer_norm.weight', 'model.decoder.layers.1.encoder_attn.out_proj.bias', 'model.decoder.layers.7.self_attn.v_proj.weight', 'model.decoder.layers.9.self_attn.v_proj.weight', 'model.encoder.layers.8.fc2.weight', 'model.encoder.layers.0.self_attn.longformer_self_attn.key_global.bias', 'model.encoder.layers.3.final_layer_norm.bias', 'model.encoder.layers.11.self_attn.longformer_self_attn.key_global.weight', 'model.decoder.layers.10.encoder_attn.k_proj.weight', 'model.decoder.layers.10.encoder_attn.out_proj.weight', 'model.encoder.layers.2.self_attn.longformer_self_attn.value.weight', 'model.decoder.layers.10.self_attn.q_proj.weight', 'model.decoder.layers.7.self_attn_layer_norm.bias', 'model.encoder.layers.6.self_attn.longformer_self_attn.query_global.weight', 'model.encoder.layers.4.self_attn.longformer_self_attn.key_global.weight', 'model.encoder.layers.10.self_attn.longformer_self_attn.query.bias', 'model.encoder.layers.4.self_attn.longformer_self_attn.value.bias', 'model.decoder.layers.1.fc2.bias', 'model.encoder.layers.8.self_attn.longformer_self_attn.query_global.bias', 'model.decoder.layers.3.self_attn.v_proj.weight', 'model.encoder.layers.11.self_attn.longformer_self_attn.value.bias', 'model.decoder.layers.3.encoder_attn.q_proj.bias', 'model.encoder.layers.5.self_attn.longformer_self_attn.key_global.weight', 'model.encoder.layers.1.self_attn.longformer_self_attn.value.bias', 'model.decoder.layers.9.self_attn_layer_norm.weight', 'model.encoder.layers.0.self_attn.longformer_self_attn.value_global.bias', 'model.encoder.layers.7.self_attn.longformer_self_attn.key.weight', 'model.decoder.layers.0.fc1.weight', 'model.encoder.layers.6.self_attn_layer_norm.bias', 'model.encoder.layers.6.fc1.weight', 'model.encoder.layers.10.self_attn_layer_norm.weight', 'model.decoder.layers.0.self_attn_layer_norm.bias', 'model.decoder.layers.1.self_attn.q_proj.weight', 'model.encoder.embed_tokens.weight', 'model.encoder.layers.8.self_attn.longformer_self_attn.value_global.weight', 'model.decoder.layers.2.encoder_attn_layer_norm.bias', 'model.decoder.layers.5.self_attn.v_proj.weight', 'model.encoder.layers.11.fc2.bias', 'model.decoder.layers.6.encoder_attn.k_proj.bias', 'model.decoder.layers.4.final_layer_norm.bias', 'model.decoder.layers.3.self_attn.k_proj.weight', 'model.decoder.layers.3.encoder_attn.v_proj.bias', 'model.encoder.layers.1.self_attn.longformer_self_attn.query_global.bias', 'model.decoder.layers.2.encoder_attn.k_proj.bias', 'model.decoder.layers.3.encoder_attn.out_proj.bias', 'model.decoder.layers.7.fc1.bias', 'model.encoder.layers.9.self_attn_layer_norm.weight', 'model.decoder.layers.9.final_layer_norm.bias', 'model.encoder.layers.6.self_attn.longformer_self_attn.key.bias', 'model.encoder.layers.4.self_attn_layer_norm.bias', 'model.encoder.layers.1.self_attn.longformer_self_attn.query_global.weight', 'model.decoder.layers.11.encoder_attn.v_proj.weight', 'model.encoder.layers.9.self_attn.longformer_self_attn.value_global.bias', 'model.decoder.layers.5.self_attn_layer_norm.bias', 'model.encoder.layers.10.self_attn.longformer_self_attn.query_global.weight', 'model.encoder.layers.7.self_attn.longformer_self_attn.key_global.bias', 'model.encoder.layers.10.final_layer_norm.bias', 'model.encoder.layers.8.fc1.bias', 'model.decoder.layers.3.self_attn.out_proj.bias', 'model.decoder.layers.1.self_attn.k_proj.bias', 'model.decoder.layers.1.encoder_attn.q_proj.bias', 'model.decoder.layers.8.encoder_attn.v_proj.bias', 'model.decoder.layernorm_embedding.weight', 'model.decoder.layers.5.encoder_attn.q_proj.bias', 'model.decoder.layers.8.fc1.bias', 'model.decoder.layers.11.encoder_attn.out_proj.bias', 'model.encoder.layers.10.fc1.weight', 'model.decoder.layers.4.encoder_attn.out_proj.weight', 'model.encoder.embed_positions.weight', 'model.encoder.layers.0.self_attn.longformer_self_attn.query.weight', 'model.decoder.layers.5.self_attn.q_proj.weight', 'model.encoder.layers.3.fc2.weight', 'model.decoder.layers.0.self_attn.k_proj.bias', 'model.decoder.layers.8.self_attn.out_proj.bias', 'model.encoder.layers.5.self_attn.longformer_self_attn.value_global.weight', 'model.decoder.layers.1.encoder_attn.v_proj.bias', 'model.encoder.layers.6.self_attn.output.weight', 'model.encoder.layers.3.fc1.bias', 'model.decoder.layers.5.encoder_attn.out_proj.bias', 'model.encoder.layers.1.self_attn.longformer_self_attn.value_global.bias', 'model.decoder.layers.11.fc1.weight', 'model.encoder.layers.9.fc2.bias', 'model.encoder.layernorm_embedding.bias', 'model.decoder.layers.6.self_attn.v_proj.bias', 'model.encoder.layers.1.self_attn.longformer_self_attn.query.bias', 'model.encoder.layers.10.fc1.bias', 'model.decoder.layers.9.fc2.bias', 'model.decoder.layers.1.self_attn_layer_norm.weight', 'model.decoder.layers.6.self_attn.k_proj.weight', 'model.encoder.layers.0.self_attn.longformer_self_attn.value_global.weight', 'model.decoder.layers.4.self_attn.out_proj.bias', 'model.decoder.layers.5.fc1.weight', 'model.decoder.embed_positions.weight', 'model.encoder.layers.7.self_attn_layer_norm.weight', 'model.encoder.layers.6.self_attn.output.bias', 'model.decoder.layers.7.encoder_attn.q_proj.weight', 'model.decoder.layers.6.self_attn.out_proj.bias', 'model.decoder.layers.10.encoder_attn.out_proj.bias', 'model.decoder.layers.11.self_attn.out_proj.weight', 'model.decoder.layers.1.fc2.weight', 'model.decoder.layers.2.self_attn.q_proj.bias', 'model.decoder.layers.11.self_attn_layer_norm.weight', 'model.encoder.layers.3.fc2.bias', 'model.decoder.layers.1.encoder_attn.v_proj.weight', 'model.decoder.layers.8.self_attn.v_proj.weight', 'model.encoder.layers.1.self_attn_layer_norm.weight', 'model.decoder.layers.0.fc2.bias', 'model.encoder.layers.0.self_attn.longformer_self_attn.query_global.bias', 'model.encoder.layers.2.self_attn.longformer_self_attn.query.weight', 'model.decoder.layers.10.self_attn.v_proj.weight', 'model.decoder.layers.5.self_attn.k_proj.bias', 'model.decoder.layers.8.encoder_attn.q_proj.weight', 'model.encoder.layers.5.self_attn.output.bias', 'model.decoder.layers.11.fc2.weight', 'model.encoder.layers.3.self_attn.longformer_self_attn.key.bias', 'model.encoder.layers.9.self_attn.longformer_self_attn.query_global.bias', 'model.decoder.layers.0.self_attn.k_proj.weight', 'model.encoder.layers.9.self_attn.longformer_self_attn.key.bias', 'model.encoder.layers.4.self_attn.longformer_self_attn.key_global.bias', 'model.encoder.layers.6.fc2.bias', 'model.decoder.layers.0.self_attn.q_proj.bias', 'model.encoder.layers.6.self_attn.longformer_self_attn.value.weight', 'model.encoder.layers.8.self_attn.longformer_self_attn.value_global.bias', 'model.encoder.layers.10.self_attn.output.bias', 'model.decoder.layers.4.self_attn.v_proj.weight', 'model.decoder.layers.1.final_layer_norm.weight', 'model.encoder.layers.1.self_attn.longformer_self_attn.value.weight', 'model.encoder.layers.10.fc2.weight', 'model.encoder.layers.11.self_attn_layer_norm.bias', 'model.decoder.layers.2.self_attn.v_proj.weight', 'model.encoder.layers.8.self_attn_layer_norm.weight', 'model.encoder.layers.4.self_attn.longformer_self_attn.key.weight', 'model.decoder.layers.11.encoder_attn.v_proj.bias', 'model.encoder.layers.2.self_attn.output.bias', 'model.decoder.layers.6.final_layer_norm.weight', 'model.decoder.layers.4.fc1.bias', 'model.encoder.layers.7.self_attn.longformer_self_attn.value_global.bias', 'model.encoder.layers.9.self_attn.longformer_self_attn.key_global.bias', 'model.decoder.layers.10.fc1.bias', 'model.encoder.layers.0.self_attn.longformer_self_attn.query_global.weight', 'model.decoder.layers.1.self_attn.k_proj.weight', 'model.encoder.layers.8.self_attn.longformer_self_attn.key_global.weight', 'model.decoder.layers.9.encoder_attn.k_proj.weight', 'model.encoder.layers.7.self_attn.longformer_self_attn.query_global.weight', 'model.decoder.layers.2.encoder_attn.v_proj.weight', 'model.decoder.layers.6.self_attn.q_proj.bias', 'model.decoder.layers.1.self_attn_layer_norm.bias', 'model.decoder.layers.8.self_attn.v_proj.bias', 'model.encoder.layers.2.self_attn.longformer_self_attn.value.bias', 'model.encoder.layers.7.self_attn.longformer_self_attn.value.bias', 'model.decoder.layers.10.final_layer_norm.bias', 'model.encoder.layers.11.self_attn.longformer_self_attn.query_global.bias', 'model.encoder.layers.4.self_attn.longformer_self_attn.value_global.weight', 'model.decoder.layers.1.encoder_attn.out_proj.weight', 'model.decoder.layers.11.self_attn.out_proj.bias', 'model.decoder.layers.11.encoder_attn.q_proj.bias', 'model.decoder.layers.2.encoder_attn.q_proj.bias', 'model.encoder.layers.4.self_attn.longformer_self_attn.query_global.weight', 'model.decoder.layers.0.fc1.bias', 'model.encoder.layers.4.self_attn.longformer_self_attn.query.weight', 'model.encoder.layers.5.self_attn.longformer_self_attn.value.weight', 'model.encoder.layers.10.self_attn.longformer_self_attn.key_global.weight', 'model.encoder.layers.4.self_attn.output.weight', 'model.decoder.layers.10.self_attn_layer_norm.weight', 'model.decoder.layers.0.final_layer_norm.bias', 'model.encoder.layers.5.self_attn.output.weight', 'model.decoder.layers.5.encoder_attn.q_proj.weight', 'model.encoder.layers.9.self_attn.longformer_self_attn.query.bias', 'model.encoder.layers.2.fc2.bias', 'model.encoder.layers.5.final_layer_norm.weight', 'model.encoder.layers.8.self_attn.longformer_self_attn.value.bias', 'model.encoder.layers.6.fc2.weight', 'model.decoder.layers.8.encoder_attn.out_proj.bias', 'model.decoder.layers.6.encoder_attn_layer_norm.bias', 'model.decoder.layers.3.encoder_attn_layer_norm.weight', 'model.decoder.layers.2.final_layer_norm.weight', 'model.encoder.layers.0.self_attn.output.bias', 'model.encoder.layers.6.fc1.bias', 'model.decoder.layers.4.encoder_attn.k_proj.weight', 'model.decoder.layers.8.encoder_attn_layer_norm.bias', 'model.encoder.layers.10.self_attn.longformer_self_attn.value.weight', 'model.decoder.layers.5.final_layer_norm.weight', 'model.decoder.layers.5.self_attn.q_proj.bias', 'model.decoder.layers.4.encoder_attn_layer_norm.bias', 'model.encoder.layers.3.fc1.weight', 'model.decoder.layers.5.fc2.weight', 'model.encoder.layers.3.self_attn.longformer_self_attn.key_global.bias', 'model.encoder.layers.0.self_attn.longformer_self_attn.key.bias', 'model.encoder.layers.0.final_layer_norm.bias', 'model.decoder.layers.0.encoder_attn.k_proj.weight', 'model.encoder.layers.8.self_attn_layer_norm.bias', 'model.decoder.layers.6.self_attn_layer_norm.weight', 'model.decoder.layers.11.self_attn_layer_norm.bias', 'model.decoder.layers.6.final_layer_norm.bias', 'model.decoder.layers.5.self_attn_layer_norm.weight', 'model.decoder.layers.7.encoder_attn.out_proj.weight', 'model.decoder.layers.5.encoder_attn.k_proj.bias', 'model.encoder.layers.3.self_attn_layer_norm.bias', 'model.encoder.layers.10.self_attn.longformer_self_attn.query.weight', 'model.decoder.layers.6.self_attn.k_proj.bias', 'model.decoder.layers.9.self_attn.k_proj.weight', 'model.decoder.layers.0.self_attn.out_proj.weight', 'model.encoder.layers.0.fc2.weight', 'model.encoder.layers.2.fc1.weight', 'model.decoder.layers.5.encoder_attn.v_proj.bias', 'model.decoder.layers.6.encoder_attn.q_proj.weight', 'model.decoder.layers.6.fc2.bias', 'model.decoder.layers.5.encoder_attn_layer_norm.weight', 'model.encoder.layers.1.self_attn.longformer_self_attn.key.weight', 'model.decoder.layers.6.fc2.weight', 'model.decoder.layers.7.final_layer_norm.bias', 'model.decoder.layers.5.self_attn.out_proj.weight', 'model.encoder.layers.7.self_attn.longformer_self_attn.query.bias', 'model.encoder.layers.7.fc2.weight', 'model.encoder.layers.0.final_layer_norm.weight', 'model.encoder.layers.0.self_attn_layer_norm.bias', 'model.decoder.layers.11.fc1.bias', 'model.decoder.layers.4.final_layer_norm.weight', 'model.decoder.layers.9.fc1.weight', 'model.decoder.layers.3.self_attn_layer_norm.weight', 'model.decoder.layers.3.self_attn.q_proj.bias', 'model.decoder.layers.10.encoder_attn.v_proj.bias', 'model.decoder.layers.2.encoder_attn.out_proj.weight', 'model.decoder.layers.11.final_layer_norm.bias', 'model.decoder.layers.4.encoder_attn.out_proj.bias', 'model.decoder.layers.8.encoder_attn_layer_norm.weight', 'model.encoder.layers.11.final_layer_norm.weight', 'model.decoder.layers.10.self_attn.q_proj.bias', 'model.decoder.layers.0.encoder_attn.v_proj.bias', 'model.encoder.layers.3.self_attn.longformer_self_attn.key_global.weight', 'model.encoder.layers.3.self_attn.longformer_self_attn.query_global.bias', 'model.decoder.layers.4.self_attn.k_proj.weight', 'model.decoder.layers.8.self_attn.k_proj.weight', 'model.encoder.layers.6.self_attn.longformer_self_attn.value_global.weight', 'model.decoder.layers.11.encoder_attn.k_proj.weight', 'model.decoder.layers.3.encoder_attn.k_proj.weight', 'model.encoder.layers.3.self_attn.output.weight', 'model.decoder.layers.2.self_attn.k_proj.bias', 'model.decoder.layers.4.fc1.weight', 'model.decoder.layers.7.fc1.weight', 'model.decoder.layers.8.self_attn_layer_norm.weight', 'model.decoder.layers.10.encoder_attn_layer_norm.weight', 'model.decoder.layers.9.self_attn.k_proj.bias', 'model.decoder.layers.2.encoder_attn.out_proj.bias', 'model.encoder.layers.8.final_layer_norm.weight', 'model.encoder.layers.11.fc1.weight', 'model.encoder.layers.2.self_attn.longformer_self_attn.key.weight', 'model.encoder.layers.10.fc2.bias', 'model.decoder.layers.10.fc1.weight', 'model.decoder.layers.10.final_layer_norm.weight', 'model.encoder.layers.1.self_attn.output.bias', 'model.decoder.layers.4.self_attn.k_proj.bias', 'model.encoder.layers.1.fc2.bias', 'model.encoder.layers.11.self_attn.longformer_self_attn.key_global.bias', 'model.decoder.layers.11.self_attn.q_proj.bias', 'model.encoder.layers.5.fc2.bias', 'model.encoder.layers.11.self_attn.output.weight', 'model.encoder.layers.2.fc2.weight', 'model.encoder.layers.0.self_attn.longformer_self_attn.key.weight', 'model.encoder.layers.2.self_attn.longformer_self_attn.value_global.bias', 'model.encoder.layers.10.self_attn.longformer_self_attn.key.weight', 'model.decoder.layers.6.encoder_attn.v_proj.bias', 'model.decoder.layers.7.self_attn.k_proj.weight', 'model.encoder.layers.0.self_attn.longformer_self_attn.key_global.weight', 'model.decoder.layers.10.self_attn_layer_norm.bias', 'model.decoder.layers.11.self_attn.k_proj.bias', 'model.decoder.layers.10.self_attn.v_proj.bias', 'model.encoder.layers.1.final_layer_norm.bias', 'model.shared.weight', 'model.encoder.layers.4.self_attn_layer_norm.weight', 'model.encoder.layers.8.self_attn.longformer_self_attn.key.weight', 'model.decoder.layers.10.encoder_attn.q_proj.bias', 'model.decoder.layers.11.self_attn.q_proj.weight', 'model.decoder.layers.11.encoder_attn.out_proj.weight', 'model.decoder.layers.3.self_attn.v_proj.bias', 'model.encoder.layers.0.fc1.weight', 'model.decoder.layers.5.encoder_attn.out_proj.weight', 'model.encoder.layers.4.final_layer_norm.weight', 'model.decoder.layers.5.encoder_attn.v_proj.weight', 'model.encoder.layers.8.self_attn.output.bias', 'model.decoder.layers.2.fc2.bias', 'model.decoder.layers.7.encoder_attn.v_proj.weight', 'model.encoder.layers.8.final_layer_norm.bias', 'model.decoder.layers.9.encoder_attn.q_proj.bias', 'model.encoder.layers.5.self_attn_layer_norm.weight', 'model.decoder.layers.7.encoder_attn_layer_norm.bias', 'model.encoder.layers.5.self_attn.longformer_self_attn.query_global.bias', 'model.decoder.layers.4.encoder_attn.v_proj.bias', 'model.decoder.layers.0.self_attn.v_proj.bias', 'model.decoder.layers.3.encoder_attn.k_proj.bias', 'model.decoder.layers.1.fc1.bias', 'model.decoder.layers.5.fc1.bias', 'model.encoder.layers.8.self_attn.longformer_self_attn.query.bias', 'model.decoder.layers.8.self_attn.q_proj.weight', 'model.encoder.layers.1.fc1.bias', 'model.encoder.layers.1.self_attn.longformer_self_attn.key_global.weight', 'model.decoder.layers.1.encoder_attn_layer_norm.weight', 'model.decoder.layers.10.encoder_attn.q_proj.weight', 'model.encoder.layers.7.fc1.weight', 'model.encoder.layers.11.final_layer_norm.bias', 'model.encoder.layers.4.fc1.bias', 'model.decoder.layers.5.encoder_attn_layer_norm.bias', 'model.encoder.layers.7.self_attn.longformer_self_attn.key.bias', 'model.decoder.layers.3.fc2.weight', 'model.encoder.layers.9.self_attn.longformer_self_attn.key.weight', 'model.encoder.layers.9.self_attn.output.bias', 'model.decoder.layers.3.encoder_attn.out_proj.weight', 'model.decoder.layers.4.self_attn.q_proj.bias', 'model.decoder.layers.1.encoder_attn.k_proj.bias', 'model.decoder.layers.2.self_attn_layer_norm.bias', 'model.encoder.layers.6.self_attn.longformer_self_attn.key.weight', 'model.decoder.layers.8.fc2.weight', 'model.encoder.layers.11.self_attn.output.bias', 'model.decoder.layers.9.self_attn.q_proj.weight', 'model.decoder.layers.7.fc2.weight', 'model.encoder.layers.3.self_attn.longformer_self_attn.query.weight', 'model.encoder.layers.6.self_attn.longformer_self_attn.key_global.bias', 'model.decoder.layers.3.encoder_attn_layer_norm.bias', 'model.encoder.layers.4.self_attn.longformer_self_attn.query_global.bias', 'model.decoder.layers.8.final_layer_norm.bias', 'model.decoder.layers.1.fc1.weight', 'model.decoder.layers.9.encoder_attn.out_proj.weight', 'model.decoder.layers.8.self_attn_layer_norm.bias', 'model.decoder.layers.7.encoder_attn.q_proj.bias', 'model.decoder.layers.4.encoder_attn.q_proj.bias', 'model.encoder.layers.5.fc2.weight', 'model.encoder.layers.7.final_layer_norm.weight', 'model.encoder.layers.10.self_attn.longformer_self_attn.key.bias', 'model.decoder.layers.8.encoder_attn.k_proj.weight', 'model.decoder.layers.9.final_layer_norm.weight', 'model.decoder.layers.3.fc1.weight', 'model.decoder.layers.5.self_attn.k_proj.weight', 'model.encoder.layers.11.self_attn.longformer_self_attn.query.bias', 'model.encoder.layers.4.self_attn.longformer_self_attn.value.weight', 'model.encoder.layers.0.self_attn_layer_norm.weight', 'model.encoder.layers.2.fc1.bias', 'model.decoder.layers.3.self_attn.q_proj.weight', 'model.decoder.layers.8.fc2.bias', 'model.encoder.layers.5.final_layer_norm.bias', 'model.encoder.layers.11.self_attn.longformer_self_attn.value_global.weight', 'model.decoder.layers.0.encoder_attn.q_proj.weight', 'model.decoder.layers.8.self_attn.k_proj.bias', 'model.decoder.layers.7.encoder_attn.k_proj.bias', 'model.encoder.layers.2.self_attn_layer_norm.bias', 'model.decoder.layers.4.self_attn.v_proj.bias', 'model.decoder.layers.6.encoder_attn_layer_norm.weight', 'model.encoder.layers.4.self_attn.longformer_self_attn.value_global.bias', 'model.encoder.layers.6.self_attn.longformer_self_attn.query_global.bias', 'model.decoder.layers.4.self_attn.out_proj.weight', 'model.encoder.layers.10.self_attn_layer_norm.bias', 'model.encoder.layers.5.self_attn.longformer_self_attn.value_global.bias', 'model.encoder.layers.6.final_layer_norm.weight', 'model.decoder.layers.9.self_attn_layer_norm.bias', 'model.encoder.layers.10.self_attn.longformer_self_attn.value.bias', 'model.decoder.layers.2.self_attn.q_proj.weight', 'model.decoder.layers.6.self_attn.q_proj.weight', 'model.encoder.layers.11.self_attn_layer_norm.weight', 'model.encoder.layers.4.self_attn.output.bias', 'model.encoder.layers.6.self_attn.longformer_self_attn.key_global.weight', 'model.encoder.layers.9.self_attn.longformer_self_attn.value_global.weight', 'model.encoder.layers.11.self_attn.longformer_self_attn.query.weight', 'model.encoder.layers.4.fc2.bias', 'model.encoder.layers.2.self_attn.longformer_self_attn.query.bias', 'model.decoder.layers.6.fc1.weight', 'model.decoder.layers.0.fc2.weight', 'model.decoder.layers.0.self_attn.v_proj.weight', 'model.decoder.layers.8.final_layer_norm.weight', 'model.decoder.layers.5.fc2.bias', 'model.encoder.layers.9.fc1.weight', 'model.decoder.layers.10.encoder_attn.k_proj.bias', 'model.decoder.embed_tokens.weight', 'model.decoder.layers.9.fc1.bias', 'model.decoder.layers.1.self_attn.v_proj.bias', 'model.decoder.layers.1.self_attn.v_proj.weight', 'model.decoder.layers.6.encoder_attn.v_proj.weight', 'model.decoder.layers.10.encoder_attn.v_proj.weight', 'model.decoder.layers.9.encoder_attn.k_proj.bias', 'model.encoder.layers.1.self_attn_layer_norm.bias', 'model.decoder.layers.10.self_attn.k_proj.bias', 'model.decoder.layers.10.fc2.bias', 'model.encoder.layers.10.self_attn.longformer_self_attn.value_global.weight', 'model.decoder.layers.5.self_attn.v_proj.bias', 'model.decoder.layers.1.self_attn.q_proj.bias']\n",
      "- This IS expected if you are initializing TFLongformerModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFLongformerModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFLongformerModel were not initialized from the PyTorch model and are newly initialized: ['embeddings.word_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.position_embeddings.weight', 'embeddings.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.query_global.weight', 'encoder.layer.0.attention.self.query_global.bias', 'encoder.layer.0.attention.self.key_global.weight', 'encoder.layer.0.attention.self.key_global.bias', 'encoder.layer.0.attention.self.value_global.weight', 'encoder.layer.0.attention.self.value_global.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.query_global.weight', 'encoder.layer.1.attention.self.query_global.bias', 'encoder.layer.1.attention.self.key_global.weight', 'encoder.layer.1.attention.self.key_global.bias', 'encoder.layer.1.attention.self.value_global.weight', 'encoder.layer.1.attention.self.value_global.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.query_global.weight', 'encoder.layer.2.attention.self.query_global.bias', 'encoder.layer.2.attention.self.key_global.weight', 'encoder.layer.2.attention.self.key_global.bias', 'encoder.layer.2.attention.self.value_global.weight', 'encoder.layer.2.attention.self.value_global.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.query_global.weight', 'encoder.layer.3.attention.self.query_global.bias', 'encoder.layer.3.attention.self.key_global.weight', 'encoder.layer.3.attention.self.key_global.bias', 'encoder.layer.3.attention.self.value_global.weight', 'encoder.layer.3.attention.self.value_global.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.query_global.weight', 'encoder.layer.4.attention.self.query_global.bias', 'encoder.layer.4.attention.self.key_global.weight', 'encoder.layer.4.attention.self.key_global.bias', 'encoder.layer.4.attention.self.value_global.weight', 'encoder.layer.4.attention.self.value_global.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.query_global.weight', 'encoder.layer.5.attention.self.query_global.bias', 'encoder.layer.5.attention.self.key_global.weight', 'encoder.layer.5.attention.self.key_global.bias', 'encoder.layer.5.attention.self.value_global.weight', 'encoder.layer.5.attention.self.value_global.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.query_global.weight', 'encoder.layer.6.attention.self.query_global.bias', 'encoder.layer.6.attention.self.key_global.weight', 'encoder.layer.6.attention.self.key_global.bias', 'encoder.layer.6.attention.self.value_global.weight', 'encoder.layer.6.attention.self.value_global.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.query_global.weight', 'encoder.layer.7.attention.self.query_global.bias', 'encoder.layer.7.attention.self.key_global.weight', 'encoder.layer.7.attention.self.key_global.bias', 'encoder.layer.7.attention.self.value_global.weight', 'encoder.layer.7.attention.self.value_global.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.query_global.weight', 'encoder.layer.8.attention.self.query_global.bias', 'encoder.layer.8.attention.self.key_global.weight', 'encoder.layer.8.attention.self.key_global.bias', 'encoder.layer.8.attention.self.value_global.weight', 'encoder.layer.8.attention.self.value_global.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.query_global.weight', 'encoder.layer.9.attention.self.query_global.bias', 'encoder.layer.9.attention.self.key_global.weight', 'encoder.layer.9.attention.self.key_global.bias', 'encoder.layer.9.attention.self.value_global.weight', 'encoder.layer.9.attention.self.value_global.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.query_global.weight', 'encoder.layer.10.attention.self.query_global.bias', 'encoder.layer.10.attention.self.key_global.weight', 'encoder.layer.10.attention.self.key_global.bias', 'encoder.layer.10.attention.self.value_global.weight', 'encoder.layer.10.attention.self.value_global.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.query_global.weight', 'encoder.layer.11.attention.self.query_global.bias', 'encoder.layer.11.attention.self.key_global.weight', 'encoder.layer.11.attention.self.key_global.bias', 'encoder.layer.11.attention.self.value_global.weight', 'encoder.layer.11.attention.self.value_global.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'pooler.dense.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer 'tf_longformer_model' (type TFLongformerModel).\n\nData of type <class 'keras.src.backend.common.keras_tensor.KerasTensor'> is not allowed only (<class 'tensorflow.python.framework.tensor.Tensor'>, <class 'bool'>, <class 'int'>, <class 'transformers.utils.generic.ModelOutput'>, <class 'tuple'>, <class 'list'>, <class 'dict'>, <class 'numpy.ndarray'>) is accepted for attention_mask.\n\nCall arguments received by layer 'tf_longformer_model' (type TFLongformerModel):\n   input_ids=<KerasTensor shape=(None, 16000), dtype=int32, sparse=False, name=keras_tensor>\n   attention_mask=<KerasTensor shape=(None, 16000), dtype=int32, sparse=False, name=keras_tensor_2>\n   head_mask=None\n   global_attention_mask=None\n   token_type_ids=<KerasTensor shape=(None, 16000), dtype=int32, sparse=False, name=keras_tensor_4>\n   position_ids=None\n   inputs_embeds=None\n   output_attentions=None\n   output_hidden_states=None\n   return_dict=None\n   training=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mdual_longformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m      3\u001b[0m     input_train, y_train,\n\u001b[1;32m      4\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[SaveModelCallback()]\n\u001b[1;32m      9\u001b[0m )\n",
      "Cell \u001b[0;32mIn[9], line 19\u001b[0m, in \u001b[0;36mdual_longformer\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m longformer_model1 \u001b[38;5;241m=\u001b[39m TFLongformerModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(MODEL_NAME, config\u001b[38;5;241m=\u001b[39mconfig, from_pt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,ignore_mismatched_sizes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     17\u001b[0m longformer_model2 \u001b[38;5;241m=\u001b[39m TFLongformerModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(MODEL_NAME, config\u001b[38;5;241m=\u001b[39mconfig, from_pt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, ignore_mismatched_sizes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 19\u001b[0m embedding1 \u001b[38;5;241m=\u001b[39m \u001b[43mlongformer_model1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mid1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43matn1\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     20\u001b[0m embedding2 \u001b[38;5;241m=\u001b[39m longformer_model2(id2, attention_mask\u001b[38;5;241m=\u001b[39mmask2, token_type_ids\u001b[38;5;241m=\u001b[39matn2)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     22\u001b[0m x1 \u001b[38;5;241m=\u001b[39m GlobalAveragePooling1D()(embedding1)\n",
      "File \u001b[0;32m~/miniconda3/envs/longformer/lib/python3.11/site-packages/tf_keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/longformer/lib/python3.11/site-packages/transformers/modeling_tf_utils.py:436\u001b[0m, in \u001b[0;36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    434\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\n\u001b[0;32m--> 436\u001b[0m unpacked_inputs \u001b[38;5;241m=\u001b[39m \u001b[43minput_processing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args_and_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munpacked_inputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/longformer/lib/python3.11/site-packages/transformers/modeling_tf_utils.py:513\u001b[0m, in \u001b[0;36minput_processing\u001b[0;34m(func, config, **kwargs)\u001b[0m\n\u001b[1;32m    511\u001b[0m         output[k] \u001b[38;5;241m=\u001b[39m v\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 513\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(v)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not allowed only \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mallowed_types\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is accepted for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(main_input, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, \u001b[38;5;28minput\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(main_input):\n\u001b[1;32m    517\u001b[0m         \u001b[38;5;66;03m# EagerTensors don't allow to use the .name property so we check for a real Tensor\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer 'tf_longformer_model' (type TFLongformerModel).\n\nData of type <class 'keras.src.backend.common.keras_tensor.KerasTensor'> is not allowed only (<class 'tensorflow.python.framework.tensor.Tensor'>, <class 'bool'>, <class 'int'>, <class 'transformers.utils.generic.ModelOutput'>, <class 'tuple'>, <class 'list'>, <class 'dict'>, <class 'numpy.ndarray'>) is accepted for attention_mask.\n\nCall arguments received by layer 'tf_longformer_model' (type TFLongformerModel):\n   input_ids=<KerasTensor shape=(None, 16000), dtype=int32, sparse=False, name=keras_tensor>\n   attention_mask=<KerasTensor shape=(None, 16000), dtype=int32, sparse=False, name=keras_tensor_2>\n   head_mask=None\n   global_attention_mask=None\n   token_type_ids=<KerasTensor shape=(None, 16000), dtype=int32, sparse=False, name=keras_tensor_4>\n   position_ids=None\n   inputs_embeds=None\n   output_attentions=None\n   output_hidden_states=None\n   return_dict=None\n   training=False"
     ]
    }
   ],
   "source": [
    "\n",
    "model = dual_longformer()\n",
    "history = model.fit(\n",
    "    input_train, y_train,\n",
    "    epochs=3,\n",
    "    batch_size=2,\n",
    "    validation_data=(input_test, y_test),\n",
    "    verbose=1,\n",
    "    callbacks=[SaveModelCallback()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Plot training history\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "if 'val_loss' in history.history:\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Predict test data\n",
    "pred_test = np.argmax(model.predict(input_test), axis=1)\n",
    "\n",
    "print(classification_report(\n",
    "    [map_label[i] for i in y_test], \n",
    "    [map_label[i] for i in pred_test]\n",
    "))\n",
    "\n",
    "cnf_matrix = confusion_matrix(\n",
    "    [map_label[i] for i in y_test], \n",
    "    [map_label[i] for i in pred_test]\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(7, 7))\n",
    "plot_confusion_matrix(cnf_matrix, classes=list(map_label.values()))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def siamese_longformer():\n",
    "    set_seed(33)\n",
    "    opt = Adam(learning_rate=2e-5)\n",
    "    \n",
    "    id1 = Input((MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    id2 = Input((MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    mask1 = Input((MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    mask2 = Input((MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    atn1 = Input((MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    atn2 = Input((MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    \n",
    "    config = LongformerConfig()\n",
    "    config.output_hidden_states = False  # Set to True to obtain hidden states\n",
    "    config.max_position_embeddings = 16000\n",
    "    config.attention_window = [256] * config.num_hidden_layers\n",
    "    longformer_model = TFLongformerModel.from_pretrained(MODEL_NAME, from_pt=True, config=config)\n",
    "\n",
    "    embedding1 = longformer_model(id1, attention_mask=mask1, token_type_ids=atn1)[0]\n",
    "    embedding2 = longformer_model(id2, attention_mask=mask2, token_type_ids=atn2)[0]\n",
    "    \n",
    "    x1 = GlobalAveragePooling1D()(embedding1)\n",
    "    x2 = GlobalAveragePooling1D()(embedding2)\n",
    "    \n",
    "    x = Concatenate()([x1, x2])\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    out = Dense(len(map_label), activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=[id1, mask1, atn1, id2, mask2, atn2], outputs=out)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=opt)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 38603520 into shape (30522,768)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43msiamese_longformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m      3\u001b[0m     input_train, y_train,\n\u001b[1;32m      4\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[SaveModelCallback()]\n\u001b[1;32m      9\u001b[0m )\n",
      "Cell \u001b[0;32mIn[13], line 16\u001b[0m, in \u001b[0;36msiamese_longformer\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m config\u001b[38;5;241m.\u001b[39mmax_position_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m16000\u001b[39m\n\u001b[1;32m     15\u001b[0m config\u001b[38;5;241m.\u001b[39mattention_window \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m256\u001b[39m] \u001b[38;5;241m*\u001b[39m config\u001b[38;5;241m.\u001b[39mnum_hidden_layers\n\u001b[0;32m---> 16\u001b[0m longformer_model \u001b[38;5;241m=\u001b[39m \u001b[43mTFLongformerModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODEL_NAME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_pt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m embedding1 \u001b[38;5;241m=\u001b[39m longformer_model(id1, attention_mask\u001b[38;5;241m=\u001b[39mmask1, token_type_ids\u001b[38;5;241m=\u001b[39matn1)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     19\u001b[0m embedding2 \u001b[38;5;241m=\u001b[39m longformer_model(id2, attention_mask\u001b[38;5;241m=\u001b[39mmask2, token_type_ids\u001b[38;5;241m=\u001b[39matn2)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/longformer/lib/python3.11/site-packages/transformers/modeling_tf_utils.py:2963\u001b[0m, in \u001b[0;36mTFPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2960\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_tf_pytorch_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_pytorch_checkpoint_in_tf2_model\n\u001b[1;32m   2962\u001b[0m     \u001b[38;5;66;03m# Load from a PyTorch checkpoint\u001b[39;00m\n\u001b[0;32m-> 2963\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_pytorch_checkpoint_in_tf2_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2964\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2965\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2966\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_missing_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2967\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_loading_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_loading_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2968\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_weight_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2969\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtf_to_pt_weight_rename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf_to_pt_weight_rename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2970\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2972\u001b[0m \u001b[38;5;66;03m# we might need to extend the variable scope for composite models\u001b[39;00m\n\u001b[1;32m   2973\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m load_weight_prefix \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/longformer/lib/python3.11/site-packages/transformers/modeling_tf_pytorch_utils.py:211\u001b[0m, in \u001b[0;36mload_pytorch_checkpoint_in_tf2_model\u001b[0;34m(tf_model, pytorch_checkpoint_path, tf_inputs, allow_missing_keys, output_loading_info, _prefix, tf_to_pt_weight_rename)\u001b[0m\n\u001b[1;32m    207\u001b[0m     pt_state_dict\u001b[38;5;241m.\u001b[39mupdate(state_dict)\n\u001b[1;32m    209\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPyTorch checkpoint contains \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(t\u001b[38;5;241m.\u001b[39mnumel()\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mt\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mpt_state_dict\u001b[38;5;241m.\u001b[39mvalues())\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_pytorch_weights_in_tf2_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtf_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpt_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtf_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_missing_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_missing_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_loading_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_loading_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtf_to_pt_weight_rename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf_to_pt_weight_rename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/longformer/lib/python3.11/site-packages/transformers/modeling_tf_pytorch_utils.py:255\u001b[0m, in \u001b[0;36mload_pytorch_weights_in_tf2_model\u001b[0;34m(tf_model, pt_state_dict, tf_inputs, allow_missing_keys, output_loading_info, _prefix, tf_to_pt_weight_rename)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;66;03m# Numpy doesn't understand bfloat16, so upcast to a dtype that doesn't lose precision\u001b[39;00m\n\u001b[1;32m    252\u001b[0m pt_state_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    253\u001b[0m     k: v\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mif\u001b[39;00m v\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbfloat16 \u001b[38;5;28;01melse\u001b[39;00m v\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m pt_state_dict\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    254\u001b[0m }\n\u001b[0;32m--> 255\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_pytorch_state_dict_in_tf2_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtf_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpt_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtf_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_missing_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_missing_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_loading_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_loading_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtf_to_pt_weight_rename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf_to_pt_weight_rename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/longformer/lib/python3.11/site-packages/transformers/modeling_tf_pytorch_utils.py:406\u001b[0m, in \u001b[0;36mload_pytorch_state_dict_in_tf2_model\u001b[0;34m(tf_model, pt_state_dict, tf_inputs, allow_missing_keys, output_loading_info, _prefix, tf_to_pt_weight_rename, ignore_mismatched_sizes, skip_logger_warnings)\u001b[0m\n\u001b[1;32m    404\u001b[0m     array \u001b[38;5;241m=\u001b[39m pt_state_dict[state_dict_name]\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 406\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mapply_transpose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtranspose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msymbolic_weight\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m tf\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mInvalidArgumentError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    408\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ignore_mismatched_sizes:\n",
      "File \u001b[0;32m~/miniconda3/envs/longformer/lib/python3.11/site-packages/transformers/modeling_tf_pytorch_utils.py:156\u001b[0m, in \u001b[0;36mapply_transpose\u001b[0;34m(transpose, weight, match_shape, pt_to_tf)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(match_shape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlist\u001b[39m(weight\u001b[38;5;241m.\u001b[39mshape):\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 156\u001b[0m         weight \u001b[38;5;241m=\u001b[39m \u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatch_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    158\u001b[0m         e\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (match_shape, match_shape)\n",
      "File \u001b[0;32m~/miniconda3/envs/longformer/lib/python3.11/site-packages/transformers/utils/generic.py:637\u001b[0m, in \u001b[0;36mreshape\u001b[0;34m(array, newshape)\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;124;03mFramework-agnostic version of `numpy.reshape` that will work on torch/TensorFlow/Jax tensors as well as NumPy\u001b[39;00m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;124;03marrays.\u001b[39;00m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_numpy_array(array):\n\u001b[0;32m--> 637\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_torch_tensor(array):\n\u001b[1;32m    639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m array\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m*\u001b[39mnewshape)\n",
      "File \u001b[0;32m~/miniconda3/envs/longformer/lib/python3.11/site-packages/numpy/core/fromnumeric.py:285\u001b[0m, in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_reshape_dispatcher)\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreshape\u001b[39m(a, newshape, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    202\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m    Gives a new shape to an array without changing its data.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;124;03m           [5, 6]])\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreshape\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/longformer/lib/python3.11/site-packages/numpy/core/fromnumeric.py:59\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 38603520 into shape (30522,768)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = siamese_longformer()\n",
    "history = model.fit(\n",
    "    input_train, y_train,\n",
    "    epochs=3,\n",
    "    batch_size=6,\n",
    "    validation_data=(input_test, y_test),\n",
    "    verbose=1,\n",
    "    callbacks=[SaveModelCallback()]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "if 'val_loss' in history.history:\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Predict test data\n",
    "pred_test = np.argmax(model.predict(input_test), axis=1)\n",
    "\n",
    "print(classification_report(\n",
    "    [map_label[i] for i in y_test], \n",
    "    [map_label[i] for i in pred_test]\n",
    "))\n",
    "\n",
    "cnf_matrix = confusion_matrix(\n",
    "    [map_label[i] for i in y_test], \n",
    "    [map_label[i] for i in pred_test]\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(7, 7))\n",
    "plot_confusion_matrix(cnf_matrix, classes=list(map_label.values()))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "longformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
