{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "/home/msi/miniconda3/envs/triallong/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Epoch 1/10:   0%|          | 0/54 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (3534 > 1024). Running this sequence through the model will result in indexing errors\n",
      "/tmp/ipykernel_3843901/1536267745.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'chunks1': torch.tensor(chunks1),\n",
      "/tmp/ipykernel_3843901/1536267745.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'chunks2': torch.tensor(chunks2),\n",
      "Epoch 1/10:   0%|          | 0/54 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [7, 31993] at entry 0 and [4, 31996] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 270\u001b[0m\n\u001b[1;32m    267\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 270\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 259\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    256\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdamW(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mLEARNING_RATE, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m)\n\u001b[1;32m    257\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mStepLR(optimizer, step_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m)\n\u001b[0;32m--> 259\u001b[0m all_preds, all_labels \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_label\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    264\u001b[0m cnf_matrix \u001b[38;5;241m=\u001b[39m confusion_matrix(all_labels, all_preds)\n\u001b[1;32m    265\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m7\u001b[39m))\n",
      "Cell \u001b[0;32mIn[2], line 109\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, device, map_label)\u001b[0m\n\u001b[1;32m    106\u001b[0m all_train_labels \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# Training loop\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEpoch \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepoch\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunks1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mchunks1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunks2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mchunks2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/triallong/lib/python3.11/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/triallong/lib/python3.11/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m~/miniconda3/envs/triallong/lib/python3.11/site-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/triallong/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 237\u001b[0m, in \u001b[0;36mmain.<locals>.custom_collate_fn\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    234\u001b[0m padded_chunks1 \u001b[38;5;241m=\u001b[39m [F\u001b[38;5;241m.\u001b[39mpad(item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchunks1\u001b[39m\u001b[38;5;124m'\u001b[39m], (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m16000\u001b[39m \u001b[38;5;241m-\u001b[39m item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchunks1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m))) \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[1;32m    235\u001b[0m padded_chunks2 \u001b[38;5;241m=\u001b[39m [F\u001b[38;5;241m.\u001b[39mpad(item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchunks2\u001b[39m\u001b[38;5;124m'\u001b[39m], (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m16000\u001b[39m \u001b[38;5;241m-\u001b[39m item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchunks2\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m))) \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m--> 237\u001b[0m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchunks1\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpadded_chunks1\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    238\u001b[0m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchunks2\u001b[39m\u001b[38;5;124m'\u001b[39m: torch\u001b[38;5;241m.\u001b[39mstack(padded_chunks2),\n\u001b[1;32m    239\u001b[0m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m: torch\u001b[38;5;241m.\u001b[39mtensor([item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m batch])}\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [7, 31993] at entry 0 and [4, 31996] at entry 1"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, LongformerModel, LongformerConfig, LongformerTokenizer\n",
    "\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "class SlidingWindowTextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length, stride):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.stride = stride\n",
    "\n",
    "    def tokenize_and_chunk(self, text):\n",
    "        tokens = self.tokenizer(text, return_tensors=\"pt\", truncation=False)[\"input_ids\"].squeeze()\n",
    "        chunks = []\n",
    "        for i in range(0, len(tokens), self.stride):\n",
    "            chunk = tokens[i:i+self.max_length]\n",
    "            if len(chunk) < self.max_length:\n",
    "                chunk = torch.cat([chunk, torch.zeros(self.max_length - len(chunk), dtype=torch.long)])\n",
    "            chunks.append(chunk)\n",
    "        return torch.stack(chunks)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text1 = self.texts.iloc[idx]['source_content']\n",
    "        text2 = self.texts.iloc[idx]['suspicious_content']\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        chunks1 = self.tokenize_and_chunk(text1)\n",
    "        chunks2 = self.tokenize_and_chunk(text2)\n",
    "        return {\n",
    "     'chunks1': torch.tensor(chunks1),\n",
    "    'chunks2': torch.tensor(chunks2),\n",
    "    'label': torch.tensor(label)}\n",
    "\n",
    "\n",
    "\n",
    "from transformers import T5Tokenizer, T5EncoderModel\n",
    "\n",
    "class DualAraT5SlidingWindow(nn.Module):\n",
    "    def __init__(self, model_name, num_labels):\n",
    "        super(DualAraT5SlidingWindow, self).__init__()\n",
    "        self.encoder = T5EncoderModel.from_pretrained(model_name)\n",
    "        hidden_size = self.encoder.config.d_model\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.dense = nn.Linear(hidden_size * 2, 64)\n",
    "        self.classifier = nn.Linear(64, num_labels)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, chunks1, chunks2):\n",
    "        embeddings1 = []\n",
    "        embeddings2 = []\n",
    "        \n",
    "        # Process chunks for the first and second documents\n",
    "        for chunk in chunks1:\n",
    "            output = self.encoder(input_ids=chunk)[\"last_hidden_state\"].mean(dim=1)\n",
    "            embeddings1.append(output)\n",
    "        \n",
    "        for chunk in chunks2:\n",
    "            output = self.encoder(input_ids=chunk)[\"last_hidden_state\"].mean(dim=1)\n",
    "            embeddings2.append(output)\n",
    "        \n",
    "        # Aggregate chunk embeddings\n",
    "        doc_embedding1 = torch.mean(torch.stack(embeddings1), dim=0)\n",
    "        doc_embedding2 = torch.mean(torch.stack(embeddings2), dim=0)\n",
    "        \n",
    "        # Concatenate and classify\n",
    "        concatenated = torch.cat((doc_embedding1, doc_embedding2), dim=1)\n",
    "        x = self.dense(concatenated)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        logits = self.classifier(x)\n",
    "        return logits\n",
    "    \n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, device, map_label=None):\n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        all_train_preds = []\n",
    "        all_train_labels = []\n",
    "        \n",
    "        # Training loop\n",
    "        for batch in tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs}'):\n",
    "            chunks1 = torch.stack(batch['chunks1']).to(device)\n",
    "            chunks2 = torch.stack(batch['chunks2']).to(device)\n",
    "            labels = torch.tensor(batch['label']).to(device)\n",
    "\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(chunks1, chunks2)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            # Collect predictions and labels\n",
    "            _, predicted = torch.max(torch.softmax(outputs, dim=1), 1)\n",
    "            all_train_preds.extend(predicted.cpu().numpy())\n",
    "            all_train_labels.extend(labels.cpu().numpy())\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Print Training Metrics\n",
    "        print(f'\\nEpoch {epoch + 1}:')\n",
    "        print(f'Training Loss: {train_loss/len(train_loader):.4f}')\n",
    "        \n",
    "        if map_label:\n",
    "            train_report = classification_report(\n",
    "                all_train_labels, all_train_preds, target_names=list(map_label.values())\n",
    "            )\n",
    "            print(\"Training Metrics:\")\n",
    "            print(train_report)\n",
    "        \n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        all_val_preds = []\n",
    "        all_val_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                chunks1 = batch['chunks1'].to(device)\n",
    "                chunks2 = batch['chunks2'].to(device)\n",
    "                labels = batch['label'].to(device)\n",
    "                \n",
    "                outputs = model(chunks1, chunks2)\n",
    "                \n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                # Collect predictions and labels\n",
    "                _, predicted = torch.max(torch.softmax(outputs, dim=1), 1)\n",
    "                all_val_preds.extend(predicted.cpu().numpy())\n",
    "                all_val_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        # Print Validation Metrics\n",
    "        print(f'Validation Loss: {val_loss/len(val_loader):.4f}')\n",
    "        \n",
    "        if map_label:\n",
    "            val_report = classification_report(\n",
    "                all_val_labels, all_val_preds, target_names=list(map_label.values())\n",
    "            )\n",
    "            print(\"Validation Metrics:\")\n",
    "            print(val_report)\n",
    "\n",
    "        # Save best model\n",
    "        if val_loss/len(val_loader) < best_val_loss:\n",
    "            best_val_loss = val_loss/len(val_loader)\n",
    "            torch.save(model.state_dict(), 'best_model.pt')\n",
    "    \n",
    "    return all_val_preds, all_val_labels\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, fontsize=25)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90, fontsize=15)\n",
    "    plt.yticks(tick_marks, classes, fontsize=15)\n",
    "    \n",
    "    fmt = '.2f'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\", fontsize=14)\n",
    "    \n",
    "    plt.ylabel('True label', fontsize=20)\n",
    "    plt.xlabel('Predicted label', fontsize=20)\n",
    "\n",
    "def main():\n",
    "    # Set constants\n",
    "    MAX_SEQUENCE_LENGTH = 16000  # Maximum sequence length for AraT5\n",
    "    STRIDE = 512  # Overlap between chunks\n",
    "    MODEL_NAME = \"UBC-NLP/AraT5v2-base-1024\"  # AraT5 model\n",
    "    BATCH_SIZE = 2\n",
    "    NUM_EPOCHS = 10\n",
    "    LEARNING_RATE = 2e-5\n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    set_seed(33)\n",
    "    \n",
    "    # Load and preprocess data\n",
    "    df = pd.read_csv('FinalDatasetBalanced.csv')\n",
    "    df['plagiarism_type'] = df['plagiarism_type'].factorize()[0]\n",
    "    map_label = dict(enumerate(df['plagiarism_type'].factorize()[1]))\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df[['source_content', 'suspicious_content']], \n",
    "        df['plagiarism_type'].values,\n",
    "        random_state=33,\n",
    "        test_size=0.3\n",
    "    )\n",
    "    \n",
    "    tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)\n",
    "    \n",
    "    # Create datasets with sliding window\n",
    "    train_dataset = SlidingWindowTextDataset(X_train, y_train, tokenizer, MAX_SEQUENCE_LENGTH, STRIDE)\n",
    "    test_dataset = SlidingWindowTextDataset(X_test, y_test, tokenizer, MAX_SEQUENCE_LENGTH, STRIDE)\n",
    "    \n",
    "\n",
    "    import torch.nn.functional as F\n",
    "\n",
    "    def custom_collate_fn(batch):\n",
    "        padded_chunks1 = [F.pad(item['chunks1'], (0, 16000 - item['chunks1'].size(0))) for item in batch]\n",
    "        padded_chunks2 = [F.pad(item['chunks2'], (0, 16000 - item['chunks2'].size(0))) for item in batch]\n",
    "        return {\n",
    "        'chunks1': torch.stack(padded_chunks1),\n",
    "        'chunks2': torch.stack(padded_chunks2),\n",
    "        'label': torch.tensor([item['label'] for item in batch])}\n",
    "\n",
    "\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=32,\n",
    "    collate_fn=custom_collate_fn)\n",
    "\n",
    "\n",
    "    # train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=lambda x: x)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, collate_fn=custom_collate_fn)\n",
    "    \n",
    "    model = DualAraT5SlidingWindow(MODEL_NAME, len(map_label)).to(DEVICE)\n",
    "    \n",
    "    class_weights = torch.tensor([0.1305, 0.1552, 0.1556, 0.5587]).to(DEVICE)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.7)\n",
    "\n",
    "    all_preds, all_labels = train_model(\n",
    "        model, train_loader, test_loader, \n",
    "        criterion, optimizer, scheduler, NUM_EPOCHS, DEVICE, map_label\n",
    "    )\n",
    "    \n",
    "    cnf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    plot_confusion_matrix(cnf_matrix, classes=list(map_label.values()))\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "triallong",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
