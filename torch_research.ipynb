{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EX8qiSe2LgSx"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 15:06:33.992359: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1731589594.002527  494758 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1731589594.005686  494758 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-14 15:06:34.016966: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import AutoTokenizer, LongformerConfig, LongformerModel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get index of currently selected device\n",
    "torch.cuda.current_device() # returns 0 in my case\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get number of GPUs available\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "tK-e7FNeLwVK"
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, fontsize=25)\n",
    "    #plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90, fontsize=15)\n",
    "    plt.yticks(tick_marks, classes, fontsize=15)\n",
    "\n",
    "    fmt = '.2f'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\", fontsize = 14)\n",
    "\n",
    "    plt.ylabel('True label', fontsize=20)\n",
    "    plt.xlabel('Predicted label', fontsize=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "1UyyorfdL7OK"
   },
   "outputs": [],
   "source": [
    "\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "df = pd.read_csv('FinalDatasetBalanced.csv')\n",
    "df['plagiarism_type'], uniques = pd.factorize(df['plagiarism_type'])\n",
    "map_label = dict(enumerate(uniques))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "1882jRpWTz-m"
   },
   "outputs": [],
   "source": [
    "def convert_to_transformer_inputs(str1, str2, tokenizer, max_sequence_length, double=True):\n",
    "    def return_id(str1, str2, length):\n",
    "        inputs = tokenizer.encode_plus(\n",
    "            str1, str2,\n",
    "            add_special_tokens=True,\n",
    "            max_length=length,\n",
    "            truncation=True,\n",
    "            padding='max_length',  # Let the tokenizer handle padding\n",
    "            return_token_type_ids=True,\n",
    "            return_attention_mask=True\n",
    "        )\n",
    "        input_ids = inputs[\"input_ids\"]\n",
    "        input_masks = inputs[\"attention_mask\"]\n",
    "        input_segments = inputs[\"token_type_ids\"]\n",
    "        return [input_ids, input_masks, input_segments]\n",
    "\n",
    "    if double:\n",
    "        input_ids_1, input_masks_1, input_segments_1 = return_id(str1, None, max_sequence_length)\n",
    "        input_ids_2, input_masks_2, input_segments_2 = return_id(str2, None, max_sequence_length)\n",
    "\n",
    "        return [input_ids_1, input_masks_1, input_segments_1,\n",
    "                input_ids_2, input_masks_2, input_segments_2]\n",
    "    else:\n",
    "        input_ids, input_masks, input_segments = return_id(str1, str2, max_sequence_length)\n",
    "\n",
    "        return [input_ids, input_masks, input_segments, None, None, None]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "YxFZyvkwT6xY"
   },
   "outputs": [],
   "source": [
    "def compute_input_arrays(df, columns, tokenizer, max_sequence_length, double=True):\n",
    "    input_ids_1, input_masks_1, input_segments_1 = [], [], []\n",
    "    input_ids_2, input_masks_2, input_segments_2 = [], [], []\n",
    "\n",
    "    for _, instance in df[columns].iterrows():\n",
    "        str1, str2 = instance[columns[0]], instance[columns[1]]\n",
    "        ids_1, masks_1, segments_1, ids_2, masks_2, segments_2 = \\\n",
    "            convert_to_transformer_inputs(str1, str2, tokenizer, max_sequence_length, double=double)\n",
    "\n",
    "        input_ids_1.append(ids_1)\n",
    "        input_masks_1.append(masks_1)\n",
    "        input_segments_1.append(segments_1)\n",
    "        input_ids_2.append(ids_2)\n",
    "        input_masks_2.append(masks_2)\n",
    "        input_segments_2.append(segments_2)\n",
    "\n",
    "    if double:\n",
    "        return [np.asarray(input_ids_1, dtype=np.int32),\n",
    "                np.asarray(input_masks_1, dtype=np.int32),\n",
    "                np.asarray(input_segments_1, dtype=np.int32),\n",
    "                np.asarray(input_ids_2, dtype=np.int32),\n",
    "                np.asarray(input_masks_2, dtype=np.int32),\n",
    "                np.asarray(input_segments_2, dtype=np.int32)]\n",
    "    else:\n",
    "        return [np.asarray(input_ids_1, dtype=np.int32),\n",
    "                np.asarray(input_masks_1, dtype=np.int32),\n",
    "                np.asarray(input_segments_1, dtype=np.int32)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zzcYoMMvUGxU",
    "outputId": "c58df3ca-1b03-4d1a-cd1d-b949f5420a2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1702, 2) (730, 2)\n",
      "(1702,) (730,)\n"
     ]
    }
   ],
   "source": [
    "### TRAIN TEST SPLIT ###\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['source_content','suspicious_content']], df['plagiarism_type'].values,\n",
    "                                                    random_state=33, test_size = 0.3)\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1TcB4yIvVO_c",
    "outputId": "3ce223de-c71f-4b90-bf51-2a9f81005092"
   },
   "outputs": [],
   "source": [
    "### IMPORT TOKENIZER ###\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 16000\n",
    "MODEL_NAME = \"longformer-encdec-large-16384\"  # Adjusted to a valid model name\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "### CREATE SEQUENCES (id, mask, segments) FOR TRAIN AND TEST ###\n",
    "\n",
    "input_train = compute_input_arrays(X_train,['source_content','suspicious_content'], tokenizer, MAX_SEQUENCE_LENGTH)\n",
    "input_test = compute_input_arrays(X_test, ['source_content','suspicious_content'], tokenizer, MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "class PlagiarismDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, inputs, labels):\n",
    "        self.inputs = inputs\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs[0])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {\n",
    "            'id1': torch.tensor(self.inputs[0][idx], dtype=torch.long),\n",
    "            'mask1': torch.tensor(self.inputs[1][idx], dtype=torch.long),\n",
    "            'atn1': torch.tensor(self.inputs[2][idx], dtype=torch.long),\n",
    "            'id2': torch.tensor(self.inputs[3][idx], dtype=torch.long),\n",
    "            'mask2': torch.tensor(self.inputs[4][idx], dtype=torch.long),\n",
    "            'atn2': torch.tensor(self.inputs[5][idx], dtype=torch.long),\n",
    "            'labels': torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }\n",
    "        return item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "rQuC1gWhVVZP"
   },
   "outputs": [],
   "source": [
    "train_dataset = PlagiarismDataset(input_train, y_train)\n",
    "test_dataset = PlagiarismDataset(input_test, y_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=2, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w7JNdSrAVaiQ"
   },
   "outputs": [],
   "source": [
    "# class DualLongformer(nn.Module):\n",
    "#     def __init__(self, num_labels):\n",
    "#         super(DualLongformer, self).__init__()\n",
    "#         set_seed(33)\n",
    "#         self.config = LongformerConfig.from_pretrained(MODEL_NAME,ignore_mismatched_sizes=True)\n",
    "#         self.config.max_position_embeddings = MAX_SEQUENCE_LENGTH\n",
    "#         self.config.attention_window = [512] * self.config.num_hidden_layers\n",
    "\n",
    "#         self.longformer_model1 = LongformerModel.from_pretrained(MODEL_NAME, config=self.config,ignore_mismatched_sizes=True)\n",
    "#         self.longformer_model2 = LongformerModel.from_pretrained(MODEL_NAME, config=self.config,ignore_mismatched_sizes=True)\n",
    "\n",
    "#         self.dropout = nn.Dropout(0.2)\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.dense = nn.Linear(2 * self.config.hidden_size, 64)\n",
    "#         self.classifier = nn.Linear(64, len(map_label))\n",
    "\n",
    "#     def forward(self, id1, mask1, atn1, id2, mask2, atn2):\n",
    "#         embedding1 = self.longformer_model1(input_ids=id1, attention_mask=mask1, token_type_ids=atn1)[0]\n",
    "#         embedding2 = self.longformer_model2(input_ids=id2, attention_mask=mask2, token_type_ids=atn2)[0]\n",
    "\n",
    "#         x1 = torch.mean(embedding1, dim=1)  # GlobalAveragePooling1D\n",
    "#         x2 = torch.mean(embedding2, dim=1)  # GlobalAveragePooling1D\n",
    "\n",
    "#         x = torch.cat((x1, x2), dim=1)\n",
    "#         x = self.dense(x)\n",
    "#         x = self.relu(x)\n",
    "#         x = self.dropout(x)\n",
    "#         logits = self.classifier(x)\n",
    "#         return logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class SiameseLongformer(nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super(SiameseLongformer, self).__init__()\n",
    "        self.config = LongformerConfig.from_pretrained(MODEL_NAME)\n",
    "        # self.config.output_hidden_states = False\n",
    "        self.config.max_position_embeddings = MAX_SEQUENCE_LENGTH\n",
    "        self.config.attention_window = [512] * self.config.num_hidden_layers\n",
    "        \n",
    "        self.longformer = LongformerModel.from_pretrained(\n",
    "            MODEL_NAME, config=self.config\n",
    "        )\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.dense = nn.Linear(2 * self.config.hidden_size, 64)\n",
    "        self.classifier = nn.Linear(64, num_labels)\n",
    "\n",
    "    def forward(\n",
    "        self, input_ids1, attention_mask1, input_ids2, attention_mask2\n",
    "    ):\n",
    "        outputs1 = self.longformer(\n",
    "            input_ids=input_ids1, attention_mask=attention_mask1\n",
    "        )\n",
    "        outputs2 = self.longformer(\n",
    "            input_ids=input_ids2, attention_mask=attention_mask2\n",
    "        )\n",
    "        # Take the mean over the sequence length\n",
    "        x1 = torch.mean(outputs1.last_hidden_state, dim=1)\n",
    "        x2 = torch.mean(outputs2.last_hidden_state, dim=1)\n",
    "        x = torch.cat((x1, x2), dim=1)  # Concatenate along the feature dimension\n",
    "        x = torch.relu(self.dense(x))\n",
    "        x = self.dropout(x)\n",
    "        logits = self.classifier(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wEhZ0UmWVknb",
    "outputId": "76d6f4ef-4e2e-47ac-c3af-c040f4b5ae34"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type bart to instantiate a model of type longformer. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of LongformerModel were not initialized from the model checkpoint at longformer-encdec-large-16384 and are newly initialized: ['embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.key_global.bias', 'encoder.layer.0.attention.self.key_global.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.query_global.bias', 'encoder.layer.0.attention.self.query_global.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.attention.self.value_global.bias', 'encoder.layer.0.attention.self.value_global.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.key_global.bias', 'encoder.layer.1.attention.self.key_global.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.query_global.bias', 'encoder.layer.1.attention.self.query_global.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.attention.self.value_global.bias', 'encoder.layer.1.attention.self.value_global.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.key_global.bias', 'encoder.layer.10.attention.self.key_global.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.query_global.bias', 'encoder.layer.10.attention.self.query_global.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.attention.self.value_global.bias', 'encoder.layer.10.attention.self.value_global.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.key_global.bias', 'encoder.layer.11.attention.self.key_global.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.query_global.bias', 'encoder.layer.11.attention.self.query_global.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.attention.self.value_global.bias', 'encoder.layer.11.attention.self.value_global.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.key_global.bias', 'encoder.layer.2.attention.self.key_global.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.query_global.bias', 'encoder.layer.2.attention.self.query_global.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.attention.self.value_global.bias', 'encoder.layer.2.attention.self.value_global.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.key_global.bias', 'encoder.layer.3.attention.self.key_global.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.query_global.bias', 'encoder.layer.3.attention.self.query_global.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.attention.self.value_global.bias', 'encoder.layer.3.attention.self.value_global.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.key_global.bias', 'encoder.layer.4.attention.self.key_global.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.query_global.bias', 'encoder.layer.4.attention.self.query_global.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.attention.self.value_global.bias', 'encoder.layer.4.attention.self.value_global.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.key_global.bias', 'encoder.layer.5.attention.self.key_global.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.query_global.bias', 'encoder.layer.5.attention.self.query_global.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.attention.self.value_global.bias', 'encoder.layer.5.attention.self.value_global.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.key_global.bias', 'encoder.layer.6.attention.self.key_global.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.query_global.bias', 'encoder.layer.6.attention.self.query_global.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.attention.self.value_global.bias', 'encoder.layer.6.attention.self.value_global.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.key_global.bias', 'encoder.layer.7.attention.self.key_global.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.query_global.bias', 'encoder.layer.7.attention.self.query_global.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.attention.self.value_global.bias', 'encoder.layer.7.attention.self.value_global.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.key_global.bias', 'encoder.layer.8.attention.self.key_global.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.query_global.bias', 'encoder.layer.8.attention.self.query_global.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.attention.self.value_global.bias', 'encoder.layer.8.attention.self.value_global.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.key_global.bias', 'encoder.layer.9.attention.self.key_global.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.query_global.bias', 'encoder.layer.9.attention.self.query_global.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.attention.self.value_global.bias', 'encoder.layer.9.attention.self.value_global.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = SiameseLongformer(len(map_label))\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "NepN2kUmVohO"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train_epoch(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(loader, desc='Training'):\n",
    "        optimizer.zero_grad()\n",
    "        id1 = batch['id1'].to(device)\n",
    "        mask1 = batch['mask1'].to(device)\n",
    "        atn1 = batch['atn1'].to(device)\n",
    "        id2 = batch['id2'].to(device)\n",
    "        mask2 = batch['mask2'].to(device)\n",
    "        atn2 = batch['atn2'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(id1, mask1, atn1, id2, mask2, atn2)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    return avg_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "o8e1Y3SjVrZo"
   },
   "outputs": [],
   "source": [
    "def eval_epoch(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    preds = []\n",
    "    true_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc='Evaluating'):\n",
    "            id1 = batch['id1'].to(device)\n",
    "            mask1 = batch['mask1'].to(device)\n",
    "            atn1 = batch['atn1'].to(device)\n",
    "            id2 = batch['id2'].to(device)\n",
    "            mask2 = batch['mask2'].to(device)\n",
    "            atn2 = batch['atn2'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(id1, mask1, atn1, id2, mask2, atn2)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    return avg_loss, preds, true_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 498
    },
    "id": "Sq7GJTtIVte-",
    "outputId": "3eac0406-b0a6-42b6-dfae-8f26cca79338"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/851 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "SiameseLongformer.forward() takes 5 positional arguments but 7 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     val_loss, val_preds, val_labels \u001b[38;5;241m=\u001b[39m eval_epoch(model, test_loader, criterion)\n\u001b[1;32m      9\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "Cell \u001b[0;32mIn[15], line 16\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, loader, optimizer, criterion)\u001b[0m\n\u001b[1;32m     13\u001b[0m atn2 \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124matn2\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     14\u001b[0m labels \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 16\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mid1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matn1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mid2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matn2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     18\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniconda3/envs/longformer/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/longformer/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[0;31mTypeError\u001b[0m: SiameseLongformer.forward() takes 5 positional arguments but 7 were given"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, criterion)\n",
    "    val_loss, val_preds, val_labels = eval_epoch(model, test_loader, criterion)\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    print(f'Train Loss: {train_loss:.4f}')\n",
    "    print(f'Val Loss: {val_loss:.4f}')\n",
    "\n",
    "    # Save the model\n",
    "    save_path = f'longformer_checkpoints/epoch_{epoch+1}'\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    model_to_save = model.module if hasattr(model, 'module') else model\n",
    "    torch.save(model_to_save.state_dict(), os.path.join(save_path, 'pytorch_model.bin'))\n",
    "    print(f'Saved model to {save_path}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8QdWPXYpVwZl"
   },
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "### PREDICT TEST ###\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "pred_test = val_preds\n",
    "true_test = val_labels\n",
    "\n",
    "class_names = list(map_label.values())\n",
    "\n",
    "true_class_names = [map_label[i] for i in true_test]\n",
    "pred_class_names = [map_label[i] for i in pred_test]\n",
    "\n",
    "print(classification_report(true_class_names, pred_class_names))\n",
    "\n",
    "cnf_matrix = confusion_matrix(true_class_names, pred_class_names)\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2DVaCWJFV0AL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "longformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
